{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m92LG8nzyz40"
      },
      "source": [
        "## Data\n",
        "- 첨부된 ko-en-en.parse.syn은 330,974 한국어 문장에 대응되는 영어문장이 품사와 구문분석이 되어 있는 파일이고 ko-en-ko.parse.syn은 이에 대응되는 한국어 문장이 형태소와 구문분석이 되어 있는 파일이다.\n",
        "\n",
        "(ROOT (S (NP (NNP Flight) (NNP 007)) (VP (MD will) (VP (VB stay) (PP (IN on) (NP (NP (DT the) (NN ground)) (PP (IN for) (NP (CD one) (NN hour))))))) (. .)))\n",
        "\n",
        "\n",
        "<id 1>\n",
        "<sent 1>\n",
        "1       2       NP      777/SN\n",
        "2       6       NP_SBJ  항공편/NNG|은/JX\n",
        "3       4       NP      1/SN|시간/NNG\n",
        "4       6       NP_AJT  동안/NNG\n",
        "5       6       NP_AJT  지상/NNG|에/JKB\n",
        "6       7       VP      머물/VV|게/EC\n",
        "7       0       VP      되/VV|ㅂ니다/EF|./SF\n",
        "</sent>\n",
        "</id>\n",
        "\n",
        "- 이 두 파일을 프로세싱하여 한-영 병행 데이터로 만들고 이를 학습 및 테스트 데이터로 사용한다.\n",
        "- Hint: 구조화된 데이터를 프로세싱하기 위해서는 nltk의 모듈을 사용할 수 있다.\n",
        "\n",
        "- 한국어 형태소 분석된 단위를 어절별로 결합할 수 있고, 분석된 채로 그대로 사용할 수도 있다.\n",
        "- 두 언어의 어순을 비슷하게 데이터를 만들어 학습할 수도 있고, 번역의 성능을 높이기 위해 다양한 형태로 재구조화 할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ITpakSHDWOc"
      },
      "source": [
        "# 1. Helsinki_NLP_opus_mt_ko_en"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4H-QtSon2VZ9"
      },
      "source": [
        "## 드라이브 마운트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuOeRDyt2VZ9",
        "outputId": "c9b7866e-f1ff-4d9e-dec5-7e2de7b2c7cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPv8J9nL2VZ-"
      },
      "source": [
        "## 파일 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNsNhRxc2VZ-"
      },
      "outputs": [],
      "source": [
        "PATH = \"/content/drive/MyDrive/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-Uc-6v62VZ-"
      },
      "outputs": [],
      "source": [
        "ko_path = PATH+\"ko-en.ko.parse\"\n",
        "en_path = PATH+\"ko-en.en.parse.syn\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGtspuJh2VZ-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SyZ608Pg2VZ_"
      },
      "outputs": [],
      "source": [
        "ko_lines = \"\"\n",
        "with open(ko_path, \"r\") as ko_file:\n",
        "    for line in ko_file.readlines():\n",
        "        ko_lines += line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qePiApWu2VZ_"
      },
      "outputs": [],
      "source": [
        "with open(en_path, \"r\") as en_file:\n",
        "    en_lines = en_file.readlines()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lskr0XJI2VZ_"
      },
      "source": [
        "## 데이터 전처리 (깔끔한 문장의 리스트로 만들기)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHD16YLz2VZ_"
      },
      "outputs": [],
      "source": [
        "from nltk import Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "477eQBmEKRGT"
      },
      "outputs": [],
      "source": [
        "# nltk의 Tree 모듈을 사용하여 필요한 정보 추출\n",
        "full_en_text_list = []\n",
        "for line in en_lines:\n",
        "    sent = \"\"\n",
        "    t = Tree.fromstring(line)\n",
        "    for token in t.leaves():\n",
        "      sent += token + ' '\n",
        "    full_en_text_list.append(sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kj_ru2RK2VaA",
        "outputId": "f4d92abb-2034-45b8-a75f-d0cb04be78fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Flight 007 will stay on the ground for one hour . ',\n",
              " 'Flight 017 will stay on the ground for three hours . ',\n",
              " \"I need 1,000 dollars in traveler 's checks . \",\n",
              " 'The official exchange rate is around 1,250 Won . ',\n",
              " 'Please give me three hundred dollar bills and twenty dollar bills for the rest . ',\n",
              " 'Can I have one hundred dollar bill and four fifty dollar bills ? ',\n",
              " 'Do you have change for $ 100 ? ',\n",
              " \"I 'd like to change 100 dollars . \",\n",
              " \"I 'd like to change $ 100 . \",\n",
              " 'Change 100 dollars . ']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "full_en_text_list[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dz0zXFSo2VaA",
        "outputId": "55f33fc5-46f8-41f3-ef7e-a3480abb43e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<id 1>',\n",
              " '<sent 1>',\n",
              " '1\\t2\\tNP\\t777/SN',\n",
              " '2\\t6\\tNP_SBJ\\t항공편/NNG|은/JX',\n",
              " '3\\t4\\tNP\\t1/SN|시간/NNG',\n",
              " '4\\t6\\tNP_AJT\\t동안/NNG',\n",
              " '5\\t6\\tNP_AJT\\t지상/NNG|에/JKB',\n",
              " '6\\t7\\tVP\\t머물/VV|게/EC',\n",
              " '7\\t0\\tVP\\t되/VV|ㅂ니다/EF|./SF',\n",
              " '</sent>',\n",
              " '']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 한 문장씩 나눈 리스트 만들기\n",
        "ko_list = ko_lines.split(\"</id>\")\n",
        "for i in range(len(ko_list)):\n",
        "    ko_list[i] = ko_list[i].split(\"\\n\")\n",
        "\n",
        "ko_list[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASAtTz6y2VaA"
      },
      "outputs": [],
      "source": [
        "# 필요한 정보만 추출\n",
        "import re\n",
        "\n",
        "pattern = r\"[가-힣ㄱ-ㅎ]+|[0-9]+(?=\\/SN)\"\n",
        "\n",
        "for i in range(len(ko_list)):\n",
        "    for j in range(len(ko_list[i])):\n",
        "        ko_list[i][j] = re.findall(pattern, ko_list[i][j])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbUoKAIn2VaA",
        "outputId": "ee05d3b5-7a64-4857-9979-318caf779aa9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[[],\n",
              "  [],\n",
              "  ['777'],\n",
              "  ['항공편', '은'],\n",
              "  ['1', '시간'],\n",
              "  ['동안'],\n",
              "  ['지상', '에'],\n",
              "  ['머물', '게'],\n",
              "  ['되', 'ㅂ니다'],\n",
              "  [],\n",
              "  []],\n",
              " [[],\n",
              "  [],\n",
              "  [],\n",
              "  [],\n",
              "  ['777'],\n",
              "  ['항공편', '은'],\n",
              "  ['3', '시간'],\n",
              "  ['동안'],\n",
              "  ['지상', '에'],\n",
              "  ['있', '겠', '습니다'],\n",
              "  [],\n",
              "  []],\n",
              " [[],\n",
              "  [],\n",
              "  [],\n",
              "  [],\n",
              "  ['1', '000', '달러'],\n",
              "  ['여행자', '수표', '가'],\n",
              "  ['필요', '하', 'ㅂ니다'],\n",
              "  [],\n",
              "  []],\n",
              " [[], [], [], [], ['1', '250', '원', '이'], ['공식'], ['환율', '이', 'ㅂ니다'], [], []],\n",
              " [[],\n",
              "  [],\n",
              "  [],\n",
              "  [],\n",
              "  ['100', '달러'],\n",
              "  ['3', '장', '과'],\n",
              "  ['나머지', '는'],\n",
              "  ['20', '달러', '권', '으로'],\n",
              "  ['주', '시', 'ㅂ시오'],\n",
              "  [],\n",
              "  []],\n",
              " [[],\n",
              "  [],\n",
              "  [],\n",
              "  [],\n",
              "  ['100', '달러'],\n",
              "  ['한'],\n",
              "  ['장', '과'],\n",
              "  ['50', '달러'],\n",
              "  ['4', '장', '으로'],\n",
              "  ['바꾸', '어'],\n",
              "  ['주', '시', '겠', '어요'],\n",
              "  [],\n",
              "  []],\n",
              " [[],\n",
              "  [],\n",
              "  [],\n",
              "  [],\n",
              "  ['100', '달러', '를'],\n",
              "  ['바꾸', '어'],\n",
              "  ['주', '시', '겠', '어요'],\n",
              "  [],\n",
              "  []],\n",
              " [[], [], [], [], ['100', '달러', '만'], ['바꾸', '어'], ['주', '시', '어요'], [], []],\n",
              " [[],\n",
              "  [],\n",
              "  [],\n",
              "  [],\n",
              "  ['100', '달러', '만'],\n",
              "  ['환전'],\n",
              "  ['좀'],\n",
              "  ['하', '아'],\n",
              "  ['주', '시', '어요'],\n",
              "  [],\n",
              "  []],\n",
              " [[],\n",
              "  [],\n",
              "  [],\n",
              "  [],\n",
              "  ['100', '달러', '만'],\n",
              "  ['환전', '하', '아'],\n",
              "  ['주', '시', '어요'],\n",
              "  [],\n",
              "  []]]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ko_list[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECNmeIGysBQ7"
      },
      "outputs": [],
      "source": [
        "# 문장으로 만들어서 리스트에 넣어주기\n",
        "ko_text_list = []\n",
        "\n",
        "for i in range(len(ko_list)-1): # id로 split 해서 1개 추가로 생긴 부분 빼줌\n",
        "    full_sent = \"\"\n",
        "    for j in range(len(ko_list[i])):\n",
        "        if ko_list[i][j]:\n",
        "            for token in ko_list[i][j]:\n",
        "                full_sent += token + ' '\n",
        "\n",
        "    ko_text_list.append(full_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmXRPHoX2VaA",
        "outputId": "57f4ea32-8c65-404e-e3d6-c83adc2d9b88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['777 항공편 은 1 시간 동안 지상 에 머물 게 되 ㅂ니다 ',\n",
              " '777 항공편 은 3 시간 동안 지상 에 있 겠 습니다 ',\n",
              " '1 000 달러 여행자 수표 가 필요 하 ㅂ니다 ',\n",
              " '1 250 원 이 공식 환율 이 ㅂ니다 ',\n",
              " '100 달러 3 장 과 나머지 는 20 달러 권 으로 주 시 ㅂ시오 ',\n",
              " '100 달러 한 장 과 50 달러 4 장 으로 바꾸 어 주 시 겠 어요 ',\n",
              " '100 달러 를 바꾸 어 주 시 겠 어요 ',\n",
              " '100 달러 만 바꾸 어 주 시 어요 ',\n",
              " '100 달러 만 환전 좀 하 아 주 시 어요 ',\n",
              " '100 달러 만 환전 하 아 주 시 어요 ']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ko_text_list[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqRVz98s2VaB",
        "outputId": "17355452-4614-470e-dccb-4b7a4d5d129f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['777 항공편 은 1 시간 동안 지상 에 머물 게 되 ㅂ니다 ', '777 항공편 은 3 시간 동안 지상 에 있 겠 습니다 ', '1 000 달러 여행자 수표 가 필요 하 ㅂ니다 ', '1 250 원 이 공식 환율 이 ㅂ니다 ', '100 달러 3 장 과 나머지 는 20 달러 권 으로 주 시 ㅂ시오 ', '100 달러 한 장 과 50 달러 4 장 으로 바꾸 어 주 시 겠 어요 ', '100 달러 를 바꾸 어 주 시 겠 어요 ', '100 달러 만 바꾸 어 주 시 어요 ', '100 달러 만 환전 좀 하 아 주 시 어요 ', '100 달러 만 환전 하 아 주 시 어요 ']\n",
            "['Flight 007 will stay on the ground for one hour . ', 'Flight 017 will stay on the ground for three hours . ', \"I need 1,000 dollars in traveler 's checks . \", 'The official exchange rate is around 1,250 Won . ', 'Please give me three hundred dollar bills and twenty dollar bills for the rest . ', 'Can I have one hundred dollar bill and four fifty dollar bills ? ', 'Do you have change for $ 100 ? ', \"I 'd like to change 100 dollars . \", \"I 'd like to change $ 100 . \", 'Change 100 dollars . ']\n",
            "330974\n",
            "330974\n"
          ]
        }
      ],
      "source": [
        "print(ko_text_list[:10])\n",
        "print(full_en_text_list[:10])\n",
        "\n",
        "print(len(ko_text_list))\n",
        "print(len(full_en_text_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjEpQmPE2H7m"
      },
      "source": [
        "## 데이터셋 구축"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V02_VmMLzqW5",
        "outputId": "964b42d6-c997-49c8-ceea-5f72295760cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Collecting aiohttp (from datasets)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.11.0 (from datasets)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Collecting responses<0.19 (from datasets)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 frozenlist-1.3.3 huggingface-hub-0.15.1 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZXPCarC1fj8",
        "outputId": "d58080b1-fe71-4ab0-b6f3-285ccc961fcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'translation'],\n",
            "        num_rows: 330974\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import DatasetDict, Dataset, Features, Value\n",
        "\n",
        "data_dict = {\n",
        "    'id': range(1, len(ko_text_list) + 1),\n",
        "    'translation': [{'ko': ko, 'en': en} for ko, en in zip(ko_text_list, full_en_text_list)]\n",
        "}\n",
        "\n",
        "features = Features({\n",
        "    'id': Value('int32'),\n",
        "    'translation': {'ko': Value('string'), 'en': Value('string')}\n",
        "})\n",
        "\n",
        "raw_datasets = Dataset.from_dict(data_dict, features=features)\n",
        "dataset = DatasetDict({'train': raw_datasets})\n",
        "\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54v_LRYt1yEZ",
        "outputId": "9e050745-e4b3-4d6a-9307-e816c18414a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'translation'],\n",
              "        num_rows: 264779\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'translation'],\n",
              "        num_rows: 16549\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'translation'],\n",
              "        num_rows: 16549\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split_datasets = dataset[\"train\"].train_test_split(train_size=0.8, test_size=0.1, seed=20)\n",
        "\n",
        "dataset[\"train\"] = split_datasets[\"train\"]\n",
        "dataset[\"validation\"] = split_datasets[\"test\"].train_test_split(train_size=0.5, seed=20)[\"train\"]\n",
        "dataset[\"test\"] = split_datasets[\"test\"].train_test_split(train_size=0.5, seed=20)[\"test\"]\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TUmQ9ma2l_2"
      },
      "source": [
        "## 데이터 전처리 (tokenize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "z7XpieH3iBfV",
        "outputId": "cf4635d3-e48b-4d7c-cad7-4a982c2572f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.28.0\n",
            "  Downloading transformers-4.28.0-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.28.0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (3.4)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "Successfully installed tokenizers-0.13.3 transformers-4.28.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.10/dist-packages (4.28.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (4.65.0)\n",
            "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece])\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<=3.20.2 (from transformers[sentencepiece])\n",
            "  Downloading protobuf-3.20.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers[sentencepiece]) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers[sentencepiece]) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (3.4)\n",
            "Installing collected packages: sentencepiece, protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.2 sentencepiece-0.1.99\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install transformers==4.28.0 # PartialState Error를 방지하기 위해 4.28.0 버전 사용\n",
        "!pip install transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346,
          "referenced_widgets": [
            "81909693eb9546baaf806b96471531d9",
            "2a217b3389a2420b830813d061ef5107",
            "934faf4e8b7d4753aa8583e9116cac78",
            "1b529a25bd2f44ddb174ea4823e99628",
            "593b89a6651a4d99b1c128b7865cf7ee",
            "655f930fbaae44328758c0d98c606b10",
            "15147414112e426f87ca21672992703c",
            "d5a35841468043659ba1e9e0c2a8905d",
            "51446f5c62cb48b9932e61af8e64595b",
            "0ceb024d95f14bf7a706fc4cf055b9d9",
            "2e32844d9dfc4e5eaf159f5bfa2d348f",
            "755b0d2e23634d24b589e6a237d08975",
            "2f1b0aad2d6b4a87a2f3a6bc70b1accb",
            "13f4ff50eaff483a864df041ada4020b",
            "88600f3932b943908c280f9917e98536",
            "b0044d9bfa1d404cb2ec31795cd92ce4",
            "9b9e1b05ebab484cb2062827886bf48e",
            "b3b3833148cc432b979d7561248ac538",
            "f0ecc5f06e6a4d6a848d947814aa6e78",
            "ebd8c067a8f14e01af16e38370e35736",
            "e8bda618e03f4c52a45e571c57486bc0",
            "0bc2a7b22b154958bec7a28d61d365d7",
            "d9ffec38df0d48b6bbbdf28f3d637a61",
            "d994430578254a0197b6143ea8083f09",
            "5436f84bf71243d4b36f34b0841a6014",
            "3b8c003317cc4e3cb9f968ffab5e163d",
            "35233df5237a49b899ff76e62c489f69",
            "3358ab6886d349af92e9e2d539e459ea",
            "29a7c193f03f4bb5aae85dccb6e1e8a4",
            "eafe581626b7494cb182539c8aeff261",
            "c7b528ee4ae1497ebf44a6d567beabcd",
            "62b094bf527b41a3bad3572549978cda",
            "45e7230c0e094bff970ed081ba9e7555",
            "8a685d45237848dda21c5637ec3efcfb",
            "1f7441fffc3042d4a704a5e6950cd69c",
            "71f372fd391e4bb9963f5130252632ca",
            "959bed102ee745e093f306f7f89aab67",
            "58de6d7ef3154342a4b2808233fe65ef",
            "2086b335b01c4c36aca1b0ddb1884226",
            "827b351dc4f04c4183f5081f68090850",
            "994381b9c0df446680b72418ca37c15d",
            "5c189bb4880e4d48b9cde20e14625b0c",
            "1e7cce9b7bca466ba8b3ea2f31062ab8",
            "9790020f0ac2421081fdeaa819ca5c6b",
            "3bfb9947c219473cacd845fd5fbcb483",
            "172f654010e3495f8de4b349c32d1030",
            "f4dd739cbdd54cdf8af2ae9c1036e48f",
            "0906ebb3c17f4d178c9b726966c4b2a4",
            "89f47ed7f03840c787b5b46159360354",
            "8e831b4fa9ae4748b43be4164794a4e8",
            "96722b4480854a619b6db7abff72bf6b",
            "9a347dcec7574e659acbcec5934adcf2",
            "2d4b3b1513af4444b2aee91305bd790a",
            "fe35af5cf1f24084913961fdb94dde01",
            "98fa70acaa564fdf875c5ab96c4f27f4"
          ]
        },
        "id": "5HGMv3SO2p2O",
        "outputId": "5a265ba3-b8c3-422c-f7b5-8e70459ff158"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81909693eb9546baaf806b96471531d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "755b0d2e23634d24b589e6a237d08975",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9ffec38df0d48b6bbbdf28f3d637a61",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)olve/main/source.spm:   0%|          | 0.00/842k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a685d45237848dda21c5637ec3efcfb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)olve/main/target.spm:   0%|          | 0.00/813k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3bfb9947c219473cacd845fd5fbcb483",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_checkpoint = \"Helsinki-NLP/opus-mt-ko-en\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxGAtt5lCLyQ",
        "outputId": "f1b485cb-5a9a-4d04-960c-cccbafb778c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('즉석 에서 투표 하 자 ', \"Let 's vote before we speak another word . \")"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['train'][0]['translation']['ko'], dataset['train'][0]['translation']['en']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aGOnST32yvQ"
      },
      "outputs": [],
      "source": [
        "max_src_length = 128\n",
        "max_trg_length = 128\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    src = [ex[\"ko\"] for ex in examples[\"translation\"]]\n",
        "    trg = [ex[\"en\"] for ex in examples[\"translation\"]]\n",
        "    model_inputs = tokenizer(src, text_target=trg, max_length=max_src_length, truncation=True)\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(trg, max_length=max_trg_length, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74,
          "referenced_widgets": [
            "419d640d72b1433cab4e2826583d42f0",
            "1e261fde9dfd4958b90248496e184100",
            "6abe2990c85a4d5d9224ae26a66baa7c",
            "8702814c584e4f8d8231cf8955b8d879",
            "2ab34379c2f946148efdefbd2424f5fb",
            "a618aeb53b4a4736a98ef22a16470ee3",
            "7d0f1726dc474f9cac1d760f9088eeab",
            "bb2612a3541d4cb4b95b61aa27b48058",
            "6593a61c02ef41c5bb0723c80c80d20f",
            "2d0d8173811b40478f537f005dbafb37",
            "44449b95ad0849d2ba12dd2dfee239ca",
            "f712c173ceea4a199333a08dae7b9ef9",
            "f86861517a3342ed83756371de629d76",
            "f182c4290d444b908eb286a81fbfd73c",
            "a85424c7f49e47f0a684eb57410d77cf",
            "a2ff92333a964bc18e2a5ed82337fe82",
            "a450ecdb39714dcf96191e8da6c29dd7",
            "740683ac2b2b4bd78725799cdee50d68",
            "12f9a5e41c7d4da9bfd9088b6d460c4a",
            "729a03dc47a84e4fa3f4d2f6b7fcadca",
            "c83a506fc1eb42d68ae418461542a017",
            "20b7764977784fb7baba261102df15ae",
            "6b66e8b888dd41deaadf79fff701ffa8",
            "9fb5aef435704f7489af713a2ad192c7",
            "2d9e1afbf08f43f09eadad8af4c69cba",
            "adbac29055e34860b649e300435b648e",
            "0016fe2cea244bdba1f604c1dc33333b",
            "9b670bc1174c488eb10701be72fef02a",
            "2fc91f8818a3498ca817f9b5ca0f4fff",
            "ffd02de0ed43436ba53789fac0354e4a",
            "79037ce74dc74a8f94d0c12350b9517f",
            "5052e83bc5304b5686fbef47c503efce",
            "cdbe13de67c542aaae2d048fd160ab61"
          ]
        },
        "id": "VaMsw9na2-_c",
        "outputId": "18ad85b5-7fce-4349-f4ca-11b442920658"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "419d640d72b1433cab4e2826583d42f0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/264779 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3596: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f712c173ceea4a199333a08dae7b9ef9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/16549 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b66e8b888dd41deaadf79fff701ffa8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/16549 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenized_datasets = dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=dataset[\"train\"].column_names,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67bK5FoeDFJb",
        "outputId": "e4ead3d1-e3c4-452e-cda5-9ae9430f5cc2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 264779\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 16549\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 16549\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCwy0eX3D14V"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaTuDbJdEDNJ"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Yr2_ZrtTEByP",
        "outputId": "5a069ec8-9ced-497c-d177-f8c41b9acddd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "78d84fa6f3aa4a1b9ec303e7deac1305",
            "28b6a00f0fa1467e80c7aa8a5dacefa2",
            "d041d3cdb1714815b460d0836c02a356",
            "819015372b3c4433aef6c945d6c41180",
            "9dde7e171fe84292a1e1b86e0a957db6",
            "2f5b233bfe6348ee8d69947086151833",
            "ce2b8553bd9748f0b2a56d5b79f6cfaa",
            "7fcfed82e4434d478af4957506c34204",
            "5fcc663ad0464686a469a03dc1361921",
            "cad84150293e4403a486dfc2449b7701",
            "0a7a2a50fee0442784d84cbe9069c42a",
            "c7e9b57b2e294192a3c8b248f146efcb",
            "0f247e8d6e11442d8b10628b56bdbe8c",
            "53eea7e50bb7425ca3230c5c682ef02d",
            "6d40abd5e8b3467f9027e316154a2b9f",
            "eda62023767a4bcab468eb5605796c17",
            "0f229e690c194d13ad62a7ea4c3e38a2",
            "f04af7256f1a465c86bc8136ce12c2a0",
            "a6bad3685aa84a49a64224c2036b891b",
            "586e0dd781ce4b1eaae18ae7bcc770f4",
            "3dcedf6b71c24a7ba3e1dfe78400bca8",
            "840fb88ebe104bbe8ab283f26b911d4b"
          ]
        },
        "id": "LlbazCuc3Zzj",
        "outputId": "a331b775-91d4-404d-caec-3e74762f5a72"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78d84fa6f3aa4a1b9ec303e7deac1305",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/312M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7e9b57b2e294192a3c8b248f146efcb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsBAnf1h3dQP"
      },
      "source": [
        "## Data Collation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VSDcdea3bmY"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO8Kz7A7msAE",
        "outputId": "9cc51afc-7757-4f2c-fc78-02e3327078f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask', 'labels', 'decoder_input_ids'])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(1, 3)])\n",
        "batch.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a98GnPUJmuD5",
        "outputId": "e23aa3cf-910b-4fe1-975b-c5ba0fa68572"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[   16,  7628,    18,   867,  1220,    49, 53552,  1479,   639,  9079,\n",
              "          1479, 11927,     9,     2,     0],\n",
              "        [  417,   892,     6,     4,  1342,  4416,    61,    31,  2690,     5,\n",
              "             4, 13596,     9,     2,     0]])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch[\"labels\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mR6YD4zHmvX0",
        "outputId": "6cf03ee1-54dd-437e-ea81-2e16b07725bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[65000,    16,  7628,    18,   867,  1220,    49, 53552,  1479,   639,\n",
              "          9079,  1479, 11927,     9,     2],\n",
              "        [65000,   417,   892,     6,     4,  1342,  4416,    61,    31,  2690,\n",
              "             5,     4, 13596,     9,     2]])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch[\"decoder_input_ids\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXNFy5kCmwsd",
        "outputId": "89eab3e9-ea01-460d-8d55-f5f3a8bdae34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[16, 7628, 18, 867, 1220, 49, 53552, 1479, 639, 9079, 1479, 11927, 9, 2, 0]\n",
            "[417, 892, 6, 4, 1342, 4416, 61, 31, 2690, 5, 4, 13596, 9, 2, 0]\n"
          ]
        }
      ],
      "source": [
        "for i in range(1, 3):\n",
        "    print(tokenized_datasets[\"train\"][i][\"labels\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT97NvyVm0mM"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nl-DEAE1m14T",
        "outputId": "b9579adb-34b8-4111-fcf5-369fa407ff43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/118.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2022.10.31)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.8.10)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.22.4)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.2)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-2.7.0 sacrebleu-2.3.1\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pip install sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106,
          "referenced_widgets": [
            "df9b0c6133494b069e7605e57f6844d1",
            "6ac8a7ad0de3488fb101d37f310d640a",
            "d62c73bdd16241648f6d8bd7b8f15295",
            "089f1f2d3a76451783fa105e94629428",
            "d8643eb02eb04e10aa7ae68fb43d4101",
            "340e65dd76fc4afebc09d4f891594397",
            "cc001e1c572044488afbac339b1df944",
            "0c46ea69b4244799b452e0ad129f2ccb",
            "30e955ee933244199cb9073ed8ede70d",
            "cb943ede259f45b9a7981b954edf7ae2",
            "ca5d61e32b89464fb103a3692ce51368"
          ]
        },
        "id": "AF3Mfje8m3he",
        "outputId": "77c32fd9-5670-4bd5-b214-c0e66b5b5645"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a15d7a2cd8c7>:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"sacrebleu\")\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df9b0c6133494b069e7605e57f6844d1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_metric\n",
        "\n",
        "metric = load_metric(\"sacrebleu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jijlQOQnm5yh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    # 모델이 예측 로짓(logits)외에 다른 것을 리턴하는 경우.\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    # -100은 건너뛴다.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # 단순 후처리\n",
        "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
        "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    return {\"bleu\": result[\"score\"]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQLOcgPVFIAF"
      },
      "source": [
        "## Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G8ZzBuc4kcO",
        "outputId": "3f0babd5-1e50-4b05-86cc-433290550d13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.19.0-py3-none-any.whl (219 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.19.0\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBcJ00xU4qo6"
      },
      "outputs": [],
      "source": [
        "import accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qurtzCXRnQiA"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    \"test-trainer\",\n",
        "    evaluation_strategy=\"no\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=3,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbEdr-EA4TXG"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Udv4CgKB-RQk",
        "outputId": "c6bf55fe-46e7-4682-9364-794adfad5a4a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='49647' max='49647' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [49647/49647 1:17:49, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.648400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.380800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.255700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.218000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>1.146700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>1.116500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>1.070600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>1.070100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>1.018900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>1.023200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>1.020700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.984800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.967900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.981300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.966100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.937100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.966400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.919400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.931600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.927600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.901100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.897500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>0.890700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.892400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>0.890700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.905300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>0.872400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>0.879100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>0.882400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>0.857900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15500</td>\n",
              "      <td>0.873600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>0.859200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16500</td>\n",
              "      <td>0.840300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17000</td>\n",
              "      <td>0.765600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17500</td>\n",
              "      <td>0.756100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18000</td>\n",
              "      <td>0.749000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18500</td>\n",
              "      <td>0.757600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19000</td>\n",
              "      <td>0.747500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19500</td>\n",
              "      <td>0.761200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20000</td>\n",
              "      <td>0.746400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20500</td>\n",
              "      <td>0.733800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21000</td>\n",
              "      <td>0.742200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21500</td>\n",
              "      <td>0.737200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22000</td>\n",
              "      <td>0.741900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22500</td>\n",
              "      <td>0.752300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23000</td>\n",
              "      <td>0.747400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23500</td>\n",
              "      <td>0.721900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24000</td>\n",
              "      <td>0.709000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24500</td>\n",
              "      <td>0.737600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25000</td>\n",
              "      <td>0.727600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25500</td>\n",
              "      <td>0.736300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26000</td>\n",
              "      <td>0.729100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26500</td>\n",
              "      <td>0.723400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27000</td>\n",
              "      <td>0.733400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27500</td>\n",
              "      <td>0.732100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28000</td>\n",
              "      <td>0.728500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28500</td>\n",
              "      <td>0.718100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29000</td>\n",
              "      <td>0.729500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29500</td>\n",
              "      <td>0.727100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30000</td>\n",
              "      <td>0.704900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30500</td>\n",
              "      <td>0.714500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31000</td>\n",
              "      <td>0.702800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31500</td>\n",
              "      <td>0.720900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32000</td>\n",
              "      <td>0.719800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32500</td>\n",
              "      <td>0.707100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33000</td>\n",
              "      <td>0.705400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33500</td>\n",
              "      <td>0.666900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34000</td>\n",
              "      <td>0.653500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34500</td>\n",
              "      <td>0.657000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35000</td>\n",
              "      <td>0.650800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35500</td>\n",
              "      <td>0.636400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36000</td>\n",
              "      <td>0.658100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36500</td>\n",
              "      <td>0.638300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37000</td>\n",
              "      <td>0.646000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37500</td>\n",
              "      <td>0.632200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38000</td>\n",
              "      <td>0.646400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38500</td>\n",
              "      <td>0.644600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39000</td>\n",
              "      <td>0.636800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39500</td>\n",
              "      <td>0.642200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40000</td>\n",
              "      <td>0.642600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40500</td>\n",
              "      <td>0.635300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41000</td>\n",
              "      <td>0.636000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41500</td>\n",
              "      <td>0.645800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42000</td>\n",
              "      <td>0.638000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42500</td>\n",
              "      <td>0.638700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43000</td>\n",
              "      <td>0.635700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43500</td>\n",
              "      <td>0.640900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44000</td>\n",
              "      <td>0.629900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44500</td>\n",
              "      <td>0.644200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45000</td>\n",
              "      <td>0.641600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45500</td>\n",
              "      <td>0.641600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46000</td>\n",
              "      <td>0.628900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46500</td>\n",
              "      <td>0.645000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47000</td>\n",
              "      <td>0.641200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47500</td>\n",
              "      <td>0.636400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48000</td>\n",
              "      <td>0.641800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48500</td>\n",
              "      <td>0.629900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49000</td>\n",
              "      <td>0.630100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49500</td>\n",
              "      <td>0.639300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=49647, training_loss=0.7907866114664551, metrics={'train_runtime': 4673.134, 'train_samples_per_second': 169.98, 'train_steps_per_second': 10.624, 'total_flos': 4834814149656576.0, 'train_loss': 0.7907866114664551, 'epoch': 3.0})"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uXpxcnIRlQT"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"./results\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBnN-dsfrgYr"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_t8NaXargYt"
      },
      "outputs": [],
      "source": [
        "# eval_dataset을 test로 설정\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "ERDlXjF9rgYt",
        "outputId": "bb360998-b4d8-423d-9034-6fac1a16d6e6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1035' max='1035' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1035/1035 09:47]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.6830718517303467,\n",
              " 'eval_bleu': 51.02922435564317,\n",
              " 'eval_runtime': 715.3461,\n",
              " 'eval_samples_per_second': 23.134,\n",
              " 'eval_steps_per_second': 1.447}"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.evaluate(max_length=max_trg_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3bQr5NPDvDl"
      },
      "source": [
        "- 여기서 train.evaluate()를 이용해서 Test 할 때는 bleu socre가 약 51 정도로 나옴"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJd5yWefroOW"
      },
      "source": [
        "## pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M1GielaroOp",
        "outputId": "2e4ffa9a-e6f7-4471-c571-b3f4281543a3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "result_model_checkpoint = \"./results\"\n",
        "translator = pipeline(\"translation\", model=result_model_checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol-pzRLor7QF"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hr9cn1z6r7QU"
      },
      "outputs": [],
      "source": [
        "sen_list = [\n",
        "'모든 액체 , 젤 , 에어로졸 등 은 1 커트 짜리 여닫이 투명 봉지 하나 에 넣 어야 하 ㅂ니다 .',\n",
        "'미안 하 지만 , 뒷쪽 아이 들 의 떠들 는 소리 가 커 어서 , 광화문 으로 가 아고 싶 은데 표 를 바꾸 어 주 시 겠 어요 ?',\n",
        "'은행 이 너무 멀 어서 안 되 겠 네요 . 현찰 이 필요 하면 돈 을 훔치 시 어요',\n",
        "'아무래도 분실 하 ㄴ 것 같 으니 분실 신고서 를 작성 하 아야 하 겠 습니다 . 사무실 로 같이 가 시 ㄹ 까요 ?',\n",
        "'부산 에서 코로나 확진자 가 급증 하 아서 병상 이 부족하 아 지자  확진자 20명 을 대구 로 이송하 ㄴ다 .',\n",
        "'변기 가 막히 었 습니다 .',\n",
        "'그 바지 좀 보이 어 주 시 ㅂ시오 . 이거 얼마 에 사 ㄹ 수 있 는 것 이 ㅂ니까 ?',\n",
        "'비 가 오 아서 백화점 으로 가지 말 고 두타 로 가 았 으면 좋 겠 습니다 .',\n",
        "'속 이 안 좋 을 때 는 죽 이나 미음 으로 아침 을 대신 하 ㅂ니다',\n",
        "'문 대통령 은 집단 이익 에서 벗어 나 아 라고 말 하 었 다 .',\n",
        "'이것 좀 먹어 보 ㄹ 몇 일 간 의 시간 을 주 시 어요 .',\n",
        "'이날 개미군단 은 외인 의 물량 을 모두 받 아 내 었 다 .',\n",
        "'통합 우승 의 목표 를 달성하 ㄴ NC 다이노스 나성범 이 메이저리그 진출 이라는 또 다른 꿈 을 향하 어 나아가 ㄴ다 .',\n",
        "'이번 구조 조정 이 제품 을 효과 적 으로 개발 하 고 판매 하 기 위하 ㄴ 회사 의 능력 강화 조처 이 ㅁ 을 이해 하 아 주 시 리라 생각 하 ㅂ니다 .',\n",
        "'요즘 이 프로그램 녹화 하 며 많은 걸 느끼 ㄴ다 ']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWggc_P6r7QU",
        "outputId": "32393d86-8778-417a-8b2b-48cd5a6eae05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "모든 액체 , 젤 , 에어로졸 등 은 1 커트 짜리 여닫이 투명 봉지 하나 에 넣 어야 하 ㅂ니다 .\n",
            "[{'translation_text': 'All liquids , gels , aerosols , and so on must be placed in a single one-centered and clear plastic bag .'}]\n",
            "\n",
            "미안 하 지만 , 뒷쪽 아이 들 의 떠들 는 소리 가 커 어서 , 광화문 으로 가 아고 싶 은데 표 를 바꾸 어 주 시 겠 어요 ?\n",
            "[{'translation_text': \"I 'm sorry , but the noise of the children behind me is loud . I 'd like to go to the Gwanghwamun . Could you change my ticket ?\"}]\n",
            "\n",
            "은행 이 너무 멀 어서 안 되 겠 네요 . 현찰 이 필요 하면 돈 을 훔치 시 어요\n",
            "[{'translation_text': \"I 'm afraid the bank is too far . If you need cash , just steal the money .\"}]\n",
            "\n",
            "아무래도 분실 하 ㄴ 것 같 으니 분실 신고서 를 작성 하 아야 하 겠 습니다 . 사무실 로 같이 가 시 ㄹ 까요 ?\n",
            "[{'translation_text': \"I 'm afraid I 'm afraid I 'm afraid I have to fill out the lost and found form . Would you like to come with me to the office ?\"}]\n",
            "\n",
            "부산 에서 코로나 확진자 가 급증 하 아서 병상 이 부족하 아 지자  확진자 20명 을 대구 로 이송하 ㄴ다 .\n",
            "[{'translation_text': 'In Busan there is a sharp rise in the number of Koronaeongjins , so that 20 people are sure to be transferred to Daegu when the ill condition is insufficient .'}]\n",
            "\n",
            "변기 가 막히 었 습니다 .\n",
            "[{'translation_text': 'The toilet is clogged up .'}]\n",
            "\n",
            "그 바지 좀 보이 어 주 시 ㅂ시오 . 이거 얼마 에 사 ㄹ 수 있 는 것 이 ㅂ니까 ?\n",
            "[{'translation_text': 'Please show me those pants . How much can I buy here ?'}]\n",
            "\n",
            "비 가 오 아서 백화점 으로 가지 말 고 두타 로 가 았 으면 좋 겠 습니다 .\n",
            "[{'translation_text': 'I want to go to Duta instead of to the department store because it is raining .'}]\n",
            "\n",
            "속 이 안 좋 을 때 는 죽 이나 미음 으로 아침 을 대신 하 ㅂ니다\n",
            "[{'translation_text': 'When I feel sick , I take my place in the morning , either to kill or to shrink .'}]\n",
            "\n",
            "문 대통령 은 집단 이익 에서 벗어 나 아 라고 말 하 었 다 .\n",
            "[{'translation_text': \"The President of Munhwa said that we should get rid of the group 's interests .\"}]\n",
            "\n",
            "이것 좀 먹어 보 ㄹ 몇 일 간 의 시간 을 주 시 어요 .\n",
            "[{'translation_text': 'Give me a few days to eat this .'}]\n",
            "\n",
            "이날 개미군단 은 외인 의 물량 을 모두 받 아 내 었 다 .\n",
            "[{'translation_text': 'On this day , antgundan received all the water from the foreign people .'}]\n",
            "\n",
            "통합 우승 의 목표 를 달성하 ㄴ NC 다이노스 나성범 이 메이저리그 진출 이라는 또 다른 꿈 을 향하 어 나아가 ㄴ다 .\n",
            "[{'translation_text': 'The NC Dainosaseongsin , who has achieved the goal of victory reunification , goes on to another dream of major leagues .'}]\n",
            "\n",
            "이번 구조 조정 이 제품 을 효과 적 으로 개발 하 고 판매 하 기 위하 ㄴ 회사 의 능력 강화 조처 이 ㅁ 을 이해 하 아 주 시 리라 생각 하 ㅂ니다 .\n",
            "[{'translation_text': \"I hope you will understand the strengthening of the company 's ability to develop and sell products effectively .\"}]\n",
            "\n",
            "요즘 이 프로그램 녹화 하 며 많은 걸 느끼 ㄴ다 \n",
            "[{'translation_text': 'I feel a lot about recording this program these days .'}]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for sent in sen_list:\n",
        "    print(sent)\n",
        "    print(translator(sent))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiHNxsR_sCVP"
      },
      "source": [
        "## Bleu Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxrhJHLsrgYs",
        "outputId": "a1ddeccb-a97d-47ff-fd20-054475c4e8ca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(result_model_checkpoint)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(result_model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMz8ZhO6Q1aq"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"test\"], batch_size=64, collate_fn=data_collator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-n2xl7nQ5bu"
      },
      "outputs": [],
      "source": [
        "test_dataloader_iter = iter(test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQF_OFFRQ714"
      },
      "outputs": [],
      "source": [
        "test_batch = next(test_dataloader_iter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW7NlojkQ9F5",
        "outputId": "62d317ab-1825-4d83-861c-44813cdcdf07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask', 'labels', 'decoder_input_ids'])"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_batch.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wu2M9Tr8sCVQ"
      },
      "outputs": [],
      "source": [
        "test_input = { key: test_batch[key] for key in ('input_ids', 'attention_mask') }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkQy4PLlsCVQ"
      },
      "outputs": [],
      "source": [
        "english = model.generate(\n",
        "    **test_input,\n",
        "    max_length=max_trg_length,\n",
        "    num_beams=5,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6ufTu3MRHev"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "labels =  np.where(test_batch.labels != -100, test_batch.labels, tokenizer.pad_token_id)\n",
        "kor_sents = tokenizer.batch_decode(test_batch.input_ids, skip_special_tokens=True) # 원래 문장 리스트\n",
        "references = tokenizer.batch_decode(labels, skip_special_tokens=True) # 번역 정답 문장 리스트\n",
        "preds = tokenizer.batch_decode(english, skip_special_tokens=True ) # 번역한 리스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duo3UkUaRL0K",
        "outputId": "8fb2a741-f146-4930-9fa3-b9af1481c34c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Korean   : ▁그럼▁다른▁데▁가 아서▁먹 어야▁하 겠 네요\n",
            "Reference : Then I must eat somewhere else!\n",
            "Translated: Well, maybe we should go somewhere else to eat.\n",
            "\n",
            "\n",
            "Korean   : ▁이것▁은▁얼마▁이 죠\n",
            "Reference : How much does it cost?\n",
            "Translated: How much is this?\n",
            "\n",
            "\n",
            "Korean   : ▁거리▁가▁보이▁는▁방▁이▁면▁좋 겠 네요\n",
            "Reference : I 'd like a room looking out on the street.\n",
            "Translated: I 'd like a room with a view of the street.\n",
            "\n",
            "\n",
            "Korean   : ▁부르▁시 었 어요\n",
            "Reference : You wanted to see me?\n",
            "Translated: Did you call me?\n",
            "\n",
            "\n",
            "Korean   : ▁변명▁하 려고▁하▁지▁말▁시 어요\n",
            "Reference : Don't try and explain it away.\n",
            "Translated: Don't make excuses.\n",
            "\n",
            "\n",
            "Korean   : ▁미국▁에서▁결혼▁하▁시 ᄅ▁것▁이 ᄇ니까\n",
            "Reference : Will you get married in America?\n",
            "Translated: Are you going to get married in America?\n",
            "\n",
            "\n",
            "Korean   : ▁너▁농담▁하▁니\n",
            "Reference : You're kidding?\n",
            "Translated: Are you kidding?\n",
            "\n",
            "\n",
            "Korean   : ▁저▁는▁중국▁베이징▁에서▁오 았 어요▁당신▁은▁요\n",
            "Reference : I'm from Beijing, China. How about you?\n",
            "Translated: I'm from Beijing, China. And you?\n",
            "\n",
            "\n",
            "Korean   : ▁우리▁는▁런던▁행연결▁비행기▁편▁을▁타 려고▁내리 었 어요\n",
            "Reference : We're having a layover for our connection to London.\n",
            "Translated: We got off on a connecting flight to London.\n",
            "\n",
            "\n",
            "Korean   : ▁어머니▁에게▁안부▁전하▁아▁주▁시 어요\n",
            "Reference : Say hello to your mother.\n",
            "Translated: Please say hello to your mother.\n",
            "\n",
            "\n",
            "Korean   : ▁상대방▁이▁나▁의▁제안▁을▁거절▁하▁면▁나▁는▁일전▁을▁불사▁하 겠▁다\n",
            "Reference : If the other party rejects my proposal, I shall not hesitate to fight.\n",
            "Translated: If my party turns down my offer, I 'll lose my head.\n",
            "\n",
            "\n",
            "Korean   : ▁그것▁은▁그▁교회▁바로▁옆▁에▁있 어요\n",
            "Reference : It's next to the church.\n",
            "Translated: It's next to the church.\n",
            "\n",
            "\n",
            "Korean   : ▁일반▁서비스▁로▁하▁아▁주▁시 어요\n",
            "Reference : I 'd like the regular service, please.\n",
            "Translated: Regular service, please.\n",
            "\n",
            "\n",
            "Korean   : ▁새▁아파트▁구하 았 어요\n",
            "Reference : Have you found a new apartment yet?\n",
            "Translated: Did you find a new apartment?\n",
            "\n",
            "\n",
            "Korean   : ▁당신▁은▁어떻 어요\n",
            "Reference : What about you?\n",
            "Translated: How about you?\n",
            "\n",
            "\n",
            "Korean   : ▁비행장▁으로▁데리▁어다▁주▁시 어요\n",
            "Reference : Take me to the airport.\n",
            "Translated: Please take me to the airport.\n",
            "\n",
            "\n",
            "Korean   : ▁아뇨▁하지만▁잠깐▁생각▁하▁아▁보 ᄅ게요\n",
            "Reference : No, but I 'll give it some thought.\n",
            "Translated: No, but I 'll think about it for a moment.\n",
            "\n",
            "\n",
            "Korean   : ▁저▁의▁이름▁은▁존▁커▁이 ᄇ니다▁신용▁카드▁번호▁가▁필요▁하▁시▁ᄂ▁가요\n",
            "Reference : My name is John Kauh. Do you need my credit card number?\n",
            "Translated: My name is John Keun. Do you need a credit card number?\n",
            "\n",
            "\n",
            "Korean   : ▁구암 서원▁까지▁는▁얼마나▁걸리▁나요\n",
            "Reference : How long does it take to get to the Guamseowon?\n",
            "Translated: How long does it take to get to the Guamseowon?\n",
            "\n",
            "\n",
            "Korean   : ▁창가▁쪽▁자리▁로▁안내▁하▁아▁주▁시 어요\n",
            "Reference : Can I take a seat by the window?\n",
            "Translated: Please guide me to the window seat.\n",
            "\n",
            "\n",
            "Korean   : ▁항공편▁으로▁좀▁부치▁어▁주▁시 어요\n",
            "Reference : Please send it by air.\n",
            "Translated: Please send it by airmail.\n",
            "\n",
            "\n",
            "Korean   : ▁한국▁의▁대학교▁에서▁저▁의▁분야▁를▁가르치▁고▁연구▁하▁며 공헌▁하▁고▁싶 습니다\n",
            "Reference : I want to dedicate myself to teaching and researching my areas in a university in Korea.\n",
            "Translated: I 'd like to teach, study and make a contribution to my field at the university in Korea.\n",
            "\n",
            "\n",
            "Korean   : 한국어▁잡지▁있 을까요\n",
            "Reference : Do you have any Korean magazines?\n",
            "Translated: Do you have any Korean magazines?\n",
            "\n",
            "\n",
            "Korean   : ▁양쯔강익스프레스▁항공▁이 ᄇ니다▁무엇▁을▁돕▁아▁드리 ᄅ 까요\n",
            "Reference : Yangtze River Express. How can I help you?\n",
            "Translated: Yangtze River Express. How can I help you?\n",
            "\n",
            "\n",
            "Korean   : ▁점수▁가 1▁대 0▁이 ᄇ니다\n",
            "Reference : The score is one, zero.\n",
            "Translated: The score is one to zero.\n",
            "\n",
            "\n",
            "Korean   : ▁지금▁비▁어▁있▁는▁것▁ᄂ▁스위트룸▁뿐▁이 ᄇ니다\n",
            "Reference : The only room available at the moment is a suite.\n",
            "Translated: The only room available now is a suite.\n",
            "\n",
            "\n",
            "Korean   : ▁당신▁비판▁은▁도▁가 지나치▁는▁것▁같▁아\n",
            "Reference : You're going a little too far with your criticism.\n",
            "Translated: I think your criticism is too far.\n",
            "\n",
            "\n",
            "Korean   : ▁중국▁으로▁수신▁이▁ᄂ▁지불▁로▁국제▁통화▁를▁하▁고▁싶▁은데요\n",
            "Reference : I want to make an overseas collect call to China.\n",
            "Translated: I want to make an overseas collect call to China.\n",
            "\n",
            "\n",
            "Korean   : 즐겁▁ᄂ▁하루▁가▁되▁시 어요\n",
            "Reference : Have a nice day.\n",
            "Translated: Have a nice day.\n",
            "\n",
            "\n",
            "Korean   : ▁맡기 ᄅ▁짐▁이▁있▁나요\n",
            "Reference : Do you have any luggage to check?\n",
            "Translated: Do you have any baggage to check?\n",
            "\n",
            "\n",
            "Korean   : 237▁호실▁을▁연결▁하▁아▁주▁시 어요\n",
            "Reference : Would you connect me to room 237?\n",
            "Translated: Could you connect me to room 237?\n",
            "\n",
            "\n",
            "Korean   : ▁취미▁는▁뭐 죠\n",
            "Reference : What are your hobbies?\n",
            "Translated: What's your hobby?\n",
            "\n",
            "\n",
            "Korean   : 싱가포르▁의▁국가▁번호▁는▁몇▁번▁이 ᄇ니까\n",
            "Reference : What's the international phone code for Singapore?\n",
            "Translated: What's the country code for Singapore?\n",
            "\n",
            "\n",
            "Korean   : ▁메이호텔▁에서▁투숙▁하 ᄅ▁예정▁이 ᄇ니다\n",
            "Reference : I 'll be staying at Hotel Mai.\n",
            "Translated: I 'll be staying at Hotel Mai.\n",
            "\n",
            "\n",
            "Korean   : ▁너▁는▁컴퓨터▁게임▁을 좋아하▁니\n",
            "Reference : Do you like computer games?\n",
            "Translated: Do you like computer games?\n",
            "\n",
            "\n",
            "Korean   : ▁지하철▁표▁는▁어디▁서▁사▁야▁하▁나요\n",
            "Reference : Where can I get a ticket?\n",
            "Translated: Where can I buy a subway ticket?\n",
            "\n",
            "\n",
            "Korean   : ▁한국통신박물관▁으로▁가 려면▁어느▁역▁에서▁내리 어야▁하 ᄇ니까\n",
            "Reference : I 'd like to go to the Hanguktongsinbangmulgwan. Which subway station should I get off at?\n",
            "Translated: I 'd like to go to the Hangukcheongbangmulgwan. Which subway station should I get off at?\n",
            "\n",
            "\n",
            "Korean   : 댈러스▁에서▁가▁는▁것▁ᄂ▁없▁나요\n",
            "Reference : Isn't there any flight from Dallas?\n",
            "Translated: Isn't there any flight from Dallas?\n",
            "\n",
            "\n",
            "Korean   : ▁이▁길▁로▁가▁면▁양재천▁이▁나옵 니까\n",
            "Reference : Does this road go to Yangjaecheon?\n",
            "Translated: Does this road go to Yangjaecheon?\n",
            "\n",
            "\n",
            "Korean   : ▁심천▁까지▁가▁는▁편도▁표 1▁장▁주▁시 어요\n",
            "Reference : A one way ticket to Simcheon, please.\n",
            "Translated: One one way ticket to Simcheon, please.\n",
            "\n",
            "\n",
            "Korean   : ▁로댕 갤러리▁는▁꼭▁들르▁어▁보▁시 어요\n",
            "Reference : Don't miss the Rodaenggaelleori.\n",
            "Translated: Don't miss the Rodaenggaelleori.\n",
            "\n",
            "\n",
            "Korean   : ▁성함▁을▁말씀▁하▁아▁주▁시 겠 어요\n",
            "Reference : Could you give me your name?\n",
            "Translated: May I have your name, please?\n",
            "\n",
            "\n",
            "Korean   : ▁그럼▁찍▁으세▁요▁준비▁되 었 습니다\n",
            "Reference : Then, go ahead, take it. I'm ready.\n",
            "Translated: Well, take it. It's ready.\n",
            "\n",
            "\n",
            "Korean   : ▁비디오▁화질▁을▁어떻▁게▁조절▁하▁나요\n",
            "Reference : How do you adjust the video quality?\n",
            "Translated: How do you adjust the video quality?\n",
            "\n",
            "\n",
            "Korean   : ▁운현궁▁에서▁자유▁시간▁을▁가집 니까\n",
            "Reference : Do we have free time at the Unhyeongung?\n",
            "Translated: Do we have free time at the Unhyeongung?\n",
            "\n",
            "\n",
            "Korean   : ▁코오롱▁세이브플라자▁까지▁어떻▁게▁가▁면▁되▁는▁거▁이 죠\n",
            "Reference : How do I get to Koorong Seibeupeullaja?\n",
            "Translated: How can I get to the Koolongseubeopeullaja?\n",
            "\n",
            "\n",
            "Korean   : 습도▁가▁굉장히▁높 군요\n",
            "Reference : It's very humid.\n",
            "Translated: The humidity is very high.\n",
            "\n",
            "\n",
            "Korean   : ▁매일▁아침 7▁시 30▁분▁부터▁두▁시간▁동안▁이▁에요\n",
            "Reference : They're at 7:30 every morning, and last for two hours.\n",
            "Translated: From 7:30 a.m. every morning, for two hours.\n",
            "\n",
            "\n",
            "Korean   : ▁이것▁은▁어떻▁게▁하 아서▁먹 어요\n",
            "Reference : How do you eat this?\n",
            "Translated: How do I eat this?\n",
            "\n",
            "\n",
            "Korean   : ▁롯데 월드▁에▁구경▁가▁고▁싶▁은데요\n",
            "Reference : I want to go to the Rotdewoldeu.\n",
            "Translated: I want to go to the Rotdewoldeu.\n",
            "\n",
            "\n",
            "Korean   : ▁올라가▁요▁아니▁면▁내려가▁요\n",
            "Reference : Up, or down?\n",
            "Translated: Going up or down?\n",
            "\n",
            "\n",
            "Korean   : 요금표▁를▁보 ᄅ▁수▁있 습니까\n",
            "Reference : Can I see list of your rates?\n",
            "Translated: Can I see a list of the rates?\n",
            "\n",
            "\n",
            "Korean   : ▁나▁를▁잊▁지▁말▁시 어요\n",
            "Reference : Don't forget me.\n",
            "Translated: Don't forget me.\n",
            "\n",
            "\n",
            "Korean   : ▁오늘▁점심▁은▁메드포갈릭여의점▁에서▁먹 었 으면▁좋 겠 는데요\n",
            "Reference : I think we should go to the Medeupogallingnyeouijeom for lunch today.\n",
            "Translated: I think we should go to the Medeupogallikuijeom for lunch today.\n",
            "\n",
            "\n",
            "Korean   : ▁이▁우유▁가▁상하 았 어요\n",
            "Reference : This milk has gone bad.\n",
            "Translated: This milk has gone bad.\n",
            "\n",
            "\n",
            "Korean   : ▁오늘▁밤▁여기▁서▁지내 ᄅ▁수▁있 을까요\n",
            "Reference : May I stay here tonight?\n",
            "Translated: Can I stay here tonight?\n",
            "\n",
            "\n",
            "Korean   : ▁훌륭▁하▁아\n",
            "Reference : That's great.\n",
            "Translated: That's great.\n",
            "\n",
            "\n",
            "Korean   : ▁좋 습니다▁끝나 았 습니다▁가▁시▁어도▁좋 습니다\n",
            "Reference : O.K. That's all. You may go now.\n",
            "Translated: O.K. It's over. You may go now.\n",
            "\n",
            "\n",
            "Korean   : ▁굽▁이▁낮▁은▁것 ᄅ▁로▁검은색▁가죽▁이▁요\n",
            "Reference : Black leather with a low heel.\n",
            "Translated: Black leather with a low heel.\n",
            "\n",
            "\n",
            "Korean   : ▁나▁는▁그▁의▁제안▁이 타당▁하▁다고▁생각▁하 ᄇ니다\n",
            "Reference : I think his recommendation is valid.\n",
            "Translated: I think his proposal is valid.\n",
            "\n",
            "\n",
            "Korean   : ▁유나이티드▁항공▁비행기▁의▁짐▁찾▁는▁곳▁이▁어디 죠\n",
            "Reference : Where is the baggage claim area for the United Airlines flight?\n",
            "Translated: Where is the baggage claim area for the United Airlines flight?\n",
            "\n",
            "\n",
            "Korean   : ▁여보세요▁이란항공▁맞▁나요\n",
            "Reference : Hello. Is this Iran Air?\n",
            "Translated: Hello. Is this Iran Air?\n",
            "\n",
            "\n",
            "Korean   : ▁여기▁서▁얼마나▁멀 죠\n",
            "Reference : How far is it from here?\n",
            "Translated: How far is it from here?\n",
            "\n",
            "\n",
            "Korean   : ▁거기▁서▁수상▁스키▁를▁타 ᄅ▁수▁있 습니까\n",
            "Reference : Can I do water-skiing there?\n",
            "Translated: Can I water-ski there?\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 번역 결과 출력\n",
        "for s in zip(kor_sents, references, preds):\n",
        "    print('Korean   :', s[0])\n",
        "    print('Reference :', s[1])\n",
        "    print('Translated:', s[2])\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGkF9dFt-W7z",
        "outputId": "470f8352-fb89-4823-dff2-048bae0f6648"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bleu': 58.85482443144882}"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compute_metrics((english, labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWytn83oD6EF"
      },
      "source": [
        "- 직접 test_dataloader를 배치사이즈 64로 만든 후, model.generate를 통해 번역 문장을 생성한 뒤 compute_metrics 함수로 bleu score를 구하면 약 59 정도가 나옴"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2vKcVBhELbo"
      },
      "source": [
        "# 2. KETI_AIR_Downstream_long_ke_t5_base_translation_aihub_ko2en"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3y3PUybEdop"
      },
      "source": [
        "- 데이터셋 구축 단계까지는 위의 코드와 동일함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSFWDjKSEV-T"
      },
      "source": [
        "## 드라이브 마운트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eesc2fxgEV-T",
        "outputId": "971904db-17f2-42db-c879-1145a1e8e0ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2AEpQKSEV-T"
      },
      "source": [
        "## 파일 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gB15rC_EEV-T"
      },
      "outputs": [],
      "source": [
        "PATH = \"/content/drive/MyDrive/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b78VJT7eEV-T"
      },
      "outputs": [],
      "source": [
        "ko_path = PATH+\"ko-en.ko.parse\"\n",
        "en_path = PATH+\"ko-en.en.parse.syn\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWm_04HfEV-U"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asQEps9WEV-U"
      },
      "outputs": [],
      "source": [
        "ko_lines = \"\"\n",
        "with open(ko_path, \"r\") as ko_file:\n",
        "    for line in ko_file.readlines():\n",
        "        ko_lines += line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOejowvmEV-U"
      },
      "outputs": [],
      "source": [
        "with open(en_path, \"r\") as en_file:\n",
        "    en_lines = en_file.readlines()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "je0DPNUtEV-U"
      },
      "source": [
        "## 데이터 전처리 (깔끔한 문장의 리스트로 만들기)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CFDoiHPEV-U"
      },
      "outputs": [],
      "source": [
        "from nltk import Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqsOV0W5EV-U"
      },
      "outputs": [],
      "source": [
        "# nltk의 Tree 모듈을 사용하여 필요한 정보 추출\n",
        "full_en_text_list = []\n",
        "for line in en_lines:\n",
        "    sent = \"\"\n",
        "    t = Tree.fromstring(line)\n",
        "    for token in t.leaves():\n",
        "      sent += token + ' '\n",
        "    full_en_text_list.append(sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwywrZghEV-U",
        "outputId": "824eff31-bf4d-4ce4-bf8f-f2ef77993333"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Flight 007 will stay on the ground for one hour . ',\n",
              " 'Flight 017 will stay on the ground for three hours . ',\n",
              " \"I need 1,000 dollars in traveler 's checks . \",\n",
              " 'The official exchange rate is around 1,250 Won . ',\n",
              " 'Please give me three hundred dollar bills and twenty dollar bills for the rest . ',\n",
              " 'Can I have one hundred dollar bill and four fifty dollar bills ? ',\n",
              " 'Do you have change for $ 100 ? ',\n",
              " \"I 'd like to change 100 dollars . \",\n",
              " \"I 'd like to change $ 100 . \",\n",
              " 'Change 100 dollars . ']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "full_en_text_list[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MdqqGKpEV-U",
        "outputId": "03b0bdab-96a7-47b8-acef-12cbdcad05d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<id 1>',\n",
              " '<sent 1>',\n",
              " '1\\t2\\tNP\\t777/SN',\n",
              " '2\\t6\\tNP_SBJ\\t항공편/NNG|은/JX',\n",
              " '3\\t4\\tNP\\t1/SN|시간/NNG',\n",
              " '4\\t6\\tNP_AJT\\t동안/NNG',\n",
              " '5\\t6\\tNP_AJT\\t지상/NNG|에/JKB',\n",
              " '6\\t7\\tVP\\t머물/VV|게/EC',\n",
              " '7\\t0\\tVP\\t되/VV|ㅂ니다/EF|./SF',\n",
              " '</sent>',\n",
              " '']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 한 문장씩 나눈 리스트 만들기\n",
        "ko_list = ko_lines.split(\"</id>\")\n",
        "for i in range(len(ko_list)):\n",
        "    ko_list[i] = ko_list[i].split(\"\\n\")\n",
        "\n",
        "ko_list[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJM--cu6EV-U"
      },
      "outputs": [],
      "source": [
        "# 필요한 정보만 추출\n",
        "import re\n",
        "\n",
        "pattern = r\"[가-힣ㄱ-ㅎ]+|[0-9]+(?=\\/SN)\"\n",
        "\n",
        "for i in range(len(ko_list)):\n",
        "    for j in range(len(ko_list[i])):\n",
        "        ko_list[i][j] = re.findall(pattern, ko_list[i][j])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Jd1XYOhEV-U",
        "outputId": "d2832b13-64c0-4181-94a6-7c0ffa7e0755"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[[],\n",
              "  [],\n",
              "  ['777'],\n",
              "  ['항공편', '은'],\n",
              "  ['1', '시간'],\n",
              "  ['동안'],\n",
              "  ['지상', '에'],\n",
              "  ['머물', '게'],\n",
              "  ['되', 'ㅂ니다'],\n",
              "  [],\n",
              "  []],\n",
              " [[],\n",
              "  [],\n",
              "  [],\n",
              "  [],\n",
              "  ['777'],\n",
              "  ['항공편', '은'],\n",
              "  ['3', '시간'],\n",
              "  ['동안'],\n",
              "  ['지상', '에'],\n",
              "  ['있', '겠', '습니다'],\n",
              "  [],\n",
              "  []],\n",
              " [[],\n",
              "  [],\n",
              "  [],\n",
              "  [],\n",
              "  ['1', '000', '달러'],\n",
              "  ['여행자', '수표', '가'],\n",
              "  ['필요', '하', 'ㅂ니다'],\n",
              "  [],\n",
              "  []],\n",
              " [[], [], [], [], ['1', '250', '원', '이'], ['공식'], ['환율', '이', 'ㅂ니다'], [], []],\n",
              " [[],\n",
              "  [],\n",
              "  [],\n",
              "  [],\n",
              "  ['100', '달러'],\n",
              "  ['3', '장', '과'],\n",
              "  ['나머지', '는'],\n",
              "  ['20', '달러', '권', '으로'],\n",
              "  ['주', '시', 'ㅂ시오'],\n",
              "  [],\n",
              "  []],\n",
              " [[],\n",
              "  [],\n",
              "  [],\n",
              "  [],\n",
              "  ['100', '달러'],\n",
              "  ['한'],\n",
              "  ['장', '과'],\n",
              "  ['50', '달러'],\n",
              "  ['4', '장', '으로'],\n",
              "  ['바꾸', '어'],\n",
              "  ['주', '시', '겠', '어요'],\n",
              "  [],\n",
              "  []],\n",
              " [[],\n",
              "  [],\n",
              "  [],\n",
              "  [],\n",
              "  ['100', '달러', '를'],\n",
              "  ['바꾸', '어'],\n",
              "  ['주', '시', '겠', '어요'],\n",
              "  [],\n",
              "  []],\n",
              " [[], [], [], [], ['100', '달러', '만'], ['바꾸', '어'], ['주', '시', '어요'], [], []],\n",
              " [[],\n",
              "  [],\n",
              "  [],\n",
              "  [],\n",
              "  ['100', '달러', '만'],\n",
              "  ['환전'],\n",
              "  ['좀'],\n",
              "  ['하', '아'],\n",
              "  ['주', '시', '어요'],\n",
              "  [],\n",
              "  []],\n",
              " [[],\n",
              "  [],\n",
              "  [],\n",
              "  [],\n",
              "  ['100', '달러', '만'],\n",
              "  ['환전', '하', '아'],\n",
              "  ['주', '시', '어요'],\n",
              "  [],\n",
              "  []]]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ko_list[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0XUvNEFEV-U"
      },
      "outputs": [],
      "source": [
        "# 문장으로 만들어서 리스트에 넣어주기\n",
        "ko_text_list = []\n",
        "\n",
        "for i in range(len(ko_list)-1): # id로 split 해서 1개 추가로 생긴 부분 빼줌\n",
        "    full_sent = \"\"\n",
        "    for j in range(len(ko_list[i])):\n",
        "        if ko_list[i][j]:\n",
        "            for token in ko_list[i][j]:\n",
        "                full_sent += token + ' '\n",
        "\n",
        "    ko_text_list.append(full_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDhr1MGeEV-U",
        "outputId": "eabfc6ca-e280-47b4-cf34-a91033707a38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['777 항공편 은 1 시간 동안 지상 에 머물 게 되 ㅂ니다 ',\n",
              " '777 항공편 은 3 시간 동안 지상 에 있 겠 습니다 ',\n",
              " '1 000 달러 여행자 수표 가 필요 하 ㅂ니다 ',\n",
              " '1 250 원 이 공식 환율 이 ㅂ니다 ',\n",
              " '100 달러 3 장 과 나머지 는 20 달러 권 으로 주 시 ㅂ시오 ',\n",
              " '100 달러 한 장 과 50 달러 4 장 으로 바꾸 어 주 시 겠 어요 ',\n",
              " '100 달러 를 바꾸 어 주 시 겠 어요 ',\n",
              " '100 달러 만 바꾸 어 주 시 어요 ',\n",
              " '100 달러 만 환전 좀 하 아 주 시 어요 ',\n",
              " '100 달러 만 환전 하 아 주 시 어요 ']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ko_text_list[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Irl3zmxaEV-U",
        "outputId": "df78a97f-160a-4435-ddd7-348d2dea4b50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['777 항공편 은 1 시간 동안 지상 에 머물 게 되 ㅂ니다 ', '777 항공편 은 3 시간 동안 지상 에 있 겠 습니다 ', '1 000 달러 여행자 수표 가 필요 하 ㅂ니다 ', '1 250 원 이 공식 환율 이 ㅂ니다 ', '100 달러 3 장 과 나머지 는 20 달러 권 으로 주 시 ㅂ시오 ', '100 달러 한 장 과 50 달러 4 장 으로 바꾸 어 주 시 겠 어요 ', '100 달러 를 바꾸 어 주 시 겠 어요 ', '100 달러 만 바꾸 어 주 시 어요 ', '100 달러 만 환전 좀 하 아 주 시 어요 ', '100 달러 만 환전 하 아 주 시 어요 ']\n",
            "['Flight 007 will stay on the ground for one hour . ', 'Flight 017 will stay on the ground for three hours . ', \"I need 1,000 dollars in traveler 's checks . \", 'The official exchange rate is around 1,250 Won . ', 'Please give me three hundred dollar bills and twenty dollar bills for the rest . ', 'Can I have one hundred dollar bill and four fifty dollar bills ? ', 'Do you have change for $ 100 ? ', \"I 'd like to change 100 dollars . \", \"I 'd like to change $ 100 . \", 'Change 100 dollars . ']\n",
            "330974\n",
            "330974\n"
          ]
        }
      ],
      "source": [
        "print(ko_text_list[:10])\n",
        "print(full_en_text_list[:10])\n",
        "\n",
        "print(len(ko_text_list))\n",
        "print(len(full_en_text_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ME-sMpJKEV-U"
      },
      "source": [
        "## 데이터셋 구축"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16Ctjre4EV-U",
        "outputId": "8c1d9b63-51ef-416a-a5fb-f3c51564c297"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Collecting aiohttp (from datasets)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.11.0 (from datasets)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Collecting responses<0.19 (from datasets)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 frozenlist-1.3.3 huggingface-hub-0.15.1 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuFDcWuvEV-U",
        "outputId": "a27bf723-c3f6-4911-a3c7-51b8adea9afd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'translation'],\n",
            "        num_rows: 330974\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import DatasetDict, Dataset, Features, Value\n",
        "\n",
        "data_dict = {\n",
        "    'id': range(1, len(ko_text_list) + 1),\n",
        "    'translation': [{'ko': ko, 'en': en} for ko, en in zip(ko_text_list, full_en_text_list)]\n",
        "}\n",
        "\n",
        "features = Features({\n",
        "    'id': Value('int32'),\n",
        "    'translation': {'ko': Value('string'), 'en': Value('string')}\n",
        "})\n",
        "\n",
        "raw_datasets = Dataset.from_dict(data_dict, features=features)\n",
        "dataset = DatasetDict({'train': raw_datasets})\n",
        "\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qi_hSkBnEV-U",
        "outputId": "194c902e-4838-43ae-a5de-59d1212ce761"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'translation'],\n",
              "        num_rows: 264779\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'translation'],\n",
              "        num_rows: 16549\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'translation'],\n",
              "        num_rows: 16549\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split_datasets = dataset[\"train\"].train_test_split(train_size=0.8, test_size=0.1, seed=20)\n",
        "\n",
        "dataset[\"train\"] = split_datasets[\"train\"]\n",
        "dataset[\"validation\"] = split_datasets[\"test\"].train_test_split(train_size=0.5, seed=20)[\"train\"]\n",
        "dataset[\"test\"] = split_datasets[\"test\"].train_test_split(train_size=0.5, seed=20)[\"test\"]\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3djK0HtHEV-V"
      },
      "source": [
        "## 데이터 전처리 (tokenize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TcLi_AsiEV-V",
        "outputId": "b430303e-1299-4566-f27e-d6ea4bee37df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.28.0\n",
            "  Downloading transformers-4.28.0-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.28.0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (3.4)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "Successfully installed tokenizers-0.13.3 transformers-4.28.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.10/dist-packages (4.28.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (4.65.0)\n",
            "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece])\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<=3.20.2 (from transformers[sentencepiece])\n",
            "  Downloading protobuf-3.20.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers[sentencepiece]) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers[sentencepiece]) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (3.4)\n",
            "Installing collected packages: sentencepiece, protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.2 sentencepiece-0.1.99\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install transformers==4.28.0 # PartialState Error를 방지하기 위해 4.28.0 버전 사용\n",
        "!pip install transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201,
          "referenced_widgets": [
            "1b38c8b8d782447eb7eab6daaa19b8e1",
            "abf932ed258b4bf98448f70a27dc7221",
            "7bfa26849095486cb86e9d278e30ad80",
            "0a654dd0c8a94113b8e7d09521fd7cce",
            "aef215a7453a4eba8814ec53b5a00648",
            "581f6d819841417da9f25761446d4af9",
            "bbad4e44bf1e4c9f89a886502748e2ae",
            "1a8fe47b046b484d88005f8cc285609f",
            "b9131f9dbf074b818a20e721c1b12d6c",
            "5a50e426921b4bccb7aeb7d3318159bc",
            "e92a386682fb457aa1b5c42e7148bdad",
            "56f1a65d6b1e44e6ba28c67ebaa72587",
            "e0f665e4ab4f4f4d8912d6218785e81c",
            "cda1ccee76c444f5bf6e7a702166a940",
            "d769f3447ce94a0fb4bbb728e50043f6",
            "b8d1dbb578624ccbbe197c72eebf1509",
            "f977052f13594945ac87a84b17ce1a67",
            "ff681f82c86d47e1b2cb1e76bb6c4438",
            "324bab37b86a430e8099c10ca9c76ee7",
            "6c385c6bebc74e21bdc3da3af9b02196",
            "6ae915ad321748afb678f35fac6cb1fa",
            "1a376c30b1564218a7c34483d5e63abe",
            "9814a27fb4ed43f0ae6b15ebde17a3ba",
            "300a4e79817a459a8ccc0567ab434fc9",
            "1a053f82ccac41a1b1044bad80470907",
            "76359166f0ed4dbeb8a3bbae77c5f586",
            "abc178b2d67f4562b9693d1658f1c7ce",
            "bf4d3f418d3743ccaafc40ede6597f76",
            "62501e24a7c8401b8c10de168e53fdd0",
            "5513568d1f75468b9142b6e910fc2662",
            "7dfa883fceaf470cbc8fcd8956d2a398",
            "456a85df43f047578ff36619ebeaeb85",
            "c9fc14aeab7a45fbb775185219e01745",
            "0df0254eb48f454396fc8f1e61295c21",
            "60e30d078dc146ba8bc14dd379a1a71c",
            "c811f605eb6a4e2b90431735907583a0",
            "e9cf0cfef6de4d798507ad63f82d1476",
            "e47956d0936148538034d71f80e177f9",
            "65f90125e14e431aaed66392a468123f",
            "8bf5e7758c56449d8b530c4e11d257c1",
            "32eecf4cefe047d1a32a2ec5b6cfb691",
            "6fa885cb4482478284c8021289a245f3",
            "3ba7674dbd8d4645bc3c6a2f27c60831",
            "8c2b05726d1c4938976b8b0a9979bc24"
          ]
        },
        "id": "Y7-LHi5eEV-V",
        "outputId": "099065ee-df26-468e-9399-0f0e2c90f00e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b38c8b8d782447eb7eab6daaa19b8e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56f1a65d6b1e44e6ba28c67ebaa72587",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading spiece.model:   0%|          | 0.00/1.59M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9814a27fb4ed43f0ae6b15ebde17a3ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/4.17M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0df0254eb48f454396fc8f1e61295c21",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.22k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_checkpoint = \"KETI-AIR-Downstream/long-ke-t5-base-translation-aihub-ko2en\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU7ak8O3EV-V",
        "outputId": "3632096e-31c9-4f71-8c7b-49a62ed5bc39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('즉석 에서 투표 하 자 ', \"Let 's vote before we speak another word . \")"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['train'][0]['translation']['ko'], dataset['train'][0]['translation']['en']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4EClwiBEV-V"
      },
      "outputs": [],
      "source": [
        "max_src_length = 64\n",
        "max_trg_length = 64\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    src = [ex[\"ko\"] for ex in examples[\"translation\"]]\n",
        "    trg = [ex[\"en\"] for ex in examples[\"translation\"]]\n",
        "    model_inputs = tokenizer(src, text_target=trg, max_length=max_src_length, truncation=True)\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(trg, max_length=max_trg_length, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74,
          "referenced_widgets": [
            "c48cb2739e794453a2f441ec9211d66a",
            "0a68ed3662a346d0a8998fe92f237c81",
            "997dd30814f4464cad3eb948340798e7",
            "5f76d280b98545de9e509982e15dcfa5",
            "ed240fca62dd41cd9657b577094f766e",
            "6f9aab4c60d3470685b143488db8baaf",
            "c5e4ea73f0734e17bb7a7b40c487421b",
            "f96e4569d7984b58a5d9d2590b97775c",
            "21a8a8addf8a46d8aaff2c58230813c8",
            "cfacc6148cbb4919b7ae9ee809625f67",
            "cdd516fa3510446b95732d6afba46c81",
            "5b11739bcd4b4870a9ad252926d80d89",
            "1f12dfefbf6c4b2eac46df8b396d4118",
            "fb9b3ddbab6244198b02c761540426c8",
            "8e357f3dc8754f738732432e2a80243e",
            "10cbff18c45c498cb7f14421bc3528b6",
            "c1f3dada96884d34ba1b04d2b8f3e5be",
            "ed1bc985afb34a58a65ad794ec3a20f9",
            "cb634e58c959478ca472e9af66fdc32d",
            "a4e38eef95e0436e9c9b30524ea07e31",
            "27f4af7c80144063bf89f19bbde83224",
            "d48279277e8343daadf787382f339c02",
            "82dad802caad4e60b8c6fafce3fa3958",
            "20e136f0fdd148d79072eb17d71646bf",
            "54bdc6c34c1f4f138d372186317d079c",
            "71693100877148d9983a29edbdae5397",
            "1bffa6f66a364a849615ec89e4463ab3",
            "8f3ed386ece249178e855f371514928a",
            "ed78383b194c46e2839b537ab44d6e97",
            "0400493c6fab40d095eebdfd06499b67",
            "3c10556a25f44f6cb45d93e9f5a5bb82",
            "a67df61ec74549e9be71611ce8f2a9a3",
            "c215572f055d443b87ad61786990ec91"
          ]
        },
        "id": "prYU4itTEV-V",
        "outputId": "50613d77-9e5f-45a7-d589-ef1af441a0f9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c48cb2739e794453a2f441ec9211d66a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/264779 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3596: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b11739bcd4b4870a9ad252926d80d89",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/16549 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82dad802caad4e60b8c6fafce3fa3958",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/16549 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenized_datasets = dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=dataset[\"train\"].column_names,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8DgB6nsEV-V",
        "outputId": "cab50e86-7624-4132-b6bc-cf0bd4bcec28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 264779\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 16549\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 16549\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-s2VRe3EV-V"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayMu8U3iEV-V"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2DnVsG-EEV-V",
        "outputId": "627d809d-b0c6-4f74-fac7-44ba7027a241"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "607ae3c8c68b48c8a69b3ac12de7a4e0",
            "df3342d486af403d8d2e985ce238fecc",
            "6b39db643f4042f889d6a7358d0f299f",
            "ab84ca4019d448f6badfdecee6816a5a",
            "74777dae22dc4d8d981e32cce3ed2923",
            "314fecd4f4394cb69bdf7983fd39f392",
            "ee3ae0cc984b48ba85cc6ba22772adbb",
            "1babb73b1c4749f89d80e462d43be1bf",
            "14e449b2b0fc4cb98338c0f7dbe995ec",
            "501f7abc1fd947e4bfe1d8d40b19dfa6",
            "a25ade2c0b3a445d85f0a5349646d610",
            "cf9d151cab9546a5899bc2db84aebdcc",
            "858127fa8be945a69ed7f0dffb48b8d8",
            "d6e63b79b5de49b9b5f162c71de57cec",
            "a2ee25b0d1484c5486de8f4f33d2a0f9",
            "10d1617b11804068aac70f4e9224f7bf",
            "dfbd020b722748448bca548851e440a4",
            "22c05eac7c8a44edbcbe3d4d82b39d02",
            "cfa8fb521d9745cbadec4963da9470d1",
            "3fbdd2e98daf45719b8abef80484a883",
            "fe70cb58c3c7417bbf3aaae886d872b0",
            "41e6488f159a48cc892bac5f7d266d18"
          ]
        },
        "id": "uX7xup-GEV-W",
        "outputId": "a988f90c-d3c7-4ae9-98a9-2043f14f9698"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "607ae3c8c68b48c8a69b3ac12de7a4e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/940 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf9d151cab9546a5899bc2db84aebdcc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/1.19G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MCiYYutEV-W"
      },
      "source": [
        "## Data Collation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUNkvxEqEV-W"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWUqCPZqEV-W",
        "outputId": "5c9a746c-81b3-469d-a401-d7b8d77cd166"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask', 'labels', 'decoder_input_ids'])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(1, 3)])\n",
        "batch.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNDXdpsNEXXE",
        "outputId": "b04c29d8-217f-4ab1-a4ee-08319cbd3118"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  122,  4059,  4149, 19416,  1202,    58,   361,   289,  1022,   112,\n",
              "           262,  1804,  1908, 20004,     1],\n",
              "        [ 6280,  3350,   462, 20283,  8340,   289,  6507,    88, 20004,     2,\n",
              "           513,     7, 20004,     1,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]]), 'labels': tensor([[20027, 22432, 20025, 20533, 20004, 20272, 20049, 53359, 35681, 20388,\n",
              "         22157, 24859, 20004, 20005, 20004,     1],\n",
              "        [20283, 20937, 20010, 20007, 20467, 21537, 20044, 20032, 20786, 20009,\n",
              "         20007, 22517, 20004, 20005, 20004,     1]]), 'decoder_input_ids': tensor([[    0, 20027, 22432, 20025, 20533, 20004, 20272, 20049, 53359, 35681,\n",
              "         20388, 22157, 24859, 20004, 20005, 20004],\n",
              "        [    0, 20283, 20937, 20010, 20007, 20467, 21537, 20044, 20032, 20786,\n",
              "         20009, 20007, 22517, 20004, 20005, 20004]])}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zQYCuofEV-W",
        "outputId": "1fac7cde-8a51-4a2b-8470-a27ca28359cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[20027, 22432, 20025, 20533, 20004, 20272, 20049, 53359, 35681, 20388,\n",
              "         22157, 24859, 20004, 20005, 20004,     1],\n",
              "        [20283, 20937, 20010, 20007, 20467, 21537, 20044, 20032, 20786, 20009,\n",
              "         20007, 22517, 20004, 20005, 20004,     1]])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch[\"labels\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Bwl9NNrEV-W",
        "outputId": "fa941089-3f4a-45f4-9db9-a2b139bd64c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[    0, 20027, 22432, 20025, 20533, 20004, 20272, 20049, 53359, 35681,\n",
              "         20388, 22157, 24859, 20004, 20005, 20004],\n",
              "        [    0, 20283, 20937, 20010, 20007, 20467, 21537, 20044, 20032, 20786,\n",
              "         20009, 20007, 22517, 20004, 20005, 20004]])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch[\"decoder_input_ids\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avPRmID2EV-W",
        "outputId": "8786b824-27f5-4a1c-ef86-40ccf5730923"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[20027, 22432, 20025, 20533, 20004, 20272, 20049, 53359, 35681, 20388, 22157, 24859, 20004, 20005, 20004, 1]\n",
            "[20283, 20937, 20010, 20007, 20467, 21537, 20044, 20032, 20786, 20009, 20007, 22517, 20004, 20005, 20004, 1]\n"
          ]
        }
      ],
      "source": [
        "for i in range(1, 3):\n",
        "    print(tokenized_datasets[\"train\"][i][\"labels\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diMCvZkSEV-W"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PnS45FiEV-W",
        "outputId": "46be7f7a-13b8-4c1d-d332-71f9f7ca711b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2022.10.31)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.8.10)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.22.4)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.2)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-2.7.0 sacrebleu-2.3.1\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pip install sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106,
          "referenced_widgets": [
            "ce844a2ff76e4b8085ab59f4712f2cd9",
            "c8c1e6b07df14868bddd5ef7c172da97",
            "fd444d75d8a2484fb9e00ba2b398f84c",
            "0b23120ac275429d9bf642928f3c4cff",
            "c82592eddf02458cbc81f3c98df1e0e9",
            "64fabd781825470d93601f5a46fbb3a3",
            "55830f07428244ada571569f31a5b840",
            "50d8a8e8b80e47d7b234986ca2974b12",
            "0b8869e1a9614cd482d5cd20a92b808d",
            "ed4fe35c2bfe49228bad4b94e5dc8140",
            "511019332bdb4211a12ab0341c2b50ef"
          ]
        },
        "id": "d5DR7wA5EV-W",
        "outputId": "de0b4418-d1ba-48d5-cfdb-60a5f9f70d85"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-a15d7a2cd8c7>:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"sacrebleu\")\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce844a2ff76e4b8085ab59f4712f2cd9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_metric\n",
        "\n",
        "metric = load_metric(\"sacrebleu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMJA-upMEV-W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    # 모델이 예측 로짓(logits)외에 다른 것을 리턴하는 경우.\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    # -100은 건너뛴다.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # 단순 후처리\n",
        "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
        "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    return {\"bleu\": result[\"score\"]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2BEci3CEV-W"
      },
      "source": [
        "## Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wp3Mg-PzEV-W",
        "outputId": "ac8568ec-aa74-45f8-c8a7-9017975f497f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.19.0-py3-none-any.whl (219 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.19.0\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPt3p7S9EV-W"
      },
      "outputs": [],
      "source": [
        "import accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DZ9wmqNEV-X"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    \"test-trainer_model_2\",\n",
        "    evaluation_strategy=\"no\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=1, # 시간이 너무 오래 걸리는 관계로 epoch 1만 훈련함.\n",
        "    predict_with_generate=True,\n",
        "    gradient_accumulation_steps=2,\n",
        "    fp16=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFd4XvtQEV-X"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "eUp69iFGEV-X",
        "outputId": "e5252c4a-858e-4fc8-872d-eee17f86445f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:816: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8274' max='8274' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8274/8274 2:00:15, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.645300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.226200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.153600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.106000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>1.069500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>1.063700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>1.044100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>1.026600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>1.030700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>1.015600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.997500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.993300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.999000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.985000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.980000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.989100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=8274, training_loss=1.0791916841465925, metrics={'train_runtime': 7219.9644, 'train_samples_per_second': 36.673, 'train_steps_per_second': 1.146, 'total_flos': 9813119581126656.0, 'train_loss': 1.0791916841465925, 'epoch': 1.0})"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLi6ly6zEV-X"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"./results_model_2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdwxZjcPEV-X"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTrMTGUdEV-X"
      },
      "outputs": [],
      "source": [
        "# eval_dataset을 test로 설정\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "MUh9KliBEV-X",
        "outputId": "1d078f7c-bbd7-44d5-cd6d-464f3468be35"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:816: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1035' max='1035' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1035/1035 10:18]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.8814811110496521,\n",
              " 'eval_bleu': 35.804538726684655,\n",
              " 'eval_runtime': 623.9212,\n",
              " 'eval_samples_per_second': 26.524,\n",
              " 'eval_steps_per_second': 1.659}"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldGmVzR_EpbN"
      },
      "source": [
        "- 여기서 train.evaluate()를 이용해서 Test 할 때는 bleu socre가 약 36 정도로 나옴\n",
        "- 첫 번째 사전학습모델(Helsinki_NLP_opus_mt_ko_en)보다 낮은 이유는 모델 자체의 다름 요인과 시간 관계상 epoch를 1까지만 훈련했다는 요인 등이 존재할 것임"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8lvcbvFEV-X"
      },
      "source": [
        "## pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4C0oUT34EV-X"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "result_model_checkpoint = \"./results_model_2\"\n",
        "translator = pipeline(\"translation\", model=result_model_checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY1jpaC9EV-X"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKHGEz6EEV-X"
      },
      "outputs": [],
      "source": [
        "sen_list = [\n",
        "'모든 액체 , 젤 , 에어로졸 등 은 1 커트 짜리 여닫이 투명 봉지 하나 에 넣 어야 하 ㅂ니다 .',\n",
        "'미안 하 지만 , 뒷쪽 아이 들 의 떠들 는 소리 가 커 어서 , 광화문 으로 가 아고 싶 은데 표 를 바꾸 어 주 시 겠 어요 ?',\n",
        "'은행 이 너무 멀 어서 안 되 겠 네요 . 현찰 이 필요 하면 돈 을 훔치 시 어요',\n",
        "'아무래도 분실 하 ㄴ 것 같 으니 분실 신고서 를 작성 하 아야 하 겠 습니다 . 사무실 로 같이 가 시 ㄹ 까요 ?',\n",
        "'부산 에서 코로나 확진자 가 급증 하 아서 병상 이 부족하 아 지자  확진자 20명 을 대구 로 이송하 ㄴ다 .',\n",
        "'변기 가 막히 었 습니다 .',\n",
        "'그 바지 좀 보이 어 주 시 ㅂ시오 . 이거 얼마 에 사 ㄹ 수 있 는 것 이 ㅂ니까 ?',\n",
        "'비 가 오 아서 백화점 으로 가지 말 고 두타 로 가 았 으면 좋 겠 습니다 .',\n",
        "'속 이 안 좋 을 때 는 죽 이나 미음 으로 아침 을 대신 하 ㅂ니다',\n",
        "'문 대통령 은 집단 이익 에서 벗어 나 아 라고 말 하 었 다 .',\n",
        "'이것 좀 먹어 보 ㄹ 몇 일 간 의 시간 을 주 시 어요 .',\n",
        "'이날 개미군단 은 외인 의 물량 을 모두 받 아 내 었 다 .',\n",
        "'통합 우승 의 목표 를 달성하 ㄴ NC 다이노스 나성범 이 메이저리그 진출 이라는 또 다른 꿈 을 향하 어 나아가 ㄴ다 .',\n",
        "'이번 구조 조정 이 제품 을 효과 적 으로 개발 하 고 판매 하 기 위하 ㄴ 회사 의 능력 강화 조처 이 ㅁ 을 이해 하 아 주 시 리라 생각 하 ㅂ니다 .',\n",
        "'요즘 이 프로그램 녹화 하 며 많은 걸 느끼 ㄴ다 ']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivewiqhdEV-X",
        "outputId": "dbd8176e-d1d1-4bd9-fb80-41a07bd99f53"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Your input_length: 31 is bigger than 0.9 * max_length: 20. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "모든 액체 , 젤 , 에어로졸 등 은 1 커트 짜리 여닫이 투명 봉지 하나 에 넣 어야 하 ㅂ니다 .\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:816: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "Your input_length: 44 is bigger than 0.9 * max_length: 20. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'translation_text': 'All liquids , gels , aerosols , etc. must be placed in a'}]\n",
            "\n",
            "미안 하 지만 , 뒷쪽 아이 들 의 떠들 는 소리 가 커 어서 , 광화문 으로 가 아고 싶 은데 표 를 바꾸 어 주 시 겠 어요 ?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Your input_length: 26 is bigger than 0.9 * max_length: 20. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'translation_text': \"I 'm sorry , but the children in the back are talking loudly , so\"}]\n",
            "\n",
            "은행 이 너무 멀 어서 안 되 겠 네요 . 현찰 이 필요 하면 돈 을 훔치 시 어요\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Your input_length: 39 is bigger than 0.9 * max_length: 20. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'translation_text': 'The bank is too far away . If you need cash , steal the money .'}]\n",
            "\n",
            "아무래도 분실 하 ㄴ 것 같 으니 분실 신고서 를 작성 하 아야 하 겠 습니다 . 사무실 로 같이 가 시 ㄹ 까요 ?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Your input_length: 33 is bigger than 0.9 * max_length: 20. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'translation_text': \"I think I lost it . I 'll have to fill out a lost report \"}]\n",
            "\n",
            "부산 에서 코로나 확진자 가 급증 하 아서 병상 이 부족하 아 지자  확진자 20명 을 대구 로 이송하 ㄴ다 .\n",
            "[{'translation_text': 'Due to the rapid increase in the number of corona confirmed cases in Busan ,'}]\n",
            "\n",
            "변기 가 막히 었 습니다 .\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Your input_length: 30 is bigger than 0.9 * max_length: 20. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'translation_text': 'The toilet is clogged . '}]\n",
            "\n",
            "그 바지 좀 보이 어 주 시 ㅂ시오 . 이거 얼마 에 사 ㄹ 수 있 는 것 이 ㅂ니까 ?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Your input_length: 29 is bigger than 0.9 * max_length: 20. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'translation_text': 'Can you show me those pants ? How much can I buy this for ? '}]\n",
            "\n",
            "비 가 오 아서 백화점 으로 가지 말 고 두타 로 가 았 으면 좋 겠 습니다 .\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Your input_length: 21 is bigger than 0.9 * max_length: 20. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'translation_text': \"I 'd rather go to the department store instead of going to the department store because it\"}]\n",
            "\n",
            "속 이 안 좋 을 때 는 죽 이나 미음 으로 아침 을 대신 하 ㅂ니다\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Your input_length: 19 is bigger than 0.9 * max_length: 20. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'translation_text': 'When I feel sick, I take the morning with porridge or micheum .'}]\n",
            "\n",
            "문 대통령 은 집단 이익 에서 벗어 나 아 라고 말 하 었 다 .\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Your input_length: 20 is bigger than 0.9 * max_length: 20. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'translation_text': 'President Moon said to get out of the collective interest . '}]\n",
            "\n",
            "이것 좀 먹어 보 ㄹ 몇 일 간 의 시간 을 주 시 어요 .\n",
            "[{'translation_text': 'Give me a few days to try this . '}]\n",
            "\n",
            "이날 개미군단 은 외인 의 물량 을 모두 받 아 내 었 다 .\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Your input_length: 36 is bigger than 0.9 * max_length: 20. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'translation_text': 'On this day, the Antsudaeundan received all the supplies of foreign '}]\n",
            "\n",
            "통합 우승 의 목표 를 달성하 ㄴ NC 다이노스 나성범 이 메이저리그 진출 이라는 또 다른 꿈 을 향하 어 나아가 ㄴ다 .\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Your input_length: 43 is bigger than 0.9 * max_length: 20. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'translation_text': 'NC Dinos Na Seong-beom, who has achieved the goal of a unified championship'}]\n",
            "\n",
            "이번 구조 조정 이 제품 을 효과 적 으로 개발 하 고 판매 하 기 위하 ㄴ 회사 의 능력 강화 조처 이 ㅁ 을 이해 하 아 주 시 리라 생각 하 ㅂ니다 .\n",
            "[{'translation_text': \"I think you understand that this restructuring is a company's ability-building measure to develop and\"}]\n",
            "\n",
            "요즘 이 프로그램 녹화 하 며 많은 걸 느끼 ㄴ다 \n",
            "[{'translation_text': 'These days I feel a lot while recording this program . '}]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for sent in sen_list:\n",
        "    print(sent)\n",
        "    print(translator(sent))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKtcIIFOEV-X"
      },
      "source": [
        "## Bleu Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDkgYiHHEV-X"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(result_model_checkpoint)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(result_model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJC9ym6hEV-X"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"test\"], batch_size=64, collate_fn=data_collator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giqT-U-_EV-X"
      },
      "outputs": [],
      "source": [
        "test_dataloader_iter = iter(test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9-mNAd1EV-X"
      },
      "outputs": [],
      "source": [
        "test_batch = next(test_dataloader_iter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUKM2Y8YEV-X",
        "outputId": "ebc1b9b1-07bf-48f7-851e-084bc19e863f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask', 'labels', 'decoder_input_ids'])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_batch.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPWyCYTnEV-X"
      },
      "outputs": [],
      "source": [
        "test_input = { key: test_batch[key] for key in ('input_ids', 'attention_mask') }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlHTMbnGEV-Y"
      },
      "outputs": [],
      "source": [
        "english = model.generate(\n",
        "    **test_input,\n",
        "    max_length=max_trg_length,\n",
        "    num_beams=5,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOc71SpeEV-Y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "labels =  np.where(test_batch.labels != -100, test_batch.labels, tokenizer.pad_token_id)\n",
        "kor_sents = tokenizer.batch_decode(test_batch.input_ids, skip_special_tokens=True) # 원래 문장 리스트\n",
        "references = tokenizer.batch_decode(labels, skip_special_tokens=True) # 번역 정답 문장 리스트\n",
        "preds = tokenizer.batch_decode(english, skip_special_tokens=True ) # 번역한 리스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Tj24fUCEV-Y",
        "outputId": "b7bccf48-48c5-45fd-921c-416623767fd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Korean   : 그럼 다른 데 가 아서 먹 어야 하 겠 네요 \n",
            "Reference : Then I must eat somewhere else! \n",
            "Translated: Then I 'll have to go somewhere else. \n",
            "\n",
            "\n",
            "Korean   : 이것 은 얼마 이 죠 \n",
            "Reference : How much does it cost? \n",
            "Translated: How much is this? \n",
            "\n",
            "\n",
            "Korean   : 거리 가 보이 는 방 이 면 좋 겠 네요 \n",
            "Reference : I 'd like a room looking out on the street. \n",
            "Translated: I 'd like a room with a street view. \n",
            "\n",
            "\n",
            "Korean   : 부르 시 었 어요 \n",
            "Reference : You wanted to see me? \n",
            "Translated: Did you call me? \n",
            "\n",
            "\n",
            "Korean   : 변명 하 려고 하 지 말 시 어요 \n",
            "Reference : Don't try and explain it away. \n",
            "Translated: Don't try to make excuses. \n",
            "\n",
            "\n",
            "Korean   : 미국 에서 결혼 하 시 ᄅ 것 이 니까 \n",
            "Reference : Will you get married in America? \n",
            "Translated: Are you getting married in America? \n",
            "\n",
            "\n",
            "Korean   : 너 농담 하 니 \n",
            "Reference : You're kidding? \n",
            "Translated: Are you kidding me? \n",
            "\n",
            "\n",
            "Korean   : 저 는 중국 베이징 에서 오 았 어요 당신 은 요 \n",
            "Reference : I'm from Beijing, China. How about you? \n",
            "Translated: I'm from Beijing, China. You? \n",
            "\n",
            "\n",
            "Korean   : 우리 는 런던 행연결 비행기 편 을 타 려고 내리 었 어요 \n",
            "Reference : We're having a layover for our connection to London. \n",
            "Translated: We're off to catch a connecting flight to London. \n",
            "\n",
            "\n",
            "Korean   : 어머니 에게 안부 전하 아 주 시 어요 \n",
            "Reference : Say hello to your mother. \n",
            "Translated: Please say hello to your mother. \n",
            "\n",
            "\n",
            "Korean   : 상대방 이 나 의 제안 을 거절 하 면 나 는 일전 을 불사 하 겠 다 \n",
            "Reference : If the other party rejects my proposal, I shall not hesitate to fight. \n",
            "Translated: If the other party rejects my offer, I 'll be ready to fight. \n",
            "\n",
            "\n",
            "Korean   : 그것 은 그 교회 바로 옆 에 있 어요 \n",
            "Reference : It's next to the church. \n",
            "Translated: It's right next to the church. \n",
            "\n",
            "\n",
            "Korean   : 일반 서비스 로 하 아 주 시 어요 \n",
            "Reference : I 'd like the regular service, please. \n",
            "Translated: General service, please. \n",
            "\n",
            "\n",
            "Korean   : 새 아파트 구하 았 어요 \n",
            "Reference : Have you found a new apartment yet? \n",
            "Translated: Have you found a new apartment? \n",
            "\n",
            "\n",
            "Korean   : 당신 은 어떻 어요 \n",
            "Reference : What about you? \n",
            "Translated: How about you? \n",
            "\n",
            "\n",
            "Korean   : 비행장 으로 데리 어다 주 시 어요 \n",
            "Reference : Take me to the airport. \n",
            "Translated: Please take me to the airfield. \n",
            "\n",
            "\n",
            "Korean   : 아뇨 하지만 잠깐 생각 하 아 보 ᄅ게요 \n",
            "Reference : No, but I 'll give it some thought. \n",
            "Translated: No, but I 'll think about it for a moment. \n",
            "\n",
            "\n",
            "Korean   : 저 의 이름 은 존 커 이 니다 신용 카드 번호 가 필요 하 시 ᄂ 가요 \n",
            "Reference : My name is John Kauh. Do you need my credit card number? \n",
            "Translated: My name is John Ke. Do you need a credit card number? \n",
            "\n",
            "\n",
            "Korean   : 구암 서원 까지 는 얼마나 걸리 나요 \n",
            "Reference : How long does it take to get to the Guamseowon? \n",
            "Translated: How long does it take to get to the Guamseowon? \n",
            "\n",
            "\n",
            "Korean   : 창가 쪽 자리 로 안내 하 아 주 시 어요 \n",
            "Reference : Can I take a seat by the window? \n",
            "Translated: Please show me to the window seat. \n",
            "\n",
            "\n",
            "Korean   : 항공편 으로 좀 부치 어 주 시 어요 \n",
            "Reference : Please send it by air. \n",
            "Translated: Please send me a flight. \n",
            "\n",
            "\n",
            "Korean   : 한국 의 대학교 에서 저 의 분야 를 가르치 고 연구 하 며 공헌 하 고 싶 습니다 \n",
            "Reference : I want to dedicate myself to teaching and researching my areas in a university in Korea. \n",
            "Translated: I 'd like to contribute by teaching and researching my field at a Korean medical university. \n",
            "\n",
            "\n",
            "Korean   : 한국어 잡지 있 을까요 \n",
            "Reference : Do you have any Korean magazines? \n",
            "Translated: Do you have a Korean magazine? \n",
            "\n",
            "\n",
            "Korean   : 양쯔강익스프레스 항공 이 니다 무엇 을 돕 아 드리 ᄅ 까요 \n",
            "Reference : Yangtze River Express. How can I help you? \n",
            "Translated: Yangtze River Express Airlines. May I help you? \n",
            "\n",
            "\n",
            "Korean   : 점수 가 1 대 0 이 니다 \n",
            "Reference : The score is one, zero. \n",
            "Translated: The score is one to zero. \n",
            "\n",
            "\n",
            "Korean   : 지금 비 어 있 는 것 ᄂ 스위트룸 뿐 이 니다 \n",
            "Reference : The only room available at the moment is a suite. \n",
            "Translated: The only available room is the suite. \n",
            "\n",
            "\n",
            "Korean   : 당신 비판 은 도 가 지나치 는 것 같 아 \n",
            "Reference : You're going a little too far with your criticism. \n",
            "Translated: Your criticism seems to be too much. \n",
            "\n",
            "\n",
            "Korean   : 중국 으로 수신 이 ᄂ 지불 로 국제 통화 를 하 고 싶 은데요 \n",
            "Reference : I want to make an overseas collect call to China. \n",
            "Translated: I 'd like to make an international call to China. \n",
            "\n",
            "\n",
            "Korean   : 즐겁 ᄂ 하루 가 되 시 어요 \n",
            "Reference : Have a nice day. \n",
            "Translated: Have a nice day. \n",
            "\n",
            "\n",
            "Korean   : 맡기 ᄅ 짐 이 있 나요 \n",
            "Reference : Do you have any luggage to check? \n",
            "Translated: Do you have any baggage to check in? \n",
            "\n",
            "\n",
            "Korean   : 237 호실 을 연결 하 아 주 시 어요 \n",
            "Reference : Would you connect me to room 237? \n",
            "Translated: Please connect room 237. \n",
            "\n",
            "\n",
            "Korean   : 취미 는 뭐 죠 \n",
            "Reference : What are your hobbies? \n",
            "Translated: What's your hobby? \n",
            "\n",
            "\n",
            "Korean   : 싱가포르 의 국가 번호 는 몇 번 이 니까 \n",
            "Reference : What's the international phone code for Singapore? \n",
            "Translated: What is Singapore's country number? \n",
            "\n",
            "\n",
            "Korean   : 메이호텔 에서 투숙 하 ᄅ 예정 이 니다 \n",
            "Reference : I 'll be staying at Hotel Mai. \n",
            "Translated: I'm going to stay at the May Hotel. \n",
            "\n",
            "\n",
            "Korean   : 너 는 컴퓨터 게임 을 좋아하 니 \n",
            "Reference : Do you like computer games? \n",
            "Translated: Do you like computer games? \n",
            "\n",
            "\n",
            "Korean   : 지하철 표 는 어디 서 사 야 하 나요 \n",
            "Reference : Where can I get a ticket? \n",
            "Translated: Where should I buy a subway ticket? \n",
            "\n",
            "\n",
            "Korean   : 한국통신박물관 으로 가 려면 어느 역 에서 내리 어야 하 니까 \n",
            "Reference : I 'd like to go to the Hanguktongsinbangmulgwan. Which subway station should I get off at? \n",
            "Translated: Which station should I get off to go to the Korea Telecommunications Museum? \n",
            "\n",
            "\n",
            "Korean   : 댈러스 에서 가 는 것 ᄂ 없 나요 \n",
            "Reference : Isn't there any flight from Dallas? \n",
            "Translated: Is there any flight from Dallas? \n",
            "\n",
            "\n",
            "Korean   : 이 길 로 가 면 양재천 이 나옵 니까 \n",
            "Reference : Does this road go to Yangjaecheon? \n",
            "Translated: Does this road go to Yangjaecheon? \n",
            "\n",
            "\n",
            "Korean   : 심천 까지 가 는 편도 표 1 장 주 시 어요 \n",
            "Reference : A one way ticket to Simcheon, please. \n",
            "Translated: One ticket to Shenzhen, please. \n",
            "\n",
            "\n",
            "Korean   : 로댕 갤러리 는 꼭 들르 어 보 시 어요 \n",
            "Reference : Don't miss the Rodaenggaelleori. \n",
            "Translated: Don't miss the Rodong Galleries. \n",
            "\n",
            "\n",
            "Korean   : 성함 을 말씀 하 아 주 시 겠 어요 \n",
            "Reference : Could you give me your name? \n",
            "Translated: May I have your name, please? \n",
            "\n",
            "\n",
            "Korean   : 그럼 찍 으세 요 준비 되 었 습니다 \n",
            "Reference : Then, go ahead, take it. I'm ready. \n",
            "Translated: Then take a picture. I'm ready. \n",
            "\n",
            "\n",
            "Korean   : 비디오 화질 을 어떻 게 조절 하 나요 \n",
            "Reference : How do you adjust the video quality? \n",
            "Translated: How do I adjust the video quality? \n",
            "\n",
            "\n",
            "Korean   : 운현궁 에서 자유 시간 을 가집 니까 \n",
            "Reference : Do we have free time at the Unhyeongung? \n",
            "Translated: Do we have free time at Unhyeongung? \n",
            "\n",
            "\n",
            "Korean   : 코오롱 세이브플라자 까지 어떻 게 가 면 되 는 거 이 죠 \n",
            "Reference : How do I get to Koorong Seibeupeullaja? \n",
            "Translated: How can I get to the Kolon Save Plaza? \n",
            "\n",
            "\n",
            "Korean   : 습도 가 굉장히 높 군요 \n",
            "Reference : It's very humid. \n",
            "Translated: The humidity is very high. \n",
            "\n",
            "\n",
            "Korean   : 매일 아침 7 시 30 분 부터 두 시간 동안 이 에요 \n",
            "Reference : They're at 7:30 every morning, and last for two hours. \n",
            "Translated: It's for two hours from 7:30 a.m. every morning. \n",
            "\n",
            "\n",
            "Korean   : 이것 은 어떻 게 하 아서 먹 어요 \n",
            "Reference : How do you eat this? \n",
            "Translated: How do I eat this? \n",
            "\n",
            "\n",
            "Korean   : 롯데 월드 에 구경 가 고 싶 은데요 \n",
            "Reference : I want to go to the Rotdewoldeu. \n",
            "Translated: I 'd like to go to the Lotte World. \n",
            "\n",
            "\n",
            "Korean   : 올라가 요 아니 면 내려가 요 \n",
            "Reference : Up, or down? \n",
            "Translated: Go up or down. \n",
            "\n",
            "\n",
            "Korean   : 요금표 를 보 ᄅ 수 있 습니까 \n",
            "Reference : Can I see list of your rates? \n",
            "Translated: May I see your rate card? \n",
            "\n",
            "\n",
            "Korean   : 나 를 잊 지 말 시 어요 \n",
            "Reference : Don't forget me. \n",
            "Translated: Don't forget me. \n",
            "\n",
            "\n",
            "Korean   : 오늘 점심 은 메드포갈릭여의점 에서 먹 었 으면 좋 겠 는데요 \n",
            "Reference : I think we should go to the Medeupogallingnyeouijeom for lunch today. \n",
            "Translated: I 'd like to have lunch at Medbogalikyeouibun for lunch today. \n",
            "\n",
            "\n",
            "Korean   : 이 우유 가 상하 았 어요 \n",
            "Reference : This milk has gone bad. \n",
            "Translated: This milk is spoiled. \n",
            "\n",
            "\n",
            "Korean   : 오늘 밤 여기 서 지내 ᄅ 수 있 을까요 \n",
            "Reference : May I stay here tonight? \n",
            "Translated: Can I stay here tonight? \n",
            "\n",
            "\n",
            "Korean   : 훌륭 하 아 \n",
            "Reference : That's great. \n",
            "Translated: That's great. \n",
            "\n",
            "\n",
            "Korean   : 좋 습니다 끝나 았 습니다 가 시 어도 좋 습니다 \n",
            "Reference : O.K. That's all. You may go now. \n",
            "Translated: Good. It's over. You can go. \n",
            "\n",
            "\n",
            "Korean   : 굽 이 낮 은 것 ᄅ 로 검은색 가죽 이 요 \n",
            "Reference : Black leather with a low heel. \n",
            "Translated: Black leather with low heels. \n",
            "\n",
            "\n",
            "Korean   : 나 는 그 의 제안 이 타당 하 다고 생각 하 니다 \n",
            "Reference : I think his recommendation is valid. \n",
            "Translated: I think his proposal is reasonable. \n",
            "\n",
            "\n",
            "Korean   : 유나이티드 항공 비행기 의 짐 찾 는 곳 이 어디 죠 \n",
            "Reference : Where is the baggage claim area for the United Airlines flight? \n",
            "Translated: Where is the baggage claim area for United Airlines? \n",
            "\n",
            "\n",
            "Korean   : 여보세요 이란항공 맞 나요 \n",
            "Reference : Hello. Is this Iran Air? \n",
            "Translated: Hello. Is this Iran Airlines? \n",
            "\n",
            "\n",
            "Korean   : 여기 서 얼마나 멀 죠 \n",
            "Reference : How far is it from here? \n",
            "Translated: How far is it from here? \n",
            "\n",
            "\n",
            "Korean   : 거기 서 수상 스키 를 타 ᄅ 수 있 습니까 \n",
            "Reference : Can I do water-skiing there? \n",
            "Translated: Can I take a water skiing there? \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 번역 결과 출력\n",
        "for s in zip(kor_sents, references, preds):\n",
        "    print('Korean   :', s[0])\n",
        "    print('Reference :', s[1])\n",
        "    print('Translated:', s[2])\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_v5eOsOEV-Y",
        "outputId": "2dae3d02-6529-40f5-ff80-4175d451db22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bleu': 37.422200547040475}"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compute_metrics((english, labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_k2vMI5HFCnH"
      },
      "source": [
        "- 직접 test_dataloader를 배치사이즈 64로 만든 후, model.generate를 통해 번역 문장을 생성한 뒤 compute_metrics 함수로 bleu score를 구하면 약 37 정도가 나옴\n",
        "- 첫 번째 사전학습모델(Helsinki_NLP_opus_mt_ko_en)보다 낮은 이유는 모델 자체의 다름 요인과 시간 관계상 epoch를 1까지만 훈련했다는 요인 등이 존재할 것임"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PjvrHl1FUJb"
      },
      "source": [
        "# 결과 정리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp-ktkQXFVjj"
      },
      "source": [
        "- Inference\n",
        "    - 두 모델 모두 잘 나오는 것으로 보이는데, 그래도 Helsinki_NLP_opus_mt_ko_en이 조금 더 정확하게 번역하는 것 같다.\n",
        "\n",
        "- Bleu Score\n",
        "    - Helsinki_NLP_opus_mt_ko_en: 59\n",
        "    - KETI_AIR_Downstream_long_ke_t5_base_translation_aihub_ko2en: 37\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
