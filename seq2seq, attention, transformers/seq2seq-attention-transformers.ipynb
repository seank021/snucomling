{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Qu68X0umFBe"
   },
   "source": [
    "# Assignment 2: Korean to English Translation\n",
    "\n",
    "- Sequence to Sequence 모델의 대표적인 한국어-영어 번역을 [Encoder-decoder](https://github.com/bentrevett/pytorch-seq2seq/blob/main/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb), [Attention]( https://github.com/bentrevett/pytorch-seq2seq/blob/main/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb), 그리고 [Transformers](https://github.com/bentrevett/pytorch-seq2seq/blob/main/legacy/6%20-%20Attention%20is%20All%20You%20Need.ipynb) 기반으로 구현\n",
    "- Pytorch Seq to Seq 모델을 참고로 하여 한국어와 영어의 형태소분석되고 의존관계로 되어 있는 파일을 프로세싱하여 두 언어의 parallel 데이터 쌍으로 만들고 이를 학습하여 모델별로 Perplexity가 어떻게 달라지는지 살펴 보고, 가장 성능이 좋은 모델을 근간으로 해서 Inference로 한국어 문장을 입력하면 대응되는 영어 번역이 출력될 수 있도록 구현\n",
    "- Transformer 기반은 이전 토치텍스트 버전으로 되어 있으니 이를 새로운 토치 텍스트 버전으로 바꾸어야 함\n",
    "- 반드시 다음 세 모델에 대해서 PPL와 BLEU score가 다 체크되어야 함.  Encoder-Decoder, Attention, Transformers.\n",
    "- 세 모델 중에 학습이 제대로 이루어지지 않는 경우, PPL이나 BLEU가 문제가 있는 경우 이를 Fix하려고 시도해 보라.\n",
    "- **새로운 버전의 TorchText를 사용하여 코랩에서 실행가능하도록**\n",
    "- 그룹을 허용. 그룹으로 할 경우 2명을 넘지 않아야 하며, 제출 파일에 참여자 이름과 역할을 반드시 명시할 것.\n",
    "- Inference시에 unk인 단어를 로마자화해서 번역에 나타날 수 있도록 시도해 볼 것(참고할 수 있는 사이트 중 하나 https://github.com/osori/korean-romanizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5vMyFp4-DV3"
   },
   "source": [
    "## Data\n",
    "- 첨부된 ko-en-en.parse.syn은 330,974 한국어 문장에 대응되는 영어문장이 품사와 구문분석이 되어 있는 파일이고 ko-en-ko.parse.syn은 이에 대응되는 한국어 문장이 형태소와 구문분석이 되어 있는 파일이다.\n",
    "\n",
    "(ROOT (S (NP (NNP Flight) (NNP 007)) (VP (MD will) (VP (VB stay) (PP (IN on) (NP (NP (DT the) (NN ground)) (PP (IN for) (NP (CD one) (NN hour))))))) (. .)))\n",
    "\n",
    "\n",
    "<id 1>\n",
    "<sent 1>\n",
    "1       2       NP      777/SN\n",
    "2       6       NP_SBJ  항공편/NNG|은/JX\n",
    "3       4       NP      1/SN|시간/NNG\n",
    "4       6       NP_AJT  동안/NNG\n",
    "5       6       NP_AJT  지상/NNG|에/JKB\n",
    "6       7       VP      머물/VV|게/EC\n",
    "7       0       VP      되/VV|ㅂ니다/EF|./SF\n",
    "</sent>\n",
    "</id>\n",
    "\n",
    "- 이 두 파일을 프로세싱하여 한-영 병행 데이터로 만들고 이를 학습 및 테스트 데이터로 사용한다.\n",
    "- Hint: 구조화된 데이터를 프로세싱하기 위해서는 nltk의 모듈을 사용할 수 있다.\n",
    "\n",
    "- 한국어 형태소 분석된 단위를 어절별로 결합할 수 있고, 분석된 채로 그대로 사용할 수도 있다.\n",
    "- 두 언어의 어순을 비슷하게 데이터를 만들어 학습할 수도 있고, 번역의 성능을 높이기 위해 다양한 형태로 재구조화 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LMbbMy6QCQ_Q"
   },
   "source": [
    "## Regarding torchtext version\n",
    "- https://github.com/pytorch/text#installation\n",
    "- torchtext 0.9.0 이전 버전은 torchtext.legacy로 변경됨; torchtext 0.12.0 버전 이후 legacy package가 제거되었음\n",
    "- colab의 python, torch, torchtext 버전을 모두 맞춰주어야 함\n",
    "- 계속 환경 및 버전을 맞춰보다가 거의 실패할 때쯤에 https://www.reddit.com/r/pytorch/comments/1eeochu/cant_import_torchtext/?rdt=64839 답변 참고해서 성공함\n",
    "- 이번 과제에서 사용하는 건 0.15.2으로, new torchtext임\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbg54Lov-DV4"
   },
   "source": [
    "# 환경 갖추기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hg2FZr7cVMaM"
   },
   "source": [
    "## 버전, 모듈 임포트 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mtp-gzFIB0Ea",
    "outputId": "a30297c4-7848-428d-f7aa-8fdd44b398d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.12\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h2OXNzG5DZq8",
    "outputId": "2c3b4166-bd5f-472e-f5d8-23b5b6d876be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting portalocker\n",
      "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: portalocker\n",
      "Successfully installed portalocker-2.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install portalocker\n",
    "import portalocker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQeR1450FE2p",
    "outputId": "1516066b-0077-49fd-a039-b5880e95c9c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.1.2\n",
      "    Uninstalling pip-24.1.2:\n",
      "      Successfully uninstalled pip-24.1.2\n",
      "Successfully installed pip-24.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nqrjIhM6H78E",
    "outputId": "d36a6302-347b-4c6c-f3f3-65b0e8fd5bc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.0.1\n",
      "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1.4)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.0.0 (from torch==2.0.1)\n",
      "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (75.1.0)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.44.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (3.30.5)\n",
      "Collecting lit (from triton==2.0.0->torch==2.0.1)\n",
      "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
      "Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m119.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
      "Installing collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.0+cu121\n",
      "    Uninstalling torch-2.5.0+cu121:\n",
      "      Successfully uninstalled torch-2.5.0+cu121\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.5.0+cu121 requires torch==2.5.0, but you have torch 2.0.1 which is incompatible.\n",
      "torchvision 0.20.0+cu121 requires torch==2.5.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 triton-2.0.0\n",
      "Collecting torchtext==0.15.2\n",
      "  Downloading torchtext-0.15.2-cp310-cp310-manylinux1_x86_64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.2) (4.66.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.2) (2.32.3)\n",
      "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.2) (2.0.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.2) (1.26.4)\n",
      "Collecting torchdata==0.6.1 (from torchtext==0.15.2)\n",
      "  Downloading torchdata-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (2.0.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.1->torchtext==0.15.2) (2.2.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchtext==0.15.2) (75.1.0)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchtext==0.15.2) (0.44.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchtext==0.15.2) (3.30.5)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchtext==0.15.2) (18.1.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.2) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.2) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.2) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchtext==0.15.2) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchtext==0.15.2) (1.3.0)\n",
      "Downloading torchtext-0.15.2-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchdata-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchdata, torchtext\n",
      "Successfully installed torchdata-0.6.1 torchtext-0.15.2\n"
     ]
    }
   ],
   "source": [
    "# not going to use torchdata, torchvision, torchaudio, so installation errors regarding those modules do not matter\n",
    "!pip install torch==2.0.1\n",
    "!pip install torchtext==0.15.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LJHSouaGC52b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "import torchtext\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QEh7piDFC2kD",
    "outputId": "bf388af9-53f2-4152-a1d9-711fa4e39f83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu117\n",
      "0.15.2+cpu\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torchtext.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5GHjW3ToT-8b"
   },
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kIIKiJmIN2MW"
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "def getpreferredencoding(do_setlocale = True):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = getpreferredencoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6HsbrgRJmLmt",
    "outputId": "a7893c98-ac82-4c5e-fa0a-e5b2430a48a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device 확인\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xML7AECBNyuR"
   },
   "source": [
    "## 드라이브 마운트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nkfCAqxON5YA",
    "outputId": "2efd0f50-000d-412f-b74e-0ca93d22dbdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c66ChvRuN_Ft"
   },
   "source": [
    "# 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPlJELxzVSYF"
   },
   "source": [
    "## 파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V86dEosdOAf7"
   },
   "outputs": [],
   "source": [
    "ko_path = \"/content/drive/MyDrive/ko-en.ko.parse\"\n",
    "en_path = \"/content/drive/MyDrive/ko-en.en.parse.syn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mO12y_baOCHM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wyGMB0uSODzr"
   },
   "outputs": [],
   "source": [
    "ko_lines = \"\"\n",
    "with open(ko_path, \"r\", encoding='utf-8') as ko_file:\n",
    "    for line in ko_file.readlines():\n",
    "        ko_lines += line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HhF8-fvROHVd"
   },
   "outputs": [],
   "source": [
    "with open(en_path, \"r\", encoding='utf-8') as en_file:\n",
    "    en_lines = en_file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frpJK18uOcOY"
   },
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5EttlOfFOc5f"
   },
   "outputs": [],
   "source": [
    "from nltk import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d-M_bLp8OeSh"
   },
   "outputs": [],
   "source": [
    "# nltk의 Tree 모듈을 사용하여 필요한 정보 추출, 각 문장에 <sos>, <eos> 넣어주기\n",
    "en_text_list = []\n",
    "for line in en_lines:\n",
    "    sent = ''\n",
    "    t = Tree.fromstring(line)\n",
    "    for token in t.leaves():\n",
    "      sent += token + ' '\n",
    "    en_text_list.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WTnFqXAOOhjL",
    "outputId": "a664834e-a2ea-47d8-a555-4775b5e7454a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Flight 007 will stay on the ground for one hour . ',\n",
       " 'Flight 017 will stay on the ground for three hours . ',\n",
       " \"I need 1,000 dollars in traveler 's checks . \",\n",
       " 'The official exchange rate is around 1,250 Won . ',\n",
       " 'Please give me three hundred dollar bills and twenty dollar bills for the rest . ',\n",
       " 'Can I have one hundred dollar bill and four fifty dollar bills ? ',\n",
       " 'Do you have change for $ 100 ? ',\n",
       " \"I 'd like to change 100 dollars . \",\n",
       " \"I 'd like to change $ 100 . \",\n",
       " 'Change 100 dollars . ',\n",
       " \"I 'd like to change 100 dollars . \",\n",
       " 'One hundred dollars . ',\n",
       " \"I want four 100 's , two 20 's , five 10 's and ten 1 's . \",\n",
       " '6 ten dollar bills and 8 five dollar bills , please . ',\n",
       " 'Could I have change for a one-hundred dollar bill ? ',\n",
       " \"I 'd like to change one hundred . \",\n",
       " 'I want four hundreds , three twenties , three tens , one five , and five ones . ',\n",
       " '100 miles is credited to your account . ',\n",
       " 'Five tens , and ten twenties , please . ',\n",
       " 'About 10 dollars . ',\n",
       " 'I want seven ten dollar bills and thirty one dollar bills . ',\n",
       " 'Two ten dollar bills , and two five dollar bills please . ',\n",
       " 'Make it 30 ten-dollar bills and small change . ',\n",
       " '8 ten-dollar bills and 4 five dollar bills , please . ',\n",
       " 'Fifty 10 dollar bills , please . ',\n",
       " 'Can I have change for this 10 dollar bill ? ',\n",
       " 'Could you give me small change for a ten dollar bill ? ',\n",
       " 'I will pay $ 10 in cash and the rest in credit card . ',\n",
       " '10dollars . ',\n",
       " 'Ten ten-dollar bills and ten one-dollar bills , please . ',\n",
       " 'Ten tens , ten fives , and fifty ones , please . ',\n",
       " '10 ten-dollar bills and 100 one-dollar bills , please . ',\n",
       " 'Twenty 10 dollar bills , forty 5 dollar bills . ',\n",
       " \"I 'd like three 10 's , two 5 's and ten 1 's . \",\n",
       " 'Four tens , four fives and the rest in singles , please . ',\n",
       " '4 tens , and the rest in one dollar bills . ',\n",
       " '7 ten dollar bills and 6 five dollar bills , please . ',\n",
       " '2 tens and the rest in one dollar bills . ',\n",
       " \"I 'd like three 10 dollar bills , and the rest in 1 dollar bills . \",\n",
       " 'Ten tens , five twenties and coins for the rest , please . ',\n",
       " \"I 'd like 10 ten-dollar bills , 20 five-dollar bills and 30 one-dollar bills . \",\n",
       " '10dollar bills , please . ',\n",
       " 'Could you give me ten one-dollar bill for this ten dollar bill ? ',\n",
       " 'Thirty ten-dollar bills and small change for ten dollars . ',\n",
       " 'Please change this for ten dollar bills . ',\n",
       " 'Ten dollar bills , please . ',\n",
       " 'Would you like tens or twenties ? ',\n",
       " 'In tens and twenties . ',\n",
       " '5 ten dollar bills , 15 five-dollar bills and 20 singles . ',\n",
       " 'I need six tens and small change for the rest . ',\n",
       " \"I 'd like to have 9 tens and the rest in fives . \",\n",
       " 'Could you change this 10 dollar bill for me ? ',\n",
       " \"I 'd like to have some tens and twenties . \",\n",
       " 'In 10 and 20 dollar bills . ',\n",
       " 'Do you like it in dimes ? ',\n",
       " 'This is 10 kilograms overweight . ',\n",
       " 'This is 12 kilograms overweight . ',\n",
       " 'There are 10 kinds of them . ',\n",
       " 'To upgrade to the diamond level requires 100,000 points or more . ',\n",
       " \"It 's Gate 10 . \",\n",
       " 'Could you tell me the way to Gate 10 ? ',\n",
       " 'Please proceed to Gate 10 . ',\n",
       " 'It will depart in ten minutes . ',\n",
       " '10 minutes . Never mind . ',\n",
       " 'October 11th . ',\n",
       " 'We reserved a seat for October 25th , eleven a.m. ',\n",
       " \"I 'd like to change the date to October 9th . \",\n",
       " \"I 'll be here for ten days . \",\n",
       " 'For 10 days . ',\n",
       " 'For about ten days . ',\n",
       " \"I 'll stay for 10 days . \",\n",
       " 'For 10 days . ',\n",
       " '10 days . ',\n",
       " 'For ten days . ',\n",
       " 'We have 10 different brands . ',\n",
       " 'Where is Gate 11 ? ',\n",
       " 'Would you tell me how to get to Gate 11 ? ',\n",
       " 'It departs at 11:00 . ',\n",
       " 'How about the 11th ? ',\n",
       " 'Where is seat 12B ? ',\n",
       " 'Where is seat 12B ? ',\n",
       " '12G is over there on the right side . ',\n",
       " 'Please go to Gate 12 . ',\n",
       " 'Please come to Gate 12 . ',\n",
       " \"It 's time for boarding now at Gate 12 . \",\n",
       " 'Boarding begins at 12:10 . ',\n",
       " 'The arrival time is twelve thirty local time . ',\n",
       " \"Let me have two seats on the 12 o'clock flight . \",\n",
       " 'I want to cancel my December 25 flight . ',\n",
       " 'I want to make it on December 27 . ',\n",
       " 'Please cancel my flight for December 4th . ',\n",
       " \"I 'd like to change the date to December 7th . \",\n",
       " 'Go to gate 13 , please . ',\n",
       " \"There 's 13 hour 's difference . \",\n",
       " 'One hundred forty dollars . Which seat do you prefer ? ',\n",
       " \"There 's a 14 hour 's difference between two cities . Seoul is 14 hours ahead . \",\n",
       " '15dollars , please . ',\n",
       " 'Where is seat 15A ? ',\n",
       " 'Your flight will depart from gate 15 . ',\n",
       " \"There 's a 15 hour 's difference . Seoul is 14 hours ahead . \"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_text_list[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MnpzEdbiOi2G",
    "outputId": "91208b61-6d24-41c3-99a4-f86cd6800b42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<id 1>',\n",
       " '<sent 1>',\n",
       " '1\\t2\\tNP\\t777/SN',\n",
       " '2\\t6\\tNP_SBJ\\t항공편/NNG|은/JX',\n",
       " '3\\t4\\tNP\\t1/SN|시간/NNG',\n",
       " '4\\t6\\tNP_AJT\\t동안/NNG',\n",
       " '5\\t6\\tNP_AJT\\t지상/NNG|에/JKB',\n",
       " '6\\t7\\tVP\\t머물/VV|게/EC',\n",
       " '7\\t0\\tVP\\t되/VV|ㅂ니다/EF|./SF',\n",
       " '</sent>',\n",
       " '</id>']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 한 문장씩 나눈 리스트 만들기\n",
    "sections = ko_lines.strip().split('\\n\\n')\n",
    "ko_list = [section.splitlines() for section in sections]\n",
    "\n",
    "ko_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SqzKjJKiQyu4"
   },
   "outputs": [],
   "source": [
    "# 필요한 정보만 추출\n",
    "import re\n",
    "\n",
    "pattern = r\"[가-힣ㄱ-ㅎ]+|[0-9]+(?=\\/SN)\"\n",
    "\n",
    "for i in range(len(ko_list)):\n",
    "    for j in range(len(ko_list[i])):\n",
    "        ko_list[i][j] = re.findall(pattern, ko_list[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "srP-_hvjQzRO",
    "outputId": "94e5216b-67c5-4e8e-b86a-a256278fd291"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[],\n",
       "  [],\n",
       "  ['777'],\n",
       "  ['항공편', '은'],\n",
       "  ['1', '시간'],\n",
       "  ['동안'],\n",
       "  ['지상', '에'],\n",
       "  ['머물', '게'],\n",
       "  ['되', 'ㅂ니다'],\n",
       "  [],\n",
       "  []],\n",
       " [[],\n",
       "  [],\n",
       "  ['777'],\n",
       "  ['항공편', '은'],\n",
       "  ['3', '시간'],\n",
       "  ['동안'],\n",
       "  ['지상', '에'],\n",
       "  ['있', '겠', '습니다'],\n",
       "  [],\n",
       "  []],\n",
       " [[], [], ['1', '000', '달러'], ['여행자', '수표', '가'], ['필요', '하', 'ㅂ니다'], [], []],\n",
       " [[], [], ['1', '250', '원', '이'], ['공식'], ['환율', '이', 'ㅂ니다'], [], []],\n",
       " [[],\n",
       "  [],\n",
       "  ['100', '달러'],\n",
       "  ['3', '장', '과'],\n",
       "  ['나머지', '는'],\n",
       "  ['20', '달러', '권', '으로'],\n",
       "  ['주', '시', 'ㅂ시오'],\n",
       "  [],\n",
       "  []],\n",
       " [[],\n",
       "  [],\n",
       "  ['100', '달러'],\n",
       "  ['한'],\n",
       "  ['장', '과'],\n",
       "  ['50', '달러'],\n",
       "  ['4', '장', '으로'],\n",
       "  ['바꾸', '어'],\n",
       "  ['주', '시', '겠', '어요'],\n",
       "  [],\n",
       "  []],\n",
       " [[], [], ['100', '달러', '를'], ['바꾸', '어'], ['주', '시', '겠', '어요'], [], []],\n",
       " [[], [], ['100', '달러', '만'], ['바꾸', '어'], ['주', '시', '어요'], [], []],\n",
       " [[],\n",
       "  [],\n",
       "  ['100', '달러', '만'],\n",
       "  ['환전'],\n",
       "  ['좀'],\n",
       "  ['하', '아'],\n",
       "  ['주', '시', '어요'],\n",
       "  [],\n",
       "  []],\n",
       " [[], [], ['100', '달러', '만'], ['환전', '하', '아'], ['주', '시', '어요'], [], []],\n",
       " [[], [], ['100', '달러', '만'], ['환전', '하', '아'], ['어', '주', '어', '요'], [], []],\n",
       " [[], [], ['100', '달러', '이', 'ㅂ니다'], [], []],\n",
       " [[],\n",
       "  [],\n",
       "  ['100', '달러', '짜리'],\n",
       "  ['4', '장'],\n",
       "  ['20', '달러', '짜리'],\n",
       "  ['2', '장'],\n",
       "  ['10', '달러', '짜리'],\n",
       "  ['5', '장'],\n",
       "  ['1', '달러', '짜리'],\n",
       "  ['10', '장', '으로'],\n",
       "  ['하', '아'],\n",
       "  ['주', '시', '어요'],\n",
       "  [],\n",
       "  []],\n",
       " [[],\n",
       "  [],\n",
       "  ['100', '달러', '짜리'],\n",
       "  ['지폐'],\n",
       "  ['6', '개'],\n",
       "  ['하', '고'],\n",
       "  ['5', '달러', '짜리'],\n",
       "  ['지폐'],\n",
       "  ['8', '개', '로'],\n",
       "  ['바꾸', '어'],\n",
       "  ['주', '시', '어요'],\n",
       "  [],\n",
       "  []],\n",
       " [[],\n",
       "  [],\n",
       "  ['100', '달러', '짜리'],\n",
       "  ['지폐', '를'],\n",
       "  ['잔돈', '으로'],\n",
       "  ['바꾸', 'ㄹ'],\n",
       "  ['수'],\n",
       "  ['있', '겠', '습니까'],\n",
       "  [],\n",
       "  []],\n",
       " [[], [], ['100', '불', '을'], ['바꾸', '겠', '습니다'], [], []],\n",
       " [[],\n",
       "  [],\n",
       "  ['100', '불', '짜리'],\n",
       "  ['4', '매'],\n",
       "  ['20', '불', '짜리'],\n",
       "  ['3', '매'],\n",
       "  ['10', '불', '짜리'],\n",
       "  ['3', '매'],\n",
       "  ['5', '불', '짜리'],\n",
       "  ['1', '매'],\n",
       "  ['그리고'],\n",
       "  ['1', '불', '짜리'],\n",
       "  ['5', '매'],\n",
       "  ['원하', 'ㅂ니다'],\n",
       "  [],\n",
       "  []],\n",
       " [[], [], ['100'], ['마일리지', '가'], ['적립', '되', '었', '습니다'], [], []],\n",
       " [[],\n",
       "  [],\n",
       "  ['10', '달러'],\n",
       "  ['5', '장', '과'],\n",
       "  ['20', '달러'],\n",
       "  ['10', '장', '으로'],\n",
       "  ['부탁', '하', 'ㅂ니다'],\n",
       "  [],\n",
       "  []],\n",
       " [[], [], ['10', '달러'], ['정도', '이', '에요'], [], []],\n",
       " [[],\n",
       "  [],\n",
       "  ['10', '달러'],\n",
       "  ['지폐'],\n",
       "  ['7', '장'],\n",
       "  ['1', '달러'],\n",
       "  ['지폐'],\n",
       "  ['30', '장'],\n",
       "  ['주', '시', '어요'],\n",
       "  [],\n",
       "  []],\n",
       " [[],\n",
       "  [],\n",
       "  ['10', '달러'],\n",
       "  ['지폐'],\n",
       "  ['두'],\n",
       "  ['장'],\n",
       "  ['5', '달러', '짜리'],\n",
       "  ['두'],\n",
       "  ['장'],\n",
       "  ['주', '어요'],\n",
       "  [],\n",
       "  []],\n",
       " [[],\n",
       "  [],\n",
       "  ['10', '달러'],\n",
       "  ['지폐'],\n",
       "  ['서른'],\n",
       "  ['장', '과'],\n",
       "  ['잔돈', '으로'],\n",
       "  ['부탁', '하', '아요'],\n",
       "  [],\n",
       "  []],\n",
       " [[],\n",
       "  [],\n",
       "  ['10', '달러'],\n",
       "  ['지폐'],\n",
       "  ['여덟'],\n",
       "  ['장하', '고'],\n",
       "  ['5', '달러'],\n",
       "  ['지폐'],\n",
       "  ['네'],\n",
       "  ['장', '으로'],\n",
       "  ['부탁', '하', '아요'],\n",
       "  [],\n",
       "  []],\n",
       " [[], [], ['10', '달러'], ['지폐', '로'], ['50', '장'], ['주', '시', '어요'], [], []],\n",
       " [[],\n",
       "  [],\n",
       "  ['10', '달러'],\n",
       "  ['지폐', '를'],\n",
       "  ['잔돈', '으로'],\n",
       "  ['바꾸', 'ㄹ'],\n",
       "  ['수'],\n",
       "  ['있', '습니까'],\n",
       "  [],\n",
       "  []],\n",
       " [[], [], ['10', '달러'], ['지폐', '를'], ['잔돈', '으로'], ['바꾸', 'ㄹ', '려고요'], [], []],\n",
       " [[],\n",
       "  [],\n",
       "  ['10', '달러', '는'],\n",
       "  ['현금', '으로'],\n",
       "  ['하', '고'],\n",
       "  ['나머지', '는'],\n",
       "  ['카드', '로'],\n",
       "  ['계산', '하', '아'],\n",
       "  ['주', '시', '어요'],\n",
       "  [],\n",
       "  []],\n",
       " [[], [], ['10', '달러', '이', 'ㅂ니다'], [], []],\n",
       " [[],\n",
       "  [],\n",
       "  ['10', '달러', '짜리'],\n",
       "  ['10', '장'],\n",
       "  ['1', '달러', '짜리'],\n",
       "  ['10', '장', '으로'],\n",
       "  ['바꾸', '어'],\n",
       "  ['주', '시', '어요'],\n",
       "  [],\n",
       "  []],\n",
       " [[],\n",
       "  [],\n",
       "  ['10', '달러', '짜리'],\n",
       "  ['10', '장'],\n",
       "  ['5', '달러', '짜리'],\n",
       "  ['10', '장'],\n",
       "  ['그리고'],\n",
       "  ['1', '달러', '짜리'],\n",
       "  ['50', '장', '으로'],\n",
       "  ['주', '시', '어요'],\n",
       "  [],\n",
       "  []],\n",
       " [[],\n",
       "  [],\n",
       "  ['10', '달러', '짜리'],\n",
       "  ['10', '장', '하', '고'],\n",
       "  ['1', '달러', '짜리'],\n",
       "  ['100', '장', '으로'],\n",
       "  ['부탁', '하', '아요'],\n",
       "  [],\n",
       "  []],\n",
       " [[],\n",
       "  [],\n",
       "  ['10', '달러', '짜리'],\n",
       "  ['20', '장'],\n",
       "  ['5', '달러', '짜리'],\n",
       "  ['40', '장', '으로'],\n",
       "  ['주', '시', '어요'],\n",
       "  [],\n",
       "  []],\n",
       " [[],\n",
       "  [],\n",
       "  ['10', '달러', '짜리'],\n",
       "  ['3', '장'],\n",
       "  ['5', '달러', '짜리'],\n",
       "  ['2', '장'],\n",
       "  ['1', '달러', '짜리'],\n",
       "  ['10', '장', '으로'],\n",
       "  ['바꾸', '어'],\n",
       "  ['주', '시', '어요'],\n",
       "  [],\n",
       "  []],\n",
       " [[],\n",
       "  [],\n",
       "  ['10', '달러', '짜리'],\n",
       "  ['4', '장'],\n",
       "  ['5', '달러', '짜리'],\n",
       "  ['4', '장'],\n",
       "  ['그리고'],\n",
       "  ['나머지', '는'],\n",
       "  ['1', '달러', '짜리', '로'],\n",
       "  ['부탁', '하', '아요'],\n",
       "  [],\n",
       "  []],\n",
       " [[],\n",
       "  [],\n",
       "  ['10', '달러', '짜리'],\n",
       "  ['4', '장', '하', '고'],\n",
       "  ['나머지', '는'],\n",
       "  ['1', '달러', '짜리', '로'],\n",
       "  ['주', '시', '어요'],\n",
       "  [],\n",
       "  []],\n",
       " [[],\n",
       "  [],\n",
       "  ['10', '달러', '짜리'],\n",
       "  ['7', '장'],\n",
       "  ['5', '달러', '짜리'],\n",
       "  ['6', '장', '으로'],\n",
       "  ['주', '시', '어요'],\n",
       "  [],\n",
       "  []],\n",
       " [[],\n",
       "  [],\n",
       "  ['10', '달러', '짜리'],\n",
       "  ['두'],\n",
       "  ['장이', '랑'],\n",
       "  ['나머지', '는'],\n",
       "  ['1', '달러', '로'],\n",
       "  ['주', '시', '어요'],\n",
       "  [],\n",
       "  []],\n",
       " [[],\n",
       "  [],\n",
       "  ['10', '달러', '짜리'],\n",
       "  ['세'],\n",
       "  ['장이', '랑'],\n",
       "  ['나머지', '는'],\n",
       "  ['1', '달러', '로'],\n",
       "  ['주', '어요'],\n",
       "  [],\n",
       "  []],\n",
       " [[],\n",
       "  [],\n",
       "  ['10', '달러', '짜리'],\n",
       "  ['열'],\n",
       "  ['장', '과'],\n",
       "  ['20', '달러', '짜리'],\n",
       "  ['다섯'],\n",
       "  ['장'],\n",
       "  ['그리고'],\n",
       "  ['나머지', '는'],\n",
       "  ['동전', '으로'],\n",
       "  ['주', '시', '어요'],\n",
       "  [],\n",
       "  []],\n",
       " [[],\n",
       "  [],\n",
       "  ['10', '달러', '짜리'],\n",
       "  ['지폐'],\n",
       "  ['10', '장'],\n",
       "  ['5', '달러', '짜리'],\n",
       "  ['지폐'],\n",
       "  ['20', '장'],\n",
       "  ['1', '달러'],\n",
       "  ['지폐'],\n",
       "  ['30', '장', '으로'],\n",
       "  ['주', '시', '어요'],\n",
       "  [],\n",
       "  []],\n",
       " [[], [], ['10', '달러', '짜리'], ['지폐', '로'], ['주', '시', '어요'], [], []],\n",
       " [[],\n",
       "  [],\n",
       "  ['10', '달러', '짜리'],\n",
       "  ['지폐', '를'],\n",
       "  ['1', '달러', '짜리'],\n",
       "  ['열'],\n",
       "  ['장', '으로'],\n",
       "  ['바꾸', '어'],\n",
       "  ['주', '시', '어요'],\n",
       "  [],\n",
       "  []],\n",
       " [[],\n",
       "  [],\n",
       "  ['10', '달러', '짜리', '가'],\n",
       "  ['서른'],\n",
       "  ['10', '달러', '는'],\n",
       "  ['잔돈', '이', 'ㅂ니다'],\n",
       "  [],\n",
       "  []],\n",
       " [[], [], ['10', '달러', '짜리', '로'], ['바꾸', '어'], ['주', '시', '어요'], [], []],\n",
       " [[], [], ['10', '달러', '짜리', '로'], ['주', '시', '어요'], [], []],\n",
       " [[],\n",
       "  [],\n",
       "  ['10', '달러', '짜리', '로'],\n",
       "  ['하', 'ㄹ까요'],\n",
       "  ['아니', '면'],\n",
       "  ['20', '달러', '짜리', '로'],\n",
       "  ['하', 'ㄹ까요'],\n",
       "  [],\n",
       "  []],\n",
       " [[],\n",
       "  [],\n",
       "  ['10', '달러', '짜리', '와'],\n",
       "  ['20', '달러', '짜리', '로'],\n",
       "  ['주', '시', '어요'],\n",
       "  [],\n",
       "  []],\n",
       " [[],\n",
       "  [],\n",
       "  ['10', '불', '짜리'],\n",
       "  ['5', '장'],\n",
       "  ['5', '불', '짜리'],\n",
       "  ['15', '장'],\n",
       "  ['1', '불', '짜리'],\n",
       "  ['20', '장', '으로'],\n",
       "  ['주', '시', '어요'],\n",
       "  [],\n",
       "  []],\n",
       " [[],\n",
       "  [],\n",
       "  ['10', '불', '짜리'],\n",
       "  ['6', '장'],\n",
       "  ['그리고'],\n",
       "  ['나머지', '는'],\n",
       "  ['잔돈', '으로'],\n",
       "  ['주', '시', '어요'],\n",
       "  [],\n",
       "  []]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ko_list[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6qqBwr8xQ6NB"
   },
   "outputs": [],
   "source": [
    "# 문장으로 만들어서 리스트에 넣어주기, 각 문장에 <sos>, <eos> 넣어주기\n",
    "ko_text_list = []\n",
    "\n",
    "for i in range(len(ko_list)):\n",
    "    sent = ''\n",
    "    for j in range(len(ko_list[i])):\n",
    "        if ko_list[i][j]:\n",
    "            for token in ko_list[i][j]:\n",
    "                sent += token + ' '\n",
    "    ko_text_list.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AgZhhw8DRBJL",
    "outputId": "9f41c6ac-87ac-43cb-9ed3-973433e1d82e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['777 항공편 은 1 시간 동안 지상 에 머물 게 되 ㅂ니다 ',\n",
       " '777 항공편 은 3 시간 동안 지상 에 있 겠 습니다 ',\n",
       " '1 000 달러 여행자 수표 가 필요 하 ㅂ니다 ',\n",
       " '1 250 원 이 공식 환율 이 ㅂ니다 ',\n",
       " '100 달러 3 장 과 나머지 는 20 달러 권 으로 주 시 ㅂ시오 ',\n",
       " '100 달러 한 장 과 50 달러 4 장 으로 바꾸 어 주 시 겠 어요 ',\n",
       " '100 달러 를 바꾸 어 주 시 겠 어요 ',\n",
       " '100 달러 만 바꾸 어 주 시 어요 ',\n",
       " '100 달러 만 환전 좀 하 아 주 시 어요 ',\n",
       " '100 달러 만 환전 하 아 주 시 어요 ',\n",
       " '100 달러 만 환전 하 아 어 주 어 요 ',\n",
       " '100 달러 이 ㅂ니다 ',\n",
       " '100 달러 짜리 4 장 20 달러 짜리 2 장 10 달러 짜리 5 장 1 달러 짜리 10 장 으로 하 아 주 시 어요 ',\n",
       " '100 달러 짜리 지폐 6 개 하 고 5 달러 짜리 지폐 8 개 로 바꾸 어 주 시 어요 ',\n",
       " '100 달러 짜리 지폐 를 잔돈 으로 바꾸 ㄹ 수 있 겠 습니까 ',\n",
       " '100 불 을 바꾸 겠 습니다 ',\n",
       " '100 불 짜리 4 매 20 불 짜리 3 매 10 불 짜리 3 매 5 불 짜리 1 매 그리고 1 불 짜리 5 매 원하 ㅂ니다 ',\n",
       " '100 마일리지 가 적립 되 었 습니다 ',\n",
       " '10 달러 5 장 과 20 달러 10 장 으로 부탁 하 ㅂ니다 ',\n",
       " '10 달러 정도 이 에요 ',\n",
       " '10 달러 지폐 7 장 1 달러 지폐 30 장 주 시 어요 ',\n",
       " '10 달러 지폐 두 장 5 달러 짜리 두 장 주 어요 ',\n",
       " '10 달러 지폐 서른 장 과 잔돈 으로 부탁 하 아요 ',\n",
       " '10 달러 지폐 여덟 장하 고 5 달러 지폐 네 장 으로 부탁 하 아요 ',\n",
       " '10 달러 지폐 로 50 장 주 시 어요 ',\n",
       " '10 달러 지폐 를 잔돈 으로 바꾸 ㄹ 수 있 습니까 ',\n",
       " '10 달러 지폐 를 잔돈 으로 바꾸 ㄹ 려고요 ',\n",
       " '10 달러 는 현금 으로 하 고 나머지 는 카드 로 계산 하 아 주 시 어요 ',\n",
       " '10 달러 이 ㅂ니다 ',\n",
       " '10 달러 짜리 10 장 1 달러 짜리 10 장 으로 바꾸 어 주 시 어요 ',\n",
       " '10 달러 짜리 10 장 5 달러 짜리 10 장 그리고 1 달러 짜리 50 장 으로 주 시 어요 ',\n",
       " '10 달러 짜리 10 장 하 고 1 달러 짜리 100 장 으로 부탁 하 아요 ',\n",
       " '10 달러 짜리 20 장 5 달러 짜리 40 장 으로 주 시 어요 ',\n",
       " '10 달러 짜리 3 장 5 달러 짜리 2 장 1 달러 짜리 10 장 으로 바꾸 어 주 시 어요 ',\n",
       " '10 달러 짜리 4 장 5 달러 짜리 4 장 그리고 나머지 는 1 달러 짜리 로 부탁 하 아요 ',\n",
       " '10 달러 짜리 4 장 하 고 나머지 는 1 달러 짜리 로 주 시 어요 ',\n",
       " '10 달러 짜리 7 장 5 달러 짜리 6 장 으로 주 시 어요 ',\n",
       " '10 달러 짜리 두 장이 랑 나머지 는 1 달러 로 주 시 어요 ',\n",
       " '10 달러 짜리 세 장이 랑 나머지 는 1 달러 로 주 어요 ',\n",
       " '10 달러 짜리 열 장 과 20 달러 짜리 다섯 장 그리고 나머지 는 동전 으로 주 시 어요 ',\n",
       " '10 달러 짜리 지폐 10 장 5 달러 짜리 지폐 20 장 1 달러 지폐 30 장 으로 주 시 어요 ',\n",
       " '10 달러 짜리 지폐 로 주 시 어요 ',\n",
       " '10 달러 짜리 지폐 를 1 달러 짜리 열 장 으로 바꾸 어 주 시 어요 ',\n",
       " '10 달러 짜리 가 서른 10 달러 는 잔돈 이 ㅂ니다 ',\n",
       " '10 달러 짜리 로 바꾸 어 주 시 어요 ',\n",
       " '10 달러 짜리 로 주 시 어요 ',\n",
       " '10 달러 짜리 로 하 ㄹ까요 아니 면 20 달러 짜리 로 하 ㄹ까요 ',\n",
       " '10 달러 짜리 와 20 달러 짜리 로 주 시 어요 ',\n",
       " '10 불 짜리 5 장 5 불 짜리 15 장 1 불 짜리 20 장 으로 주 시 어요 ',\n",
       " '10 불 짜리 6 장 그리고 나머지 는 잔돈 으로 주 시 어요 ',\n",
       " '10 불 짜리 9 장 나머지 는 5 불 짜리 로 주 시 어요 ',\n",
       " '10 불 짜리 를 바꾸 어 주 시 겠 어요 ',\n",
       " '10 불 짜리 와 20 불 짜리 로 주 시 어요 ',\n",
       " '10 불 하 고 20 불 짜리로요 ',\n",
       " '10 센트 로 드리 ㄹ 까요 ',\n",
       " '10 무게 초과 되 시 었 습니다 ',\n",
       " '12 초과 이 ㅂ니다 ',\n",
       " '10 가지 종류 가 있 는데요 ',\n",
       " '10 만 점 이상 부터 다이아몬드 등급 으로 상향 조정 되 ㅂ니다 ',\n",
       " '10 번 게이트 이 ㅂ니다 ',\n",
       " '10 번 출구 로 가 는 길 을 알리 러 주 시 겠 습니까 ',\n",
       " '10 번 출구 로 가 시 어요 ',\n",
       " '10 분 후 에 출발 하 ㅂ니다 ',\n",
       " '10 분 이 ㅂ니다 신경 쓰 지 말 시 어요 ',\n",
       " '10 월 11 일 이 ㅂ니다 ',\n",
       " '10 월 25 일 오전 11 시 발 비행 편 에 예약 되 었 습니다 ',\n",
       " '10 월 9 일 로 변경 하 고 싶 은데요 ',\n",
       " '10 일 동안 있 을 거 이 에요 ',\n",
       " '열흘 동안 이 요 ',\n",
       " '십 일 정도 ',\n",
       " '열흘 간 머무르 ㄹ 려구요 ',\n",
       " '십 일 간 이 ㅂ니다 ',\n",
       " '10 일 이 요 ',\n",
       " '10 일 이 요 ',\n",
       " '10 종류 의 상표 가 있 어요 ',\n",
       " '11 번 게이트 는 어디 에 있 나요 ',\n",
       " '11 번 게이트 에 어떻 게 가 는지 알리 러 주 시 겠 어요 ',\n",
       " '11 시 에 출발 하 ㅂ니다 ',\n",
       " '11 일 은 어떻 어요 ',\n",
       " '12 자리 가 어디 죠 ',\n",
       " '12 좌석 은 어디 이 ㅂ니까 ',\n",
       " '12 좌석 은 저기 오른쪽 에 있 습니다 ',\n",
       " '12 번 게이트 로 가 시 어요 ',\n",
       " '12 번 게이트 로 오 시 어요 ',\n",
       " '12 번 창구 에서 지금 탑승 하 시 ㅂ시오 ',\n",
       " '12 시 10 분 에 탑승 을 시작 하 ㅂ니다 ',\n",
       " '12 시 30 분 에 도착 예정 이 ㅂ니다 ',\n",
       " '12 시 편 두 장 주 시 어요 ',\n",
       " '12 월 25 일 편 을 취소 하 고 싶 은데요 ',\n",
       " '12 월 27 일 로 하 아 주 시 어요 ',\n",
       " '12 월 4 일 예약 취소 하 아 어 주 어 요 ',\n",
       " '12 월 7 일 로 날짜 를 바꾸 고 싶 은데요 ',\n",
       " '13 번 게이트 로 가 시 어요 ',\n",
       " '13 시간 의 시차 가 있 습니다 ',\n",
       " '140 달러 이 ㅂ니다 어느 쪽 좌석 을 원하 시 어요 ',\n",
       " '14 시간 의 시차 가 있 습니다 서울 이 14 시간 빠르 죠 ',\n",
       " '15 달러 이 ㅂ니다 ',\n",
       " '15 좌석 은 어디 이 에요 ',\n",
       " '15 번 탑승구 는 번 중앙 홀 에 있 습니다 ',\n",
       " '15 시간 이 ㅂ니다 서울 이 14 시간 빠릅 니다 ']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ko_text_list[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2RnRaygS1Rt"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C6Yd4BkgRQtl",
    "outputId": "037e3798-e100-4f76-b6af-904bed7d0f4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Flight 007 will stay on the ground for one hour . ', 'Flight 017 will stay on the ground for three hours . ', \"I need 1,000 dollars in traveler 's checks . \", 'The official exchange rate is around 1,250 Won . ', 'Please give me three hundred dollar bills and twenty dollar bills for the rest . ', 'Can I have one hundred dollar bill and four fifty dollar bills ? ', 'Do you have change for $ 100 ? ', \"I 'd like to change 100 dollars . \", \"I 'd like to change $ 100 . \", 'Change 100 dollars . ']\n",
      "['777 항공편 은 1 시간 동안 지상 에 머물 게 되 ㅂ니다 ', '777 항공편 은 3 시간 동안 지상 에 있 겠 습니다 ', '1 000 달러 여행자 수표 가 필요 하 ㅂ니다 ', '1 250 원 이 공식 환율 이 ㅂ니다 ', '100 달러 3 장 과 나머지 는 20 달러 권 으로 주 시 ㅂ시오 ', '100 달러 한 장 과 50 달러 4 장 으로 바꾸 어 주 시 겠 어요 ', '100 달러 를 바꾸 어 주 시 겠 어요 ', '100 달러 만 바꾸 어 주 시 어요 ', '100 달러 만 환전 좀 하 아 주 시 어요 ', '100 달러 만 환전 하 아 주 시 어요 ']\n"
     ]
    }
   ],
   "source": [
    "print(en_text_list[:10])\n",
    "print(ko_text_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VdraG3QHb7iN"
   },
   "outputs": [],
   "source": [
    "assert len(en_text_list) == len(ko_text_list), \"Lists must be of equal length.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pPAx5n8cexqx"
   },
   "outputs": [],
   "source": [
    "sos_token = \"<sos>\"\n",
    "eos_token = \"<eos>\"\n",
    "\n",
    "def tokenize_with_special_tokens(text, type): # type: 0 for en, 1 for ko\n",
    "    if type == 0:\n",
    "        tokens = [token.lower() for token in text.split()]\n",
    "    else:\n",
    "        tokens = [token for token in text.split()]\n",
    "\n",
    "    return [sos_token] + tokens + [eos_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZcvTOegdeMhs",
    "outputId": "95ea1a88-196f-4d08-e5f9-cbb96103cbb5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'Does your watch keep good time ? ',\n",
       " 'ko': '당신 시계 는 잘 맞 아요 ',\n",
       " 'en_tokens': ['<sos>',\n",
       "  'does',\n",
       "  'your',\n",
       "  'watch',\n",
       "  'keep',\n",
       "  'good',\n",
       "  'time',\n",
       "  '?',\n",
       "  '<eos>'],\n",
       " 'ko_tokens': ['<sos>', '당신', '시계', '는', '잘', '맞', '아요', '<eos>']}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    {\n",
    "        \"en\": en_text,\n",
    "        \"ko\": ko_text,\n",
    "        \"en_tokens\": tokenize_with_special_tokens(en_text, 0),\n",
    "        \"ko_tokens\": tokenize_with_special_tokens(ko_text, 1),\n",
    "    }\n",
    "    for en_text, ko_text in zip(en_text_list, ko_text_list)\n",
    "]\n",
    "\n",
    "# Shuffle the data to randomize for train-test split.\n",
    "random.shuffle(data)\n",
    "\n",
    "# Define split ratios.\n",
    "train_ratio, valid_ratio, test_ratio = 0.8, 0.1, 0.1\n",
    "train_size = int(len(data) * train_ratio)\n",
    "valid_size = int(len(data) * valid_ratio)\n",
    "\n",
    "# Split the data.\n",
    "train_data = data[:train_size]\n",
    "valid_data = data[train_size:train_size + valid_size]\n",
    "test_data = data[train_size + valid_size:]\n",
    "\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBuiOfLQfNHL"
   },
   "source": [
    "## Vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBg3aQwkfOeg"
   },
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "# Collect all tokens from train_data for each language\n",
    "def yield_tokens(data, key):\n",
    "    for sample in data:\n",
    "        yield sample[key]\n",
    "\n",
    "# Define special tokens\n",
    "min_freq = 2\n",
    "unk_token = \"<unk>\"\n",
    "pad_token = \"<pad>\"\n",
    "sos_token = \"<sos>\"\n",
    "eos_token = \"<eos>\"\n",
    "\n",
    "special_tokens = [\n",
    "    unk_token,\n",
    "    pad_token,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "]\n",
    "\n",
    "# Build vocabularies using the token iterator\n",
    "en_vocab = build_vocab_from_iterator(\n",
    "    yield_tokens(train_data, \"en_tokens\"),\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    ")\n",
    "\n",
    "ko_vocab = build_vocab_from_iterator(\n",
    "    yield_tokens(train_data, \"ko_tokens\"),\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C8htNAJQfvAl",
    "outputId": "c9982989-b645-4233-a524-bf4456d5220b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', '<sos>', '<eos>', '.', '?', 'i', 'you', 'the', 'to']\n",
      "['<unk>', '<pad>', '<sos>', '<eos>', '이', '하', '시', '어요', '는', '가']\n"
     ]
    }
   ],
   "source": [
    "print(en_vocab.get_itos()[:10])\n",
    "print(ko_vocab.get_itos()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2t5BufRbf26l",
    "outputId": "fe2ce76b-a877-433c-b913-286d9b2fd3c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14212, 15986)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_vocab), len(ko_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kmxznXBWf7xg"
   },
   "outputs": [],
   "source": [
    "assert en_vocab[unk_token] == ko_vocab[unk_token]\n",
    "assert en_vocab[pad_token] == ko_vocab[pad_token]\n",
    "\n",
    "unk_index = en_vocab[unk_token]\n",
    "pad_index = en_vocab[pad_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_zmAh0Oef9qm"
   },
   "outputs": [],
   "source": [
    "en_vocab.set_default_index(unk_index)\n",
    "ko_vocab.set_default_index(unk_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "wHIUqhPQgETb",
    "outputId": "ba558a11-ba90-4fce-9d68-556c514912b5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab.get_itos()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-Fw0tMWgGxi",
    "outputId": "aad22fad-03de-4f08-82a2-41538ed3dc9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 525, 1484, 5537, 1785]\n",
      "['i', 'love', 'watching', 'crime', 'shows']\n"
     ]
    }
   ],
   "source": [
    "tokens = [\"i\", \"love\", \"watching\", \"crime\", \"shows\"]\n",
    "\n",
    "print(en_vocab.lookup_indices(tokens))\n",
    "print(en_vocab.lookup_tokens(en_vocab.lookup_indices(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ca5s9MphjUN"
   },
   "outputs": [],
   "source": [
    "def numericalize_example(example, en_vocab, ko_vocab):\n",
    "    en_ids = en_vocab.lookup_indices(example[\"en_tokens\"])\n",
    "    ko_ids = ko_vocab.lookup_indices(example[\"ko_tokens\"])\n",
    "    return {\"en\": example[\"en\"], \"ko\": example[\"ko\"], \"en_tokens\": example[\"en_tokens\"], \"ko_tokens\": example[\"ko_tokens\"], \"en_ids\": en_ids, \"ko_ids\": ko_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vUS4uy58hnyP"
   },
   "outputs": [],
   "source": [
    "fn_kwargs = {\"en_vocab\": en_vocab, \"ko_vocab\": ko_vocab}\n",
    "\n",
    "train_data = [numericalize_example(example, **fn_kwargs) for example in train_data]\n",
    "valid_data = [numericalize_example(example, **fn_kwargs) for example in valid_data]\n",
    "test_data = [numericalize_example(example, **fn_kwargs) for example in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I5Uh50CggrCX",
    "outputId": "c37254c7-672c-4cce-d4b4-d62476114ac8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'Does your watch keep good time ? ',\n",
       " 'ko': '당신 시계 는 잘 맞 아요 ',\n",
       " 'en_tokens': ['<sos>',\n",
       "  'does',\n",
       "  'your',\n",
       "  'watch',\n",
       "  'keep',\n",
       "  'good',\n",
       "  'time',\n",
       "  '?',\n",
       "  '<eos>'],\n",
       " 'ko_tokens': ['<sos>', '당신', '시계', '는', '잘', '맞', '아요', '<eos>'],\n",
       " 'en_ids': [2, 49, 30, 370, 192, 80, 51, 5, 3],\n",
       " 'ko_ids': [2, 79, 640, 8, 86, 167, 46, 3]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4o_ZMGGJiGnQ",
    "outputId": "995bf006-190e-41bf-859f-94b121967b85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>', 'does', 'your', 'watch', 'keep', 'good', 'time', '?', '<eos>']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab.lookup_tokens(train_data[0][\"en_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VpEcjmiJiKKa",
    "outputId": "bedcf7be-6caa-41ad-9d69-0e936efae028"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 'Does your watch keep good time ? ', 'ko': '당신 시계 는 잘 맞 아요 ', 'en_tokens': ['<sos>', 'does', 'your', 'watch', 'keep', 'good', 'time', '?', '<eos>'], 'ko_tokens': ['<sos>', '당신', '시계', '는', '잘', '맞', '아요', '<eos>'], 'en_ids': tensor([  2,  49,  30, 370, 192,  80,  51,   5,   3]), 'ko_ids': tensor([  2,  79, 640,   8,  86, 167,  46,   3])}\n",
      "{'en': 'Would you please tell me how to open this gateway ? ', 'ko': '이 출입구 열 는 법 을 가르치 어 주 시 겠 습니까 ', 'en_tokens': ['<sos>', 'would', 'you', 'please', 'tell', 'me', 'how', 'to', 'open', 'this', 'gateway', '?', '<eos>'], 'ko_tokens': ['<sos>', '이', '출입구', '열', '는', '법', '을', '가르치', '어', '주', '시', '겠', '습니까', '<eos>'], 'en_ids': tensor([   2,   46,    7,   23,   87,   22,   18,    9,  212,   20, 9497,    5,\n",
      "           3]), 'ko_ids': tensor([   2,    4, 4123,  367,    8,  895,   12,  146,   17,   14,    6,   21,\n",
      "          26,    3])}\n",
      "{'en': \"I 'm looking for marine products . \", 'ko': '수산물 을 찾 고 있 는데요 ', 'en_tokens': ['<sos>', 'i', \"'m\", 'looking', 'for', 'marine', 'products', '.', '<eos>'], 'ko_tokens': ['<sos>', '수산물', '을', '찾', '고', '있', '는데요', '<eos>'], 'en_ids': tensor([   2,    6,   33,  184,   17, 6346,  689,    4,    3]), 'ko_ids': tensor([  2,   0,  12, 122,  22,  11,  85,   3])}\n"
     ]
    }
   ],
   "source": [
    "data_type = \"torch\"\n",
    "format_columns = [\"en_ids\", \"ko_ids\"]\n",
    "\n",
    "for example in train_data:\n",
    "    for column in format_columns:\n",
    "        example[column] = torch.tensor(example[column], dtype=torch.long)\n",
    "\n",
    "for example in valid_data:\n",
    "    for column in format_columns:\n",
    "        example[column] = torch.tensor(example[column], dtype=torch.long)\n",
    "\n",
    "for example in test_data:\n",
    "    for column in format_columns:\n",
    "        example[column] = torch.tensor(example[column], dtype=torch.long)\n",
    "\n",
    "print(train_data[0])\n",
    "print(valid_data[0])\n",
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YV9jRsL1i-So",
    "outputId": "e5b578d2-3e35-4036-990f-08ab53dd276a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data[0][\"en_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZDHDYoijAah"
   },
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wQmnccV4jCqF"
   },
   "outputs": [],
   "source": [
    "def get_collate_fn(pad_index):\n",
    "    def collate_fn(batch):\n",
    "        batch_en_ids = [example[\"en_ids\"] for example in batch]\n",
    "        batch_ko_ids = [example[\"ko_ids\"] for example in batch]\n",
    "        batch_en_ids = nn.utils.rnn.pad_sequence(batch_en_ids, padding_value=pad_index)\n",
    "        batch_ko_ids = nn.utils.rnn.pad_sequence(batch_ko_ids, padding_value=pad_index)\n",
    "        batch = {\n",
    "            \"en_ids\": batch_en_ids,\n",
    "            \"ko_ids\": batch_ko_ids,\n",
    "        }\n",
    "        return batch\n",
    "\n",
    "    return collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r59buVhtjG2T"
   },
   "outputs": [],
   "source": [
    "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
    "    collate_fn = get_collate_fn(pad_index)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xmhmwJK1jJQy"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_data_loader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\n",
    "valid_data_loader = get_data_loader(valid_data, batch_size, pad_index)\n",
    "test_data_loader = get_data_loader(test_data, batch_size, pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-c_zBnEyxwCN",
    "outputId": "64fdb61b-9201-43ca-e0a5-f2f5fabd26aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23, 128])\n",
      "torch.Size([27, 128])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_data_loader))\n",
    "\n",
    "print(batch['en_ids'].shape)\n",
    "print(batch['ko_ids'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAy9HeoB-SP9"
   },
   "source": [
    "# Encoder-decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jdZgjCDnVCR8"
   },
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zcNNik0bVBK_"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src = [src length, batch size]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # embedded = [src length, batch size, embedding dim]\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        # outputs = [src length, batch size, hidden dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # outputs are always from the top hidden layer\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YUzmkg5TWzUI"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        # input = [batch size]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # n directions in the decoder will both always be 1, therefore:\n",
    "        # hidden = [n layers, batch size, hidden dim]\n",
    "        # context = [n layers, batch size, hidden dim]\n",
    "        input = input.unsqueeze(0)\n",
    "        # input = [1, batch size]\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # embedded = [1, batch size, embedding dim]\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        # output = [seq length, batch size, hidden dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # seq length and n directions will always be 1 in this decoder, therefore:\n",
    "        # output = [1, batch size, hidden dim]\n",
    "        # hidden = [n layers, batch size, hidden dim]\n",
    "        # cell = [n layers, batch size, hidden dim]\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        # prediction = [batch size, output dim]\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tngePtR8W4fE"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        assert (\n",
    "            encoder.hidden_dim == decoder.hidden_dim\n",
    "        ), \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert (\n",
    "            encoder.n_layers == decoder.n_layers\n",
    "        ), \"Encoder and decoder must have equal number of layers!\"\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio):\n",
    "        # src = [src length, batch size]\n",
    "        # trg = [trg length, batch size]\n",
    "        # teacher_forcing_ratio is probability to use teacher forcing\n",
    "        # e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_length = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        # tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_length, batch_size, trg_vocab_size).to(self.device)\n",
    "        # last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        hidden, cell = self.encoder(src)\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # first input to the decoder is the <sos> tokens\n",
    "        input = trg[0, :]\n",
    "        # input = [batch size]\n",
    "        for t in range(1, trg_length):\n",
    "            # insert input token embedding, previous hidden and previous cell states\n",
    "            # receive output tensor (predictions) and new hidden and cell states\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            # output = [batch size, output dim]\n",
    "            # hidden = [n layers, batch size, hidden dim]\n",
    "            # cell = [n layers, batch size, hidden dim]\n",
    "            # place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            # decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            # get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1)\n",
    "            # if teacher forcing, use actual next token as next input\n",
    "            # if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "            # input = [batch size]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzcTY231Vmo-"
   },
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9VvdHm3GW9LK"
   },
   "outputs": [],
   "source": [
    "input_dim = len(ko_vocab)\n",
    "output_dim = len(en_vocab)\n",
    "encoder_embedding_dim = 256\n",
    "decoder_embedding_dim = 256\n",
    "hidden_dim = 512\n",
    "n_layers = 2\n",
    "encoder_dropout = 0.5\n",
    "decoder_dropout = 0.5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "encoder = Encoder(\n",
    "    input_dim,\n",
    "    encoder_embedding_dim,\n",
    "    hidden_dim,\n",
    "    n_layers,\n",
    "    encoder_dropout,\n",
    ")\n",
    "\n",
    "decoder = Decoder(\n",
    "    output_dim,\n",
    "    decoder_embedding_dim,\n",
    "    hidden_dim,\n",
    "    n_layers,\n",
    "    decoder_dropout,\n",
    ")\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HfzotopeXY5J",
    "outputId": "bcb507bd-09b1-4127-f62a-944ed64d9212"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(15986, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(14212, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=512, out_features=14212, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KwVvrSWlXbkI",
    "outputId": "d3f83323-b5a0-4f60-ddf7-fe7c71ca83f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 22,377,860 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lbpCK0ZqXd3i"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJEHPRMfXeX3"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9YuIHnKYQSu"
   },
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lxQao88b_tMo"
   },
   "outputs": [],
   "source": [
    "def train_fn(\n",
    "    model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device\n",
    "):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        src = batch[\"ko_ids\"].to(device)\n",
    "        trg = batch[\"en_ids\"].to(device)\n",
    "        # src = [src length, batch size]\n",
    "        # trg = [trg length, batch size]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg, teacher_forcing_ratio)\n",
    "        # output = [trg length, batch size, trg vocab size]\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        # output = [(trg length - 1) * batch size, trg vocab size]\n",
    "        trg = trg[1:].view(-1)\n",
    "        # trg = [(trg length - 1) * batch size]\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0uVB205YRjl"
   },
   "source": [
    "### Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zMVchV1fYS9l"
   },
   "outputs": [],
   "source": [
    "def evaluate_fn(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            src = batch[\"ko_ids\"].to(device)\n",
    "            trg = batch[\"en_ids\"].to(device)\n",
    "            # src = [src length, batch size]\n",
    "            # trg = [trg length, batch size]\n",
    "            output = model(src, trg, 0)  # turn off teacher forcing\n",
    "            # output = [trg length, batch size, trg vocab size]\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            # output = [(trg length - 1) * batch size, trg vocab size]\n",
    "            trg = trg[1:].view(-1)\n",
    "            # trg = [(trg length - 1) * batch size]\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWE7tB23YZQT"
   },
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jC7s0cfZYdhd",
    "outputId": "e5de0f8d-2204-43e1-935c-fe17248edd8f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [04:16<38:24, 256.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   4.324 | Train PPL:  75.502\n",
      "\tValid Loss:   4.344 | Valid PPL:  76.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 20%|██        | 2/10 [08:31<34:06, 255.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   3.188 | Train PPL:  24.234\n",
      "\tValid Loss:   3.462 | Valid PPL:  31.884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 30%|███       | 3/10 [12:47<29:50, 255.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   2.652 | Train PPL:  14.180\n",
      "\tValid Loss:   3.147 | Valid PPL:  23.256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 40%|████      | 4/10 [17:02<25:32, 255.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   2.337 | Train PPL:  10.350\n",
      "\tValid Loss:   2.935 | Valid PPL:  18.829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 50%|█████     | 5/10 [21:18<21:19, 255.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   2.122 | Train PPL:   8.352\n",
      "\tValid Loss:   2.776 | Valid PPL:  16.057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 60%|██████    | 6/10 [25:35<17:04, 256.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   1.955 | Train PPL:   7.067\n",
      "\tValid Loss:   2.721 | Valid PPL:  15.188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 70%|███████   | 7/10 [29:50<12:47, 255.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   1.830 | Train PPL:   6.234\n",
      "\tValid Loss:   2.648 | Valid PPL:  14.123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 80%|████████  | 8/10 [34:06<08:31, 255.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   1.728 | Train PPL:   5.628\n",
      "\tValid Loss:   2.595 | Valid PPL:  13.402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 90%|█████████ | 9/10 [38:22<04:15, 255.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   1.656 | Train PPL:   5.238\n",
      "\tValid Loss:   2.543 | Valid PPL:  12.720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [42:38<00:00, 255.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   1.583 | Train PPL:   4.870\n",
      "\tValid Loss:   2.514 | Valid PPL:  12.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "clip = 1.0\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "for epoch in tqdm.tqdm(range(n_epochs)):\n",
    "    train_loss = train_fn(\n",
    "        model,\n",
    "        train_data_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        clip,\n",
    "        teacher_forcing_ratio,\n",
    "        device,\n",
    "    )\n",
    "    valid_loss = evaluate_fn(\n",
    "        model,\n",
    "        valid_data_loader,\n",
    "        criterion,\n",
    "        device,\n",
    "    )\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), \"encoder-decoder-model.pt\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n",
    "    print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFuLbElMjugT"
   },
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oCtMCvakjxap",
    "outputId": "f88c081b-f9e2-442d-a45f-2401a17a87aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 2.508 | Test PPL:  12.286 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"encoder-decoder-model.pt\"))\n",
    "\n",
    "test_loss = evaluate_fn(model, test_data_loader, criterion, device)\n",
    "\n",
    "print(f\"| Test Loss: {test_loss:.3f} | Test PPL: {np.exp(test_loss):7.3f} |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdH4f9wyVpWv"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bog0VPM-ZwVf"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def translate_sentence(\n",
    "    sentence,\n",
    "    model,\n",
    "    en_vocab,\n",
    "    ko_vocab,\n",
    "    sos_token=\"<sos>\",\n",
    "    eos_token=\"<eos>\",\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    max_output_length=25,\n",
    "    lower=True\n",
    "):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if isinstance(sentence, str):\n",
    "            tokens = sentence.split()\n",
    "        else:\n",
    "            tokens = [token for token in sentence]\n",
    "        if lower:\n",
    "            tokens = [token.lower() for token in tokens]\n",
    "        tokens = [sos_token] + tokens + [eos_token]\n",
    "        ids = ko_vocab.lookup_indices(tokens)\n",
    "        tensor = torch.LongTensor(ids).unsqueeze(1).to(device)\n",
    "        hidden, cell = model.encoder(tensor)\n",
    "        inputs = en_vocab.lookup_indices([sos_token])\n",
    "        for _ in range(max_output_length):\n",
    "            inputs_tensor = torch.LongTensor([inputs[-1]]).to(device)\n",
    "            output, hidden, cell = model.decoder(inputs_tensor, hidden, cell)\n",
    "            predicted_token = output.argmax(-1).item()\n",
    "            inputs.append(predicted_token)\n",
    "            if predicted_token == en_vocab[eos_token]:\n",
    "                break\n",
    "        tokens = en_vocab.lookup_tokens(inputs)\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AODTXsJs-DV5"
   },
   "outputs": [],
   "source": [
    "sen_list = [\n",
    "'모든 액체 , 젤 , 에어로졸 등 은 1 커트 짜리 여닫이 투명 봉지 하나 에 넣 어야 하 ㅂ니다 .',\n",
    "'미안 하 지만 , 뒷쪽 아이 들 의 떠들 는 소리 가 커 어서 , 광화문 으로 가 아고 싶 은데 표 를 바꾸 어 주 시 겠 어요 ?',\n",
    "'은행 이 너무 멀 어서 안 되 겠 네요 . 현찰 이 필요 하면 돈 을 훔치 시 어요',\n",
    "'아무래도 분실 하 ㄴ 것 같 으니 분실 신고서 를 작성 하 아야 하 겠 습니다 . 사무실 로 같이 가 시 ㄹ 까요 ?',\n",
    "'부산 에서 코로나 확진자 가 급증 하 아서 병상 이 부족하 아 지자  확진자 20명 을 대구 로 이송하 ㄴ다 .',\n",
    "'변기 가 막히 었 습니다 .',\n",
    "'그 바지 좀 보이 어 주 시 ㅂ시오 . 이거 얼마 에 사 ㄹ 수 있 는 것 이 ㅂ니까 ?',\n",
    "'비 가 오 아서 백화점 으로 가지 말 고 두타 로 가 았 으면 좋 겠 습니다 .',\n",
    "'속 이 안 좋 을 때 는 죽 이나 미음 으로 아침 을 대신 하 ㅂ니다',\n",
    "'문 대통령 은 집단 이익 에서 벗어 나 아 라고 말 하 었 다 .',\n",
    "'이것 좀 먹어 보 ㄹ 몇 일 간 의 시간 을 주 시 어요 .',\n",
    "'이날 개미군단 은 외인 의 물량 을 모두 받 아 내 었 다 .',\n",
    "'통합 우승 의 목표 를 달성하 ㄴ NC 다이노스 나성범 이 메이저리그 진출 이라는 또 다른 꿈 을 향하 어 나아가 ㄴ다 .',\n",
    "'이번 구조 조정 이 제품 을 효과 적 으로 개발 하 고 판매 하 기 위하 ㄴ 회사 의 능력 강화 조처 이 ㅁ 을 이해 하 아 주 시 리라 생각 하 ㅂ니다 .',\n",
    "'요즘 이 프로그램 녹화 하 며 많은 걸 느끼 ㄴ다 ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3-sJuDZRZyiD",
    "outputId": "961ccd23-e3a3-4d54-9c99-3ae043176e04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 모든 액체 , 젤 , 에어로졸 등 은 1 커트 짜리 여닫이 투명 봉지 하나 에 넣 어야 하 ㅂ니다 .\n",
      "Translation: all liquids , gels , gels , gels , zip-top , zip-top , zip-top , zip-top , zip-top , one-quart plastic bag .\n",
      "\n",
      "Original: 미안 하 지만 , 뒷쪽 아이 들 의 떠들 는 소리 가 커 어서 , 광화문 으로 가 아고 싶 은데 표 를 바꾸 어 주 시 겠 어요 ?\n",
      "Translation: i 'm sorry , but i 'm to the the <unk> for the <unk> . could you please give me to the <unk> on the\n",
      "\n",
      "Original: 은행 이 너무 멀 어서 안 되 겠 네요 . 현찰 이 필요 하면 돈 을 훔치 시 어요\n",
      "Translation: the 's too much . i you give me a parking lot of the it 's not working .\n",
      "\n",
      "Original: 아무래도 분실 하 ㄴ 것 같 으니 분실 신고서 를 작성 하 아야 하 겠 습니다 . 사무실 로 같이 가 시 ㄹ 까요 ?\n",
      "Translation: i think we have lost the computer , so we can have to have lost our baggage . could you send our name ?\n",
      "\n",
      "Original: 부산 에서 코로나 확진자 가 급증 하 아서 병상 이 부족하 아 지자  확진자 20명 을 대구 로 이송하 ㄴ다 .\n",
      "Translation: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> .\n",
      "\n",
      "Original: 변기 가 막히 었 습니다 .\n",
      "Translation: the toilet does n't flush .\n",
      "\n",
      "Original: 그 바지 좀 보이 어 주 시 ㅂ시오 . 이거 얼마 에 사 ㄹ 수 있 는 것 이 ㅂ니까 ?\n",
      "Translation: can you show me the one ? these are the on display . they 're looking for a .\n",
      "\n",
      "Original: 비 가 오 아서 백화점 으로 가지 말 고 두타 로 가 았 으면 좋 겠 습니다 .\n",
      "Translation: i 'd like to go to the department store and it 's near the shop .\n",
      "\n",
      "Original: 속 이 안 좋 을 때 는 죽 이나 미음 으로 아침 을 대신 하 ㅂ니다\n",
      "Translation: i feel like my feel like to feel in my when i feel in my stomach .\n",
      "\n",
      "Original: 문 대통령 은 집단 이익 에서 벗어 나 아 라고 말 하 었 다 .\n",
      "Translation: the airline granted a a <unk> for the the of the .\n",
      "\n",
      "Original: 이것 좀 먹어 보 ㄹ 몇 일 간 의 시간 을 주 시 어요 .\n",
      "Translation: i hope you could give you a few of these days .\n",
      "\n",
      "Original: 이날 개미군단 은 외인 의 물량 을 모두 받 아 내 었 다 .\n",
      "Translation: the korea has has been to to to abroad by american states .\n",
      "\n",
      "Original: 통합 우승 의 목표 를 달성하 ㄴ NC 다이노스 나성범 이 메이저리그 진출 이라는 또 다른 꿈 을 향하 어 나아가 ㄴ다 .\n",
      "Translation: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> .\n",
      "\n",
      "Original: 이번 구조 조정 이 제품 을 효과 적 으로 개발 하 고 판매 하 기 위하 ㄴ 회사 의 능력 강화 조처 이 ㅁ 을 이해 하 아 주 시 리라 생각 하 ㅂ니다 .\n",
      "Translation: i am sure that will explain the restructuring of restructuring capable of these products , capable of <unk> .\n",
      "\n",
      "Original: 요즘 이 프로그램 녹화 하 며 많은 걸 느끼 ㄴ다 \n",
      "Translation: the new program is a caged curriculum and and i .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "translated_sentences = []\n",
    "for sentence in sen_list:\n",
    "    translation = translate_sentence(\n",
    "        sentence=sentence,\n",
    "        model=model,\n",
    "        en_vocab=en_vocab,\n",
    "        ko_vocab=ko_vocab,\n",
    "        sos_token=\"<sos>\",\n",
    "        eos_token=\"<eos>\",\n",
    "        device=device,\n",
    "        max_output_length=25\n",
    "    )\n",
    "    translated_sentences.append(translation)\n",
    "\n",
    "for original, translation in zip(sen_list, translated_sentences):\n",
    "    print(f\"Original: {original}\")\n",
    "    filtered_translation = [token for token in translation if token not in [\"<sos>\", \"<eos>\"]]\n",
    "    print(f\"Translation: {' '.join(filtered_translation)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQJqSBoS-DV5"
   },
   "source": [
    "## Bleu Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZL4lnCvWfzbb"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def calculate_bleu(reference, prediction, weights=[1, 0, 0, 0]):\n",
    "    score = corpus_bleu(reference, prediction, weights=weights)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J8nbtpJa-DV5",
    "outputId": "8cc4f93f-0f20-4a55-b328-91486b514ded"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33098/33098 [02:52<00:00, 192.25it/s]\n"
     ]
    }
   ],
   "source": [
    "translations = [\n",
    "    translate_sentence(\n",
    "        example[\"ko\"],\n",
    "        model,\n",
    "        en_vocab,\n",
    "        ko_vocab,\n",
    "        sos_token,\n",
    "        eos_token,\n",
    "        device,\n",
    "        max_output_length=25,\n",
    "        lower=True,\n",
    "    )\n",
    "    for example in tqdm.tqdm(test_data)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fVHYJNOkefK-",
    "outputId": "6e65ff53-bf34-4b84-b933-034b5d65256e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I 'm looking for marine products . \", 'Can I get off at the Seouryeoksabangmulgwan ? ', 'I just got here this morning . ', 'Can I help you ? ', \"There 's a police station across the street . I 'm sure they can help you . \"]\n",
      "[\"i 'm looking for a <unk> .\", 'can i get off at the seouryeoksabangmulgwan ?', \"i 'm here here this morning .\", 'may i ask you you ?', \"there 's a police stand across the street . you can see the way .\"]\n"
     ]
    }
   ],
   "source": [
    "reference = [example[\"en\"] for example in test_data]\n",
    "prediction = [\" \".join([token for token in translation if token not in [\"<sos>\", \"<eos>\"]]) for translation in translations]\n",
    "\n",
    "print(reference[:5])\n",
    "print(prediction[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eaYiErUMjErf",
    "outputId": "dee70228-eeb2-4d89-8b77-e8d84c226147"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score = 39.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "bleu_score = calculate_bleu(reference, prediction)\n",
    "print(f'BLEU score = {bleu_score*100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZGUZ7MS-dO4"
   },
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qUkGOJCmVzZj"
   },
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fjyw1qGGVzZk"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_dim, embedding_dim, encoder_hidden_dim, decoder_hidden_dim, dropout\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.GRU(embedding_dim, encoder_hidden_dim, bidirectional=True)\n",
    "        self.fc = nn.Linear(encoder_hidden_dim * 2, decoder_hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src = [src length, batch size]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # embedded = [src length, batch size, embedding dim]\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        # outputs = [src length, batch size, hidden dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
    "        # outputs are always from the last layer\n",
    "        # hidden [-2, :, : ] is the last of the forwards RNN\n",
    "        # hidden [-1, :, : ] is the last of the backwards RNN\n",
    "        # initial decoder hidden is final hidden state of the forwards and backwards\n",
    "        # encoder RNNs fed through a linear layer\n",
    "        hidden = torch.tanh(\n",
    "            self.fc(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1))\n",
    "        )\n",
    "        # outputs = [src length, batch size, encoder hidden dim * 2]\n",
    "        # hidden = [batch size, decoder hidden dim]\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2b4sMZBAk-ud"
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, encoder_hidden_dim, decoder_hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn_fc = nn.Linear(\n",
    "            (encoder_hidden_dim * 2) + decoder_hidden_dim, decoder_hidden_dim\n",
    "        )\n",
    "        self.v_fc = nn.Linear(decoder_hidden_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # hidden = [batch size, decoder hidden dim]\n",
    "        # encoder_outputs = [src length, batch size, encoder hidden dim * 2]\n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_length = encoder_outputs.shape[0]\n",
    "        # repeat decoder hidden state src_length times\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_length, 1)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        # hidden = [batch size, src length, decoder hidden dim]\n",
    "        # encoder_outputs = [batch size, src length, encoder hidden dim * 2]\n",
    "        energy = torch.tanh(self.attn_fc(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        # energy = [batch size, src length, decoder hidden dim]\n",
    "        attention = self.v_fc(energy).squeeze(2)\n",
    "        # attention = [batch size, src length]\n",
    "        return torch.softmax(attention, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5uYaH1oblAd3"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_dim,\n",
    "        embedding_dim,\n",
    "        encoder_hidden_dim,\n",
    "        decoder_hidden_dim,\n",
    "        dropout,\n",
    "        attention,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
    "        self.rnn = nn.GRU((encoder_hidden_dim * 2) + embedding_dim, decoder_hidden_dim)\n",
    "        self.fc_out = nn.Linear(\n",
    "            (encoder_hidden_dim * 2) + decoder_hidden_dim + embedding_dim, output_dim\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        # input = [batch size]\n",
    "        # hidden = [batch size, decoder hidden dim]\n",
    "        # encoder_outputs = [src length, batch size, encoder hidden dim * 2]\n",
    "        input = input.unsqueeze(0)\n",
    "        # input = [1, batch size]\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # embedded = [1, batch size, embedding dim]\n",
    "        a = self.attention(hidden, encoder_outputs)\n",
    "        # a = [batch size, src length]\n",
    "        a = a.unsqueeze(1)\n",
    "        # a = [batch size, 1, src length]\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        # encoder_outputs = [batch size, src length, encoder hidden dim * 2]\n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        # weighted = [batch size, 1, encoder hidden dim * 2]\n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        # weighted = [1, batch size, encoder hidden dim * 2]\n",
    "        rnn_input = torch.cat((embedded, weighted), dim=2)\n",
    "        # rnn_input = [1, batch size, (encoder hidden dim * 2) + embedding dim]\n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        # output = [seq length, batch size, decoder hid dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, decoder hid dim]\n",
    "        # seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
    "        # output = [1, batch size, decoder hidden dim]\n",
    "        # hidden = [1, batch size, decoder hidden dim]\n",
    "        # this also means that output == hidden\n",
    "        assert (output == hidden).all()\n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim=1))\n",
    "        # prediction = [batch size, output dim]\n",
    "        return prediction, hidden.squeeze(0), a.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2vS_bavzlFGa"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio):\n",
    "        # src = [src length, batch size]\n",
    "        # trg = [trg length, batch size]\n",
    "        # teacher_forcing_ratio is probability to use teacher forcing\n",
    "        # e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
    "        batch_size = src.shape[1]\n",
    "        trg_length = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        # tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_length, batch_size, trg_vocab_size).to(self.device)\n",
    "        # encoder_outputs is all hidden states of the input sequence, back and forwards\n",
    "        # hidden is the final forward and backward hidden states, passed through a linear layer\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "        # outputs = [src length, batch size, encoder hidden dim * 2]\n",
    "        # hidden = [batch size, decoder hidden dim]\n",
    "        # first input to the decoder is the <sos> tokens\n",
    "        input = trg[0, :]\n",
    "        for t in range(1, trg_length):\n",
    "            # insert input token embedding, previous hidden state and all encoder hidden states\n",
    "            # receive output tensor (predictions) and new hidden state\n",
    "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs)\n",
    "            # output = [batch size, output dim]\n",
    "            # hidden = [n layers, batch size, decoder hidden dim]\n",
    "            # place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            # decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            # get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1)\n",
    "            # if teacher forcing, use actual next token as next input\n",
    "            # if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "            # input = [batch size]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Swek3LiWVzZk"
   },
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bFhD_irVVzZk"
   },
   "outputs": [],
   "source": [
    "input_dim = len(ko_vocab)\n",
    "output_dim = len(en_vocab)\n",
    "encoder_embedding_dim = 256\n",
    "decoder_embedding_dim = 256\n",
    "encoder_hidden_dim = 512\n",
    "decoder_hidden_dim = 512\n",
    "encoder_dropout = 0.5\n",
    "decoder_dropout = 0.5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "attention = Attention(encoder_hidden_dim, decoder_hidden_dim)\n",
    "\n",
    "encoder = Encoder(\n",
    "    input_dim,\n",
    "    encoder_embedding_dim,\n",
    "    encoder_hidden_dim,\n",
    "    decoder_hidden_dim,\n",
    "    encoder_dropout,\n",
    ")\n",
    "\n",
    "decoder = Decoder(\n",
    "    output_dim,\n",
    "    decoder_embedding_dim,\n",
    "    encoder_hidden_dim,\n",
    "    decoder_hidden_dim,\n",
    "    decoder_dropout,\n",
    "    attention,\n",
    ")\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gbcpi7uBlWYj",
    "outputId": "d0ded2ba-a567-4c78-f4e0-066915a42ec0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(15986, 256)\n",
       "    (rnn): GRU(256, 512, bidirectional=True)\n",
       "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (attn_fc): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (v_fc): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "    (embedding): Embedding(14212, 256)\n",
       "    (rnn): GRU(1280, 512)\n",
       "    (fc_out): Linear(in_features=1792, out_features=14212, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if \"weight\" in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "84dZ0C1MlY2b",
    "outputId": "13aea5c7-2334-482d-e802-83304e365d86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 39,646,084 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ECr_25wWlahN"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j5d5ZSJrlb24"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eC1_tTLkleNq"
   },
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RPVZMY9llfYJ"
   },
   "outputs": [],
   "source": [
    "def train_fn(\n",
    "    model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device\n",
    "):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        src = batch[\"ko_ids\"].to(device)\n",
    "        trg = batch[\"en_ids\"].to(device)\n",
    "        # src = [src length, batch size]\n",
    "        # trg = [trg length, batch size]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg, teacher_forcing_ratio)\n",
    "        # output = [trg length, batch size, trg vocab size]\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        # output = [(trg length - 1) * batch size, trg vocab size]\n",
    "        trg = trg[1:].view(-1)\n",
    "        # trg = [(trg length - 1) * batch size]\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TB4ioK6RlkDh"
   },
   "source": [
    "### Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wuva-9QQljx_"
   },
   "outputs": [],
   "source": [
    "def evaluate_fn(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            src = batch[\"ko_ids\"].to(device)\n",
    "            trg = batch[\"en_ids\"].to(device)\n",
    "            # src = [src length, batch size]\n",
    "            # trg = [trg length, batch size]\n",
    "            output = model(src, trg, 0)  # turn off teacher forcing\n",
    "            # output = [trg length, batch size, trg vocab size]\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            # output = [(trg length - 1) * batch size, trg vocab size]\n",
    "            trg = trg[1:].view(-1)\n",
    "            # trg = [(trg length - 1) * batch size]\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGuRBHLTlpNX"
   },
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g5lPGdlUlrYT",
    "outputId": "2ec388a4-90ca-47aa-b2bd-f4d6742dd6e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [06:08<55:16, 368.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   3.322 | Train PPL:  27.726\n",
      "\tValid Loss:   2.931 | Valid PPL:  18.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 20%|██        | 2/10 [12:18<49:13, 369.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   2.068 | Train PPL:   7.910\n",
      "\tValid Loss:   2.535 | Valid PPL:  12.611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 30%|███       | 3/10 [18:26<43:01, 368.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   1.701 | Train PPL:   5.481\n",
      "\tValid Loss:   2.425 | Valid PPL:  11.299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 40%|████      | 4/10 [24:34<36:51, 368.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   1.509 | Train PPL:   4.520\n",
      "\tValid Loss:   2.382 | Valid PPL:  10.832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 50%|█████     | 5/10 [30:42<30:41, 368.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   1.383 | Train PPL:   3.987\n",
      "\tValid Loss:   2.335 | Valid PPL:  10.325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 60%|██████    | 6/10 [36:50<24:32, 368.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   1.294 | Train PPL:   3.649\n",
      "\tValid Loss:   2.300 | Valid PPL:   9.974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 70%|███████   | 7/10 [42:57<18:23, 367.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   1.227 | Train PPL:   3.410\n",
      "\tValid Loss:   2.247 | Valid PPL:   9.463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 80%|████████  | 8/10 [49:06<12:16, 368.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   1.181 | Train PPL:   3.258\n",
      "\tValid Loss:   2.273 | Valid PPL:   9.707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 90%|█████████ | 9/10 [55:15<06:08, 368.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   1.143 | Train PPL:   3.135\n",
      "\tValid Loss:   2.259 | Valid PPL:   9.574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [1:01:26<00:00, 368.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   1.104 | Train PPL:   3.017\n",
      "\tValid Loss:   2.265 | Valid PPL:   9.632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "clip = 1.0\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "for epoch in tqdm.tqdm(range(n_epochs)):\n",
    "    train_loss = train_fn(\n",
    "        model,\n",
    "        train_data_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        clip,\n",
    "        teacher_forcing_ratio,\n",
    "        device,\n",
    "    )\n",
    "    valid_loss = evaluate_fn(\n",
    "        model,\n",
    "        valid_data_loader,\n",
    "        criterion,\n",
    "        device,\n",
    "    )\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), \"attention-model.pt\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n",
    "    print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMn1asLpVzZk"
   },
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FmcEeCBhVzZk",
    "outputId": "16f6eb88-d093-413b-ba1d-3c1b1b5b7fa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 2.240 | Test PPL:   9.391 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"attention-model.pt\"))\n",
    "\n",
    "test_loss = evaluate_fn(model, test_data_loader, criterion, device)\n",
    "\n",
    "print(f\"| Test Loss: {test_loss:.3f} | Test PPL: {np.exp(test_loss):7.3f} |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgVnXEdJVzZl"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UvaR6JYanQfH"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def translate_sentence(\n",
    "    sentence,\n",
    "    model,\n",
    "    en_vocab,\n",
    "    ko_vocab,\n",
    "    sos_token=\"<sos>\",\n",
    "    eos_token=\"<eos>\",\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    max_output_length=25,\n",
    "    lower=True\n",
    "):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if isinstance(sentence, str):\n",
    "            tokens = sentence.split()\n",
    "        else:\n",
    "            tokens = [token for token in sentence]\n",
    "        if lower:\n",
    "            tokens = [token.lower() for token in tokens]\n",
    "        tokens = [sos_token] + tokens + [eos_token]\n",
    "        ids = ko_vocab.lookup_indices(tokens)\n",
    "        tensor = torch.LongTensor(ids).unsqueeze(-1).to(device)\n",
    "\n",
    "        encoder_outputs, hidden = model.encoder(tensor)\n",
    "        inputs = en_vocab.lookup_indices([sos_token])\n",
    "        attentions = []\n",
    "        for _ in range(max_output_length):\n",
    "            inputs_tensor = torch.LongTensor([inputs[-1]]).to(device)\n",
    "            output, hidden, attention = model.decoder(\n",
    "                inputs_tensor, hidden, encoder_outputs\n",
    "            )\n",
    "            attentions.append(attention.squeeze(0).cpu())\n",
    "            predicted_token = output.argmax(-1).item()\n",
    "            inputs.append(predicted_token)\n",
    "            if predicted_token == en_vocab[eos_token]:\n",
    "                break\n",
    "\n",
    "        tokens = en_vocab.lookup_tokens(inputs)\n",
    "\n",
    "    attentions = torch.stack(attentions)\n",
    "    return tokens, attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oznypfUrVzZl"
   },
   "outputs": [],
   "source": [
    "sen_list = [\n",
    "'모든 액체 , 젤 , 에어로졸 등 은 1 커트 짜리 여닫이 투명 봉지 하나 에 넣 어야 하 ㅂ니다 .',\n",
    "'미안 하 지만 , 뒷쪽 아이 들 의 떠들 는 소리 가 커 어서 , 광화문 으로 가 아고 싶 은데 표 를 바꾸 어 주 시 겠 어요 ?',\n",
    "'은행 이 너무 멀 어서 안 되 겠 네요 . 현찰 이 필요 하면 돈 을 훔치 시 어요',\n",
    "'아무래도 분실 하 ㄴ 것 같 으니 분실 신고서 를 작성 하 아야 하 겠 습니다 . 사무실 로 같이 가 시 ㄹ 까요 ?',\n",
    "'부산 에서 코로나 확진자 가 급증 하 아서 병상 이 부족하 아 지자  확진자 20명 을 대구 로 이송하 ㄴ다 .',\n",
    "'변기 가 막히 었 습니다 .',\n",
    "'그 바지 좀 보이 어 주 시 ㅂ시오 . 이거 얼마 에 사 ㄹ 수 있 는 것 이 ㅂ니까 ?',\n",
    "'비 가 오 아서 백화점 으로 가지 말 고 두타 로 가 았 으면 좋 겠 습니다 .',\n",
    "'속 이 안 좋 을 때 는 죽 이나 미음 으로 아침 을 대신 하 ㅂ니다',\n",
    "'문 대통령 은 집단 이익 에서 벗어 나 아 라고 말 하 었 다 .',\n",
    "'이것 좀 먹어 보 ㄹ 몇 일 간 의 시간 을 주 시 어요 .',\n",
    "'이날 개미군단 은 외인 의 물량 을 모두 받 아 내 었 다 .',\n",
    "'통합 우승 의 목표 를 달성하 ㄴ NC 다이노스 나성범 이 메이저리그 진출 이라는 또 다른 꿈 을 향하 어 나아가 ㄴ다 .',\n",
    "'이번 구조 조정 이 제품 을 효과 적 으로 개발 하 고 판매 하 기 위하 ㄴ 회사 의 능력 강화 조처 이 ㅁ 을 이해 하 아 주 시 리라 생각 하 ㅂ니다 .',\n",
    "'요즘 이 프로그램 녹화 하 며 많은 걸 느끼 ㄴ다 ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wP3fDsn4nWKY",
    "outputId": "7c9bc1e9-dcf5-4020-d8d7-901114db32c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 모든 액체 , 젤 , 에어로졸 등 은 1 커트 짜리 여닫이 투명 봉지 하나 에 넣 어야 하 ㅂ니다 .\n",
      "Translation: all liquids , gels and aerosols must be placed in a single , and aerosols in a single plastic bag , and a plastic bag\n",
      "\n",
      "Original: 미안 하 지만 , 뒷쪽 아이 들 의 떠들 는 소리 가 커 어서 , 광화문 으로 가 아고 싶 은데 표 를 바꾸 어 주 시 겠 어요 ?\n",
      "Translation: i 'm sorry , but i have to move to <unk> <unk> . could i change my ticket to <unk> <unk> .\n",
      "\n",
      "Original: 은행 이 너무 멀 어서 안 되 겠 네요 . 현찰 이 필요 하면 돈 을 훔치 시 어요\n",
      "Translation: that bank is too bad . you you need to buy some money cash or money ?\n",
      "\n",
      "Original: 아무래도 분실 하 ㄴ 것 같 으니 분실 신고서 를 작성 하 아야 하 겠 습니다 . 사무실 로 같이 가 시 ㄹ 까요 ?\n",
      "Translation: i may have lost loss , may i have to ship the baggage report . then . do you you to come to the office\n",
      "\n",
      "Original: 부산 에서 코로나 확진자 가 급증 하 아서 병상 이 부족하 아 지자  확진자 20명 을 대구 로 이송하 ㄴ다 .\n",
      "Translation: the <unk> <unk> the <unk> <unk> <unk> <unk> <unk> and <unk> <unk> <unk> <unk> <unk> <unk> <unk> .\n",
      "\n",
      "Original: 변기 가 막히 었 습니다 .\n",
      "Translation: the toilet is clogged .\n",
      "\n",
      "Original: 그 바지 좀 보이 어 주 시 ㅂ시오 . 이거 얼마 에 사 ㄹ 수 있 는 것 이 ㅂ니까 ?\n",
      "Translation: do you see that pants that i can buy it .\n",
      "\n",
      "Original: 비 가 오 아서 백화점 으로 가지 말 고 두타 로 가 았 으면 좋 겠 습니다 .\n",
      "Translation: i 'd like to go to the store and go to go to go shopping .\n",
      "\n",
      "Original: 속 이 안 좋 을 때 는 죽 이나 미음 으로 아침 을 대신 하 ㅂ니다\n",
      "Translation: i feel porridge in my stomach because it because it is not so good .\n",
      "\n",
      "Original: 문 대통령 은 집단 이익 에서 벗어 나 아 라고 말 하 었 다 .\n",
      "Translation: the president president was <unk> at all in the big agency in the region .\n",
      "\n",
      "Original: 이것 좀 먹어 보 ㄹ 몇 일 간 의 시간 을 주 시 어요 .\n",
      "Translation: please give me a few hours to see this for this eye .\n",
      "\n",
      "Original: 이날 개미군단 은 외인 의 물량 을 모두 받 아 내 었 다 .\n",
      "Translation: this <unk> of the <unk> of the <unk> of the national assembly .\n",
      "\n",
      "Original: 통합 우승 의 목표 를 달성하 ㄴ NC 다이노스 나성범 이 메이저리그 진출 이라는 또 다른 꿈 을 향하 어 나아가 ㄴ다 .\n",
      "Translation: the union suggest suggest the increase of the <unk> <unk> and the <unk> the chance of the chance .\n",
      "\n",
      "Original: 이번 구조 조정 이 제품 을 효과 적 으로 개발 하 고 판매 하 기 위하 ㄴ 회사 의 능력 강화 조처 이 ㅁ 을 이해 하 아 주 시 리라 생각 하 ㅂ니다 .\n",
      "Translation: i 'm sure restructuring this restructuring restructuring restructuring restructuring restructuring restructuring restructuring strengthening restructuring strengthening effectively effectively effectively effectively effectively effectively effectively effectively effectively effectively\n",
      "\n",
      "Original: 요즘 이 프로그램 녹화 하 며 많은 걸 느끼 ㄴ다 \n",
      "Translation: nowadays , these days will always <unk> reading these days .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "translated_sentences = []\n",
    "for sentence in sen_list:\n",
    "    translation, attentions = translate_sentence(\n",
    "        sentence=sentence,\n",
    "        model=model,\n",
    "        en_vocab=en_vocab,\n",
    "        ko_vocab=ko_vocab,\n",
    "        sos_token=\"<sos>\",\n",
    "        eos_token=\"<eos>\",\n",
    "        device=device,\n",
    "        max_output_length=25\n",
    "    )\n",
    "    translated_sentences.append(translation)\n",
    "\n",
    "for original, translation in zip(sen_list, translated_sentences):\n",
    "    print(f\"Original: {original}\")\n",
    "    filtered_translation = [token for token in translation if token not in [\"<sos>\", \"<eos>\"]]\n",
    "    print(f\"Translation: {' '.join(filtered_translation)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRUqZw0dVzZl"
   },
   "source": [
    "## Bleu Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PjMQR1udnjEc"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def calculate_bleu(reference, prediction, weights=[1, 0, 0, 0]):\n",
    "    score = corpus_bleu(reference, prediction, weights=weights)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RDCiU5v2njEc",
    "outputId": "25e7ee58-e24b-4b71-9518-31df23cfe322"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33098/33098 [05:57<00:00, 92.67it/s]\n"
     ]
    }
   ],
   "source": [
    "translations = [\n",
    "    translate_sentence(\n",
    "        example[\"ko\"],\n",
    "        model,\n",
    "        en_vocab,\n",
    "        ko_vocab,\n",
    "        sos_token,\n",
    "        eos_token,\n",
    "        device,\n",
    "        max_output_length=25,\n",
    "        lower=True,\n",
    "    )\n",
    "    for example in tqdm.tqdm(test_data)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bl3FiJuPNUSD",
    "outputId": "d2d4a6b3-1cc3-433f-e2a4-bcb0d5f0eb6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['<sos>', 'i', \"'m\", 'looking', 'for', 'a', '<unk>', 'rice', 'cooker', '.', '<eos>'], tensor([[1.5945e-02, 1.4400e-01, 3.2376e-02, 2.1313e-02, 1.4572e-01, 5.4628e-01,\n",
      "         2.8635e-03, 9.1506e-02],\n",
      "        [1.8612e-02, 1.9571e-01, 1.2708e-01, 1.8384e-02, 4.8681e-02, 5.0221e-01,\n",
      "         1.9165e-03, 8.7399e-02],\n",
      "        [4.9689e-03, 1.2740e-01, 1.0835e-01, 7.3191e-03, 7.7570e-02, 5.3438e-01,\n",
      "         7.1126e-04, 1.3930e-01],\n",
      "        [2.4011e-02, 5.6920e-01, 1.3364e-01, 5.8792e-03, 3.2484e-02, 1.6364e-01,\n",
      "         5.5477e-04, 7.0583e-02],\n",
      "        [1.5532e-02, 7.9818e-01, 7.9315e-02, 3.9566e-03, 1.2931e-02, 3.5891e-02,\n",
      "         2.6419e-04, 5.3931e-02],\n",
      "        [2.0228e-02, 8.0961e-01, 4.9750e-02, 3.0977e-03, 2.1421e-02, 3.6902e-02,\n",
      "         9.4605e-04, 5.8043e-02],\n",
      "        [2.2163e-02, 6.6409e-01, 1.6977e-01, 3.6386e-03, 2.0855e-02, 3.9728e-02,\n",
      "         1.4730e-03, 7.8289e-02],\n",
      "        [1.6622e-02, 7.8706e-01, 6.5737e-02, 2.5083e-03, 1.3994e-02, 4.9837e-02,\n",
      "         1.9007e-03, 6.2343e-02],\n",
      "        [5.3036e-02, 6.5363e-01, 7.3412e-02, 2.6566e-03, 1.4493e-02, 5.8294e-02,\n",
      "         2.4312e-03, 1.4204e-01],\n",
      "        [1.7041e-01, 4.6862e-01, 8.0825e-02, 4.9544e-03, 1.9895e-02, 4.8141e-02,\n",
      "         5.6721e-03, 2.0148e-01]])), (['<sos>', 'can', 'i', 'get', 'off', 'at', 'the', 'seouryeoksabangmulgwan', '?', '<eos>'], tensor([[6.5877e-03, 6.4218e-02, 2.6257e-02, 2.2952e-03, 2.6766e-03, 2.4619e-01,\n",
      "         1.6337e-01, 1.6918e-02, 1.7050e-01, 2.9247e-01, 8.5073e-03],\n",
      "        [6.9447e-03, 1.8442e-02, 1.8815e-02, 9.9474e-03, 2.5916e-02, 6.9049e-01,\n",
      "         1.5672e-01, 5.5673e-03, 4.2421e-02, 1.2196e-02, 1.2534e-02],\n",
      "        [3.2976e-03, 9.8438e-03, 1.4743e-02, 9.0730e-03, 1.0757e-02, 8.0253e-01,\n",
      "         1.1175e-01, 4.7896e-03, 2.0787e-02, 8.7054e-03, 3.7199e-03],\n",
      "        [3.3686e-03, 2.8877e-02, 6.5837e-02, 2.2599e-02, 4.4448e-02, 7.4121e-01,\n",
      "         6.3128e-02, 4.4047e-03, 1.2499e-02, 1.0167e-02, 3.4574e-03],\n",
      "        [1.6802e-02, 6.6684e-02, 1.3743e-01, 4.3121e-02, 6.5259e-02, 5.9040e-01,\n",
      "         4.4290e-02, 4.1037e-03, 1.0798e-02, 1.0948e-02, 1.0171e-02],\n",
      "        [4.2042e-02, 1.4182e-01, 5.3186e-01, 1.0600e-01, 6.3489e-02, 7.6698e-02,\n",
      "         9.8019e-03, 1.2448e-03, 2.1694e-03, 1.2745e-02, 1.2126e-02],\n",
      "        [5.9799e-03, 2.5228e-01, 6.6541e-01, 5.5269e-02, 6.8020e-03, 7.6211e-03,\n",
      "         4.9964e-04, 4.2811e-04, 4.3100e-04, 3.9598e-03, 1.3132e-03],\n",
      "        [1.4074e-01, 4.6476e-02, 4.7695e-01, 6.8869e-02, 9.7476e-03, 3.4403e-02,\n",
      "         5.4571e-02, 2.3203e-02, 3.2957e-02, 7.8742e-02, 3.3339e-02],\n",
      "        [1.9454e-01, 1.5441e-01, 1.6491e-01, 5.9233e-02, 5.8544e-02, 9.2177e-02,\n",
      "         1.0150e-01, 1.8868e-02, 2.0455e-02, 4.5325e-02, 9.0040e-02]])), (['<sos>', 'i', 'arrived', 'here', 'this', 'morning', '.', '<eos>'], tensor([[0.0823, 0.0135, 0.2235, 0.0163, 0.0497, 0.1815, 0.0868, 0.2886, 0.0095,\n",
      "         0.0231, 0.0252],\n",
      "        [0.0827, 0.0083, 0.0240, 0.0053, 0.0256, 0.3087, 0.1767, 0.3484, 0.0057,\n",
      "         0.0050, 0.0097],\n",
      "        [0.0138, 0.0019, 0.0138, 0.0036, 0.0257, 0.3806, 0.1471, 0.3576, 0.0085,\n",
      "         0.0155, 0.0321],\n",
      "        [0.0232, 0.0059, 0.0375, 0.0064, 0.2209, 0.3822, 0.0812, 0.1296, 0.0052,\n",
      "         0.0157, 0.0922],\n",
      "        [0.0246, 0.0051, 0.0247, 0.0114, 0.2278, 0.3811, 0.0482, 0.1340, 0.0109,\n",
      "         0.0352, 0.0970],\n",
      "        [0.0467, 0.0116, 0.0558, 0.0249, 0.3063, 0.2294, 0.0395, 0.1253, 0.0115,\n",
      "         0.0543, 0.0947],\n",
      "        [0.0600, 0.0133, 0.0427, 0.0284, 0.1675, 0.2323, 0.0669, 0.1083, 0.0219,\n",
      "         0.0757, 0.1831]])), (['<sos>', 'would', 'you', 'tell', 'me', 'to', 'call', '?', '<eos>'], tensor([[0.1353, 0.2070, 0.2376, 0.2071, 0.0779, 0.0407, 0.0209, 0.0275, 0.0461],\n",
      "        [0.1731, 0.3352, 0.2448, 0.1374, 0.0412, 0.0123, 0.0089, 0.0109, 0.0363],\n",
      "        [0.1704, 0.2498, 0.3022, 0.1560, 0.0431, 0.0137, 0.0084, 0.0104, 0.0459],\n",
      "        [0.1629, 0.3055, 0.2634, 0.1491, 0.0411, 0.0053, 0.0054, 0.0084, 0.0589],\n",
      "        [0.1579, 0.5306, 0.1888, 0.0649, 0.0136, 0.0044, 0.0030, 0.0033, 0.0336],\n",
      "        [0.1604, 0.5313, 0.1995, 0.0490, 0.0139, 0.0035, 0.0034, 0.0043, 0.0347],\n",
      "        [0.1464, 0.5464, 0.2169, 0.0324, 0.0079, 0.0065, 0.0031, 0.0043, 0.0360],\n",
      "        [0.1376, 0.5270, 0.1730, 0.0454, 0.0132, 0.0060, 0.0070, 0.0104, 0.0804]])), (['<sos>', 'there', \"'s\", 'a', 'police', 'station', 'across', 'the', 'street', '.', 'i', 'can', 'sure', 'they', 'can', 'help', 'you', '.', '<eos>'], tensor([[2.4677e-02, 3.4765e-02, 2.3361e-02, 6.2657e-01, 1.6663e-01, 7.0028e-02,\n",
      "         1.0308e-03, 1.2078e-02, 2.3783e-03, 9.0221e-03, 2.7830e-03, 6.3488e-03,\n",
      "         4.0967e-03, 2.8076e-03, 5.6205e-03, 2.9492e-04, 7.5016e-03],\n",
      "        [4.0834e-02, 1.1961e-01, 4.5315e-02, 6.1203e-01, 1.0734e-01, 1.3252e-02,\n",
      "         3.0811e-04, 4.9316e-03, 6.3778e-03, 9.4501e-03, 7.3566e-03, 1.9939e-02,\n",
      "         6.6015e-03, 1.6802e-03, 1.1443e-03, 8.7124e-05, 3.7508e-03],\n",
      "        [2.4097e-02, 4.3972e-02, 4.6563e-02, 6.6485e-01, 1.1419e-01, 1.3313e-02,\n",
      "         6.7665e-04, 6.8492e-03, 5.1829e-03, 9.1206e-03, 7.2851e-03, 4.9450e-02,\n",
      "         6.6706e-03, 8.0610e-04, 1.8928e-03, 1.3758e-04, 4.9453e-03],\n",
      "        [1.9047e-02, 9.8620e-02, 8.0722e-02, 6.8116e-01, 5.5931e-02, 5.3014e-03,\n",
      "         4.7221e-04, 4.9583e-03, 3.6730e-03, 1.3019e-02, 4.8897e-03, 2.5591e-02,\n",
      "         1.7139e-03, 2.8691e-04, 4.8133e-04, 6.7112e-05, 4.0618e-03],\n",
      "        [4.2515e-02, 1.6966e-01, 1.0330e-01, 5.0664e-01, 9.2741e-02, 1.3757e-02,\n",
      "         7.1419e-04, 1.3797e-02, 7.2407e-03, 2.0373e-02, 4.7965e-03, 1.4712e-02,\n",
      "         3.2514e-03, 1.1040e-03, 7.8308e-04, 1.5125e-04, 4.4689e-03],\n",
      "        [1.4606e-01, 4.0045e-01, 9.5775e-02, 1.9987e-01, 6.4669e-02, 1.2476e-02,\n",
      "         1.6007e-03, 1.3541e-02, 6.8345e-03, 1.3936e-02, 9.4012e-03, 1.8896e-02,\n",
      "         2.7886e-03, 2.1526e-03, 7.0314e-04, 1.9690e-04, 1.0651e-02],\n",
      "        [2.1820e-01, 4.7034e-01, 2.9335e-02, 4.5124e-02, 1.7395e-02, 9.5962e-03,\n",
      "         3.1746e-03, 2.0714e-02, 4.6579e-02, 3.3022e-02, 1.9153e-02, 4.2943e-02,\n",
      "         7.8826e-03, 4.3976e-03, 1.4804e-03, 5.2535e-04, 3.0147e-02],\n",
      "        [1.3166e-01, 5.9227e-01, 1.3329e-02, 2.4386e-02, 5.8340e-03, 3.8857e-03,\n",
      "         1.9664e-03, 4.9611e-02, 3.4354e-02, 5.2071e-02, 1.7824e-02, 2.8477e-02,\n",
      "         1.0392e-02, 3.1940e-03, 2.5599e-03, 2.9712e-04, 2.7890e-02],\n",
      "        [9.5911e-02, 3.6153e-01, 1.2727e-02, 3.4969e-02, 2.2168e-02, 1.9301e-02,\n",
      "         5.9915e-03, 6.3203e-02, 6.4183e-02, 9.0328e-02, 4.3754e-02, 7.4652e-02,\n",
      "         2.5237e-02, 1.0787e-02, 9.8458e-03, 1.8740e-03, 6.3541e-02],\n",
      "        [3.4140e-02, 1.0042e-01, 8.2163e-03, 7.5058e-03, 8.0924e-03, 8.7195e-03,\n",
      "         5.8899e-03, 9.7301e-02, 1.7295e-01, 1.3972e-01, 6.8201e-02, 1.6340e-01,\n",
      "         6.8295e-02, 1.3149e-02, 8.6099e-03, 3.5067e-03, 9.1886e-02],\n",
      "        [1.1316e-02, 4.3096e-02, 2.8451e-03, 8.0774e-03, 5.0261e-03, 3.4200e-03,\n",
      "         3.2218e-03, 1.0661e-01, 1.0293e-01, 1.7370e-01, 1.0884e-01, 2.8279e-01,\n",
      "         5.8102e-02, 8.1794e-03, 8.9385e-03, 1.0414e-03, 7.1870e-02],\n",
      "        [4.7061e-03, 1.9312e-02, 1.9716e-03, 7.7736e-03, 4.3416e-03, 1.1315e-03,\n",
      "         1.5576e-03, 7.1451e-02, 7.7646e-02, 3.0461e-01, 1.0171e-01, 3.1188e-01,\n",
      "         4.3783e-02, 3.3710e-03, 5.9100e-03, 7.4832e-04, 3.8094e-02],\n",
      "        [5.8802e-03, 2.1844e-02, 1.8741e-03, 1.9802e-02, 4.6008e-03, 1.8322e-03,\n",
      "         1.2687e-03, 7.7082e-02, 6.8064e-02, 4.4723e-01, 5.3700e-02, 2.0089e-01,\n",
      "         2.4693e-02, 2.8985e-03, 7.2670e-03, 6.8714e-04, 6.0385e-02],\n",
      "        [8.5198e-03, 3.6756e-02, 2.7099e-03, 1.2670e-02, 3.0271e-03, 7.0660e-04,\n",
      "         1.7632e-03, 1.0822e-01, 1.0284e-01, 3.5561e-01, 8.3738e-02, 1.7947e-01,\n",
      "         3.4164e-02, 1.7798e-03, 2.1213e-03, 8.8253e-04, 6.5026e-02],\n",
      "        [9.1010e-03, 4.4272e-02, 3.0187e-03, 1.1120e-02, 2.7342e-03, 5.1355e-04,\n",
      "         1.6351e-03, 1.3314e-01, 1.1832e-01, 4.1531e-01, 5.2306e-02, 1.3104e-01,\n",
      "         1.0333e-02, 1.9023e-03, 1.2337e-03, 3.0352e-04, 6.3708e-02],\n",
      "        [1.1775e-02, 4.4377e-02, 2.9444e-03, 1.5135e-02, 2.7905e-03, 1.0304e-03,\n",
      "         1.5115e-03, 1.0926e-01, 1.1083e-01, 4.6011e-01, 5.3677e-02, 9.4384e-02,\n",
      "         1.8149e-02, 3.1736e-03, 3.1499e-03, 8.1228e-04, 6.6892e-02],\n",
      "        [1.3194e-02, 7.1431e-02, 3.6588e-03, 1.0309e-02, 1.6287e-03, 8.4663e-04,\n",
      "         2.0780e-03, 1.4176e-01, 1.7572e-01, 3.7554e-01, 4.7508e-02, 8.2196e-02,\n",
      "         1.1216e-02, 2.8397e-03, 1.5257e-03, 1.0935e-03, 5.7460e-02],\n",
      "        [1.4640e-02, 8.6671e-02, 5.5401e-03, 7.6691e-03, 1.6384e-03, 1.0362e-03,\n",
      "         2.8893e-03, 1.9190e-01, 1.9277e-01, 2.7097e-01, 5.2835e-02, 7.2298e-02,\n",
      "         1.2761e-02, 3.2383e-03, 1.3755e-03, 5.6807e-04, 8.1205e-02]]))]\n"
     ]
    }
   ],
   "source": [
    "print(translations[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w-g9O1JFnjEc",
    "outputId": "9034bc7a-d60a-458f-cdac-a13b94fd22cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I 'm looking for marine products . \", 'Can I get off at the Seouryeoksabangmulgwan ? ', 'I just got here this morning . ', 'Can I help you ? ', \"There 's a police station across the street . I 'm sure they can help you . \"]\n",
      "[\"i 'm looking for a <unk> rice cooker .\", 'can i get off at the seouryeoksabangmulgwan ?', 'i arrived here this morning .', 'would you tell me to call ?', \"there 's a police station across the street . i can sure they can help you .\"]\n"
     ]
    }
   ],
   "source": [
    "reference = [example[\"en\"] for example in test_data]\n",
    "prediction = [\n",
    "    \" \".join([token for token in translation[0] if token not in [\"<sos>\", \"<eos>\"]])\n",
    "    for translation in translations\n",
    "]\n",
    "\n",
    "print(reference[:5])\n",
    "print(prediction[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S01EPQadnjEc",
    "outputId": "7ee2f67f-8d6c-4e6f-f210-856a4e2ec131"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score = 37.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "bleu_score = calculate_bleu(reference, prediction)\n",
    "print(f'BLEU score = {bleu_score*100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_i9R2j_w_TTS"
   },
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpf9zFY4V2a-"
   },
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LIpjN75tV2a-"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 hid_dim,\n",
    "                 n_layers,\n",
    "                 n_heads,\n",
    "                 pf_dim,\n",
    "                 dropout,\n",
    "                 device,\n",
    "                 max_length=100):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
    "        self.layers = nn.ModuleList([\n",
    "            EncoderLayer(hid_dim, n_heads, pf_dim, dropout, device)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        # src = [src len, batch size]\n",
    "        # src_mask = [batch size, 1, 1, src len]\n",
    "\n",
    "        batch_size = src.shape[1]\n",
    "        src_len = src.shape[0]\n",
    "\n",
    "        pos = torch.arange(0, src_len).unsqueeze(1).repeat(1, batch_size).to(self.device)\n",
    "        # pos = [src len, batch size]\n",
    "\n",
    "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
    "        # src = [src len, batch size, hid dim]\n",
    "\n",
    "        for layer in self.layers:\n",
    "            src = layer(src, src_mask)\n",
    "        # src = [src len, batch size, hid dim]\n",
    "\n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YBcM0oj5nRJ_"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 hid_dim,\n",
    "                 n_heads,\n",
    "                 pf_dim,\n",
    "                 dropout,\n",
    "                 device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim,\n",
    "                                                                     pf_dim,\n",
    "                                                                     dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        #src = [batch size, src len, hid dim]\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "\n",
    "        #self attention\n",
    "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
    "\n",
    "        #dropout, residual connection and layer norm\n",
    "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
    "        #src = [batch size, src len, hid dim]\n",
    "\n",
    "        #positionwise feedforward\n",
    "        _src = self.positionwise_feedforward(src)\n",
    "\n",
    "        #dropout, residual and layer norm\n",
    "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
    "        #src = [batch size, src len, hid dim]\n",
    "\n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GN4M_feYnSsi"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
    "        super().__init__()\n",
    "\n",
    "        assert hid_dim % n_heads == 0\n",
    "\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = hid_dim // n_heads\n",
    "\n",
    "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
    "\n",
    "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        # query, key, value = [seq len, batch size, hid dim]\n",
    "\n",
    "        batch_size = query.shape[1]\n",
    "\n",
    "        # Fully connected layers\n",
    "        Q = self.fc_q(query)\n",
    "        K = self.fc_k(key)\n",
    "        V = self.fc_v(value)\n",
    "        # Q, K, V = [seq len, batch size, hid dim]\n",
    "\n",
    "        # Reshape to [seq len, batch size, n heads, head dim] and permute\n",
    "        Q = Q.view(-1, batch_size, self.n_heads, self.head_dim).permute(1, 2, 0, 3)\n",
    "        K = K.view(-1, batch_size, self.n_heads, self.head_dim).permute(1, 2, 0, 3)\n",
    "        V = V.view(-1, batch_size, self.n_heads, self.head_dim).permute(1, 2, 0, 3)\n",
    "        # Q, K, V = [batch size, n heads, seq len, head dim]\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
    "        # energy = [batch size, n heads, seq len, seq len]\n",
    "\n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, -1e10)\n",
    "\n",
    "        attention = torch.softmax(energy, dim=-1)\n",
    "        # attention = [batch size, n heads, seq len, seq len]\n",
    "\n",
    "        x = torch.matmul(self.dropout(attention), V)\n",
    "        # x = [batch size, n heads, seq len, head dim]\n",
    "\n",
    "        x = x.permute(2, 0, 1, 3).contiguous()\n",
    "        # x = [seq len, batch size, n heads, head dim]\n",
    "\n",
    "        x = x.view(-1, batch_size, self.hid_dim)\n",
    "        # x = [seq len, batch size, hid dim]\n",
    "\n",
    "        x = self.fc_o(x)\n",
    "        # x = [seq len, batch size, hid dim]\n",
    "\n",
    "        return x, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wbTMO8pUnUlw"
   },
   "outputs": [],
   "source": [
    "class PositionwiseFeedforwardLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, pf_dim, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
    "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = [batch size, seq len, hid dim]\n",
    "\n",
    "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
    "        #x = [batch size, seq len, pf dim]\n",
    "\n",
    "        x = self.fc_2(x)\n",
    "        #x = [batch size, seq len, hid dim]\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T6fHQd3HnWEk"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 output_dim,\n",
    "                 hid_dim,\n",
    "                 n_layers,\n",
    "                 n_heads,\n",
    "                 pf_dim,\n",
    "                 dropout,\n",
    "                 device,\n",
    "                 max_length=100):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
    "        self.layers = nn.ModuleList([\n",
    "            DecoderLayer(hid_dim, n_heads, pf_dim, dropout, device)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
    "\n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "        # trg = [trg len, batch size]\n",
    "        # enc_src = [src len, batch size, hid dim]\n",
    "        # trg_mask = [batch size, 1, trg len, trg len]\n",
    "        # src_mask = [batch size, 1, 1, src len]\n",
    "\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "\n",
    "        pos = torch.arange(0, trg_len).unsqueeze(1).repeat(1, batch_size).to(self.device)\n",
    "        # pos = [trg len, batch size]\n",
    "\n",
    "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
    "        # trg = [trg len, batch size, hid dim]\n",
    "\n",
    "        for layer in self.layers:\n",
    "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
    "        # trg = [trg len, batch size, hid dim]\n",
    "        # attention = [batch size, n heads, trg len, src len]\n",
    "\n",
    "        output = self.fc_out(trg)\n",
    "        # output = [trg len, batch size, output dim]\n",
    "\n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyzImtUDnXXc"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 hid_dim,\n",
    "                 n_heads,\n",
    "                 pf_dim,\n",
    "                 dropout,\n",
    "                 device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim,\n",
    "                                                                     pf_dim,\n",
    "                                                                     dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "\n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        #enc_src = [batch size, src len, hid dim]\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "\n",
    "        #self attention\n",
    "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
    "\n",
    "        #dropout, residual connection and layer norm\n",
    "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "\n",
    "        #encoder attention\n",
    "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
    "\n",
    "        #dropout, residual connection and layer norm\n",
    "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "\n",
    "        #positionwise feedforward\n",
    "        _trg = self.positionwise_feedforward(trg)\n",
    "\n",
    "        #dropout, residual and layer norm\n",
    "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        #attention = [batch size, n heads, trg len, src len]\n",
    "\n",
    "        return trg, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GbDnhC9xnaKF"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.device = device\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        # src = [src len, batch size]\n",
    "        src_mask = (src != self.src_pad_idx).permute(1, 0).unsqueeze(1).unsqueeze(2)\n",
    "        # src_mask = [batch size, 1, 1, src len]\n",
    "        return src_mask\n",
    "\n",
    "    def make_trg_mask(self, trg):\n",
    "        # trg = [trg len, batch size]\n",
    "        trg_pad_mask = (trg != self.trg_pad_idx).permute(1, 0).unsqueeze(1).unsqueeze(2)\n",
    "        # trg_pad_mask = [batch size, 1, 1, trg len]\n",
    "\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device=self.device)).bool()\n",
    "        # trg_sub_mask = [trg len, trg len]\n",
    "\n",
    "        trg_sub_mask = trg_sub_mask.unsqueeze(0).unsqueeze(0)\n",
    "        # trg_sub_mask = [1, 1, trg len, trg len]\n",
    "\n",
    "        trg_mask = trg_pad_mask & trg_sub_mask\n",
    "        # trg_mask = [batch size, 1, trg len, trg len]\n",
    "\n",
    "        return trg_mask\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        # src = [src len, batch size]\n",
    "        # trg = [trg len, batch size]\n",
    "\n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "        # src_mask = [batch size, 1, 1, src len]\n",
    "        # trg_mask = [batch size, 1, trg len, trg len]\n",
    "\n",
    "        enc_src = self.encoder(src, src_mask)\n",
    "        # enc_src = [src len, batch size, hid dim]\n",
    "\n",
    "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
    "        # output = [trg len, batch size, output dim]\n",
    "        # attention = [batch size, n heads, trg len, src len]\n",
    "\n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMwL6jgHV2a_"
   },
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4tH-cuw3V2a_"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(ko_vocab)\n",
    "OUTPUT_DIM = len(en_vocab)\n",
    "HID_DIM = 256\n",
    "ENC_LAYERS = 3\n",
    "DEC_LAYERS = 3\n",
    "ENC_HEADS = 8\n",
    "DEC_HEADS = 8\n",
    "ENC_PF_DIM = 512\n",
    "DEC_PF_DIM = 512\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1\n",
    "\n",
    "enc = Encoder(INPUT_DIM,\n",
    "              HID_DIM,\n",
    "              ENC_LAYERS,\n",
    "              ENC_HEADS,\n",
    "              ENC_PF_DIM,\n",
    "              ENC_DROPOUT,\n",
    "              device)\n",
    "\n",
    "dec = Decoder(OUTPUT_DIM,\n",
    "              HID_DIM,\n",
    "              DEC_LAYERS,\n",
    "              DEC_HEADS,\n",
    "              DEC_PF_DIM,\n",
    "              DEC_DROPOUT,\n",
    "              device)\n",
    "\n",
    "model = Seq2Seq(enc, dec, pad_index, pad_index, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8hjt9xfnnhTr",
    "outputId": "3b55632a-0acb-477a-b149-458ad741492c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (tok_embedding): Embedding(15986, 256)\n",
       "    (pos_embedding): Embedding(100, 256)\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x EncoderLayer(\n",
       "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
       "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (tok_embedding): Embedding(14212, 256)\n",
       "    (pos_embedding): Embedding(100, 256)\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x DecoderLayer(\n",
       "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
       "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (fc_out): Linear(in_features=256, out_features=14212, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "\n",
    "model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Cp2G7a7njjJ",
    "outputId": "222c807b-d499-4a67-f9ee-da989fc10f4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 15,388,036 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p5N5K6AcnlCi"
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V8ieh4wtnlZx"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index = pad_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lyt8C6IynnSi"
   },
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ebTB3PqbnoQI"
   },
   "outputs": [],
   "source": [
    "def train_fn(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        src = batch[\"ko_ids\"].to(device)  # [src len, batch size]\n",
    "        trg = batch[\"en_ids\"].to(device)  # [trg len, batch size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output, _ = model(src, trg[:-1, :])  # trg의 마지막 단어 제외\n",
    "        # output = [trg len - 1, batch size, output dim]\n",
    "        # trg = [trg len, batch size]\n",
    "\n",
    "        output_dim = output.shape[-1]\n",
    "\n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        trg = trg[1:].contiguous().view(-1)  # trg의 첫 단어 제외\n",
    "        # output = [(trg len - 1) * batch size, output dim]\n",
    "        # trg = [(trg len - 1) * batch size]\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9w7cEal7ntsp"
   },
   "source": [
    "### Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JruoZR6Fnrv9"
   },
   "outputs": [],
   "source": [
    "def evaluate_fn(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            src = batch[\"ko_ids\"].to(device)  # [src len, batch size]\n",
    "            trg = batch[\"en_ids\"].to(device)  # [trg len, batch size]\n",
    "\n",
    "            output, _ = model(src, trg[:-1, :])  # trg의 마지막 단어 제외\n",
    "            # output = [trg len - 1, batch size, output dim]\n",
    "            # trg = [trg len, batch size]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[1:].contiguous().view(-1)  # trg의 첫 단어 제외\n",
    "            # output = [(trg len - 1) * batch size, output dim]\n",
    "            # trg = [(trg len - 1) * batch size]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYmt9QHkny3A"
   },
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wgGkDE4nn0Tt",
    "outputId": "94e23a6b-e1f0-4420-a6e1-644e418e0e10"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [02:47<25:03, 167.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   1.440 | Train PPL:   4.223\n",
      "\tValid Loss:   1.315 | Valid PPL:   3.724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 20%|██        | 2/10 [05:30<21:59, 164.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   1.189 | Train PPL:   3.284\n",
      "\tValid Loss:   1.185 | Valid PPL:   3.270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 30%|███       | 3/10 [08:09<18:55, 162.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   1.042 | Train PPL:   2.834\n",
      "\tValid Loss:   1.120 | Valid PPL:   3.065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 40%|████      | 4/10 [10:47<16:04, 160.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   0.941 | Train PPL:   2.562\n",
      "\tValid Loss:   1.074 | Valid PPL:   2.927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 50%|█████     | 5/10 [13:27<13:21, 160.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   0.868 | Train PPL:   2.382\n",
      "\tValid Loss:   1.037 | Valid PPL:   2.820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 60%|██████    | 6/10 [16:05<10:38, 159.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   0.809 | Train PPL:   2.246\n",
      "\tValid Loss:   1.012 | Valid PPL:   2.751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 70%|███████   | 7/10 [18:44<07:57, 159.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   0.762 | Train PPL:   2.143\n",
      "\tValid Loss:   0.989 | Valid PPL:   2.688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 80%|████████  | 8/10 [21:22<05:17, 158.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   0.724 | Train PPL:   2.063\n",
      "\tValid Loss:   0.975 | Valid PPL:   2.651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 90%|█████████ | 9/10 [24:00<02:38, 158.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   0.691 | Train PPL:   1.996\n",
      "\tValid Loss:   0.964 | Valid PPL:   2.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [26:39<00:00, 159.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   0.663 | Train PPL:   1.941\n",
      "\tValid Loss:   0.950 | Valid PPL:   2.587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "clip = 1.0\n",
    "\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "for epoch in tqdm.tqdm(range(n_epochs)):\n",
    "    train_loss = train_fn(\n",
    "        model,\n",
    "        train_data_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        clip,\n",
    "    )\n",
    "    valid_loss = evaluate_fn(\n",
    "        model,\n",
    "        valid_data_loader,\n",
    "        criterion,\n",
    "    )\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), \"transformers-model.pt\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n",
    "    print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MImHFWJV2a_"
   },
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PPBA8dz5V2a_",
    "outputId": "adca1e28-bf34-4a73-8c8b-a43ba5ea5f79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.951 | Test PPL:   2.589 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"transformers-model.pt\"))\n",
    "\n",
    "test_loss = evaluate_fn(model, test_data_loader, criterion)\n",
    "\n",
    "print(f\"| Test Loss: {test_loss:.3f} | Test PPL: {np.exp(test_loss):7.3f} |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySqP9zU9V2a_"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dEkKPXaSonrt"
   },
   "outputs": [],
   "source": [
    "def translate_sentence(\n",
    "    sentence,\n",
    "    model,\n",
    "    en_vocab,\n",
    "    ko_vocab,\n",
    "    sos_token=\"<sos>\",\n",
    "    eos_token=\"<eos>\",\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    max_output_length=25,\n",
    "    lower=True\n",
    "):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if isinstance(sentence, str):\n",
    "            tokens = sentence.split()\n",
    "        else:\n",
    "            tokens = [token for token in sentence]\n",
    "        if lower:\n",
    "            tokens = [token.lower() for token in tokens]\n",
    "        tokens = [sos_token] + tokens + [eos_token]\n",
    "        src_indices = ko_vocab.lookup_indices(tokens)\n",
    "        src_tensor = torch.LongTensor(src_indices).unsqueeze(1).to(device)\n",
    "\n",
    "        src_mask = model.make_src_mask(src_tensor)\n",
    "        enc_src = model.encoder(src_tensor, src_mask)\n",
    "\n",
    "        trg_indices = [en_vocab[sos_token]]\n",
    "        attentions = []\n",
    "\n",
    "        for _ in range(max_output_length):\n",
    "            trg_tensor = torch.LongTensor(trg_indices).unsqueeze(1).to(device)\n",
    "            trg_mask = model.make_trg_mask(trg_tensor)\n",
    "\n",
    "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
    "            attentions.append(attention.cpu())\n",
    "\n",
    "            predicted_token = output.argmax(-1)[-1].item()\n",
    "            trg_indices.append(predicted_token)\n",
    "\n",
    "            if predicted_token == en_vocab[eos_token]:\n",
    "                break\n",
    "\n",
    "        translated_tokens = en_vocab.lookup_tokens(trg_indices)\n",
    "\n",
    "    return translated_tokens, attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3oj63XRV2a_"
   },
   "outputs": [],
   "source": [
    "sen_list = [\n",
    "'모든 액체 , 젤 , 에어로졸 등 은 1 커트 짜리 여닫이 투명 봉지 하나 에 넣 어야 하 ㅂ니다 .',\n",
    "'미안 하 지만 , 뒷쪽 아이 들 의 떠들 는 소리 가 커 어서 , 광화문 으로 가 아고 싶 은데 표 를 바꾸 어 주 시 겠 어요 ?',\n",
    "'은행 이 너무 멀 어서 안 되 겠 네요 . 현찰 이 필요 하면 돈 을 훔치 시 어요',\n",
    "'아무래도 분실 하 ㄴ 것 같 으니 분실 신고서 를 작성 하 아야 하 겠 습니다 . 사무실 로 같이 가 시 ㄹ 까요 ?',\n",
    "'부산 에서 코로나 확진자 가 급증 하 아서 병상 이 부족하 아 지자  확진자 20명 을 대구 로 이송하 ㄴ다 .',\n",
    "'변기 가 막히 었 습니다 .',\n",
    "'그 바지 좀 보이 어 주 시 ㅂ시오 . 이거 얼마 에 사 ㄹ 수 있 는 것 이 ㅂ니까 ?',\n",
    "'비 가 오 아서 백화점 으로 가지 말 고 두타 로 가 았 으면 좋 겠 습니다 .',\n",
    "'속 이 안 좋 을 때 는 죽 이나 미음 으로 아침 을 대신 하 ㅂ니다',\n",
    "'문 대통령 은 집단 이익 에서 벗어 나 아 라고 말 하 었 다 .',\n",
    "'이것 좀 먹어 보 ㄹ 몇 일 간 의 시간 을 주 시 어요 .',\n",
    "'이날 개미군단 은 외인 의 물량 을 모두 받 아 내 었 다 .',\n",
    "'통합 우승 의 목표 를 달성하 ㄴ NC 다이노스 나성범 이 메이저리그 진출 이라는 또 다른 꿈 을 향하 어 나아가 ㄴ다 .',\n",
    "'이번 구조 조정 이 제품 을 효과 적 으로 개발 하 고 판매 하 기 위하 ㄴ 회사 의 능력 강화 조처 이 ㅁ 을 이해 하 아 주 시 리라 생각 하 ㅂ니다 .',\n",
    "'요즘 이 프로그램 녹화 하 며 많은 걸 느끼 ㄴ다 ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b-cvW_ugoqmv",
    "outputId": "ddfec08b-e45f-46bb-9af3-48c986345309"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 모든 액체 , 젤 , 에어로졸 등 은 1 커트 짜리 여닫이 투명 봉지 하나 에 넣 어야 하 ㅂ니다 .\n",
      "Translation: all liquids , gels and aerosols , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , and may\n",
      "\n",
      "Original: 미안 하 지만 , 뒷쪽 아이 들 의 떠들 는 소리 가 커 어서 , 광화문 으로 가 아고 싶 은데 표 를 바꾸 어 주 시 겠 어요 ?\n",
      "Translation: i 'm sorry , miss. . <unk> <unk> the <unk> of communication companies in gwanghwamun . could you change the <unk> ?\n",
      "\n",
      "Original: 은행 이 너무 멀 어서 안 되 겠 네요 . 현찰 이 필요 하면 돈 을 훔치 시 어요\n",
      "Translation: the bank is too far . i need to steal someone else <unk> .\n",
      "\n",
      "Original: 아무래도 분실 하 ㄴ 것 같 으니 분실 신고서 를 작성 하 아야 하 겠 습니다 . 사무실 로 같이 가 시 ㄹ 까요 ?\n",
      "Translation: we 've lost the error of our loss , we have to fill out the office <unk> . would you like to join us ?\n",
      "\n",
      "Original: 부산 에서 코로나 확진자 가 급증 하 아서 병상 이 부족하 아 지자  확진자 20명 을 대구 로 이송하 ㄴ다 .\n",
      "Translation: busan is going through the street <unk> of <unk> .\n",
      "\n",
      "Original: 변기 가 막히 었 습니다 .\n",
      "Translation: the toilet does n't flush .\n",
      "\n",
      "Original: 그 바지 좀 보이 어 주 시 ㅂ시오 . 이거 얼마 에 사 ㄹ 수 있 는 것 이 ㅂ니까 ?\n",
      "Translation: i need to see these pants , and i need to buy some <unk> . how much do i have to install this ?\n",
      "\n",
      "Original: 비 가 오 아서 백화점 으로 가지 말 고 두타 로 가 았 으면 좋 겠 습니다 .\n",
      "Translation: i 'd like to go to the department store because it rained to the island .\n",
      "\n",
      "Original: 속 이 안 좋 을 때 는 죽 이나 미음 으로 아침 을 대신 하 ㅂ니다\n",
      "Translation: i feel strange to avoid a bad day , but instead of the breakfast is n't it .\n",
      "\n",
      "Original: 문 대통령 은 집단 이익 에서 벗어 나 아 라고 말 하 었 다 .\n",
      "Translation: the door was told me about the president 's opening time .\n",
      "\n",
      "Original: 이것 좀 먹어 보 ㄹ 몇 일 간 의 시간 을 주 시 어요 .\n",
      "Translation: can you give me some time to see these up ?\n",
      "\n",
      "Original: 이날 개미군단 은 외인 의 물량 을 모두 받 아 내 었 다 .\n",
      "Translation: the <unk> of this mall received all the right <unk> .\n",
      "\n",
      "Original: 통합 우승 의 목표 를 달성하 ㄴ NC 다이노스 나성범 이 메이저리그 진출 이라는 또 다른 꿈 을 향하 어 나아가 ㄴ다 .\n",
      "Translation: <unk> <unk> <unk> and <unk> the <unk> of our <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> systems .\n",
      "\n",
      "Original: 이번 구조 조정 이 제품 을 효과 적 으로 개발 하 고 판매 하 기 위하 ㄴ 회사 의 능력 강화 조처 이 ㅁ 을 이해 하 아 주 시 리라 생각 하 ㅂ니다 .\n",
      "Translation: i think we 'll make sure this work will work out as long as we can benefit from our company .\n",
      "\n",
      "Original: 요즘 이 프로그램 녹화 하 며 많은 걸 느끼 ㄴ다 \n",
      "Translation: i feel <unk> these days .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "translated_sentences = []\n",
    "for sentence in sen_list:\n",
    "    translation, attentions = translate_sentence(\n",
    "        sentence=sentence,\n",
    "        model=model,\n",
    "        en_vocab=en_vocab,\n",
    "        ko_vocab=ko_vocab,\n",
    "        sos_token=\"<sos>\",\n",
    "        eos_token=\"<eos>\",\n",
    "        device=device,\n",
    "        max_output_length=25\n",
    "    )\n",
    "    translated_sentences.append(translation)\n",
    "\n",
    "for original, translation in zip(sen_list, translated_sentences):\n",
    "    print(f\"Original: {original}\")\n",
    "    filtered_translation = [token for token in translation if token not in [\"<sos>\", \"<eos>\"]]\n",
    "    print(f\"Translation: {' '.join(filtered_translation)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdIkyYpUV2a_"
   },
   "source": [
    "## Bleu Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_awwNcYov21"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def calculate_bleu(reference, prediction, weights=[1, 0, 0, 0]):\n",
    "    score = corpus_bleu(reference, prediction, weights=weights)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S-jgm9uZov21",
    "outputId": "10d654e1-8fe4-4310-99e7-c88ca7fc57ab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33098/33098 [24:37<00:00, 22.40it/s]\n"
     ]
    }
   ],
   "source": [
    "translations = [\n",
    "    translate_sentence(\n",
    "        example[\"ko\"],\n",
    "        model,\n",
    "        en_vocab,\n",
    "        ko_vocab,\n",
    "        sos_token,\n",
    "        eos_token,\n",
    "        device,\n",
    "        max_output_length=25,\n",
    "        lower=True,\n",
    "    )\n",
    "    for example in tqdm.tqdm(test_data)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rmE3fucxov22",
    "outputId": "cf140fca-9891-446d-b904-d8f686904a16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['<sos>', 'i', \"'m\", 'looking', 'for', 'a', 'spoon', 'stand', '.', '<eos>'], [tensor([[[[0.1809, 0.2804, 0.1938, 0.0308, 0.0453, 0.0505, 0.0336, 0.1849]],\n",
      "\n",
      "         [[0.0350, 0.0707, 0.1608, 0.0812, 0.1926, 0.1594, 0.2653, 0.0350]],\n",
      "\n",
      "         [[0.0911, 0.0597, 0.1563, 0.0789, 0.1440, 0.1262, 0.2565, 0.0873]],\n",
      "\n",
      "         [[0.0934, 0.0896, 0.2173, 0.0895, 0.1479, 0.0563, 0.2165, 0.0895]],\n",
      "\n",
      "         [[0.1822, 0.1334, 0.1522, 0.0392, 0.0903, 0.0649, 0.1659, 0.1719]],\n",
      "\n",
      "         [[0.1431, 0.1238, 0.1823, 0.0603, 0.1085, 0.1035, 0.1421, 0.1364]],\n",
      "\n",
      "         [[0.0324, 0.0475, 0.2220, 0.1067, 0.1826, 0.0820, 0.2950, 0.0319]],\n",
      "\n",
      "         [[0.0310, 0.0379, 0.1628, 0.0537, 0.2239, 0.1650, 0.2948, 0.0308]]]]), tensor([[[[0.1809, 0.2804, 0.1938, 0.0308, 0.0453, 0.0505, 0.0336, 0.1849],\n",
      "          [0.0075, 0.0122, 0.1085, 0.2855, 0.1220, 0.2123, 0.2447, 0.0073]],\n",
      "\n",
      "         [[0.0350, 0.0707, 0.1608, 0.0812, 0.1926, 0.1594, 0.2653, 0.0350],\n",
      "          [0.0073, 0.0050, 0.1398, 0.4022, 0.1754, 0.0927, 0.1703, 0.0072]],\n",
      "\n",
      "         [[0.0911, 0.0597, 0.1563, 0.0789, 0.1440, 0.1262, 0.2565, 0.0873],\n",
      "          [0.0048, 0.0033, 0.0697, 0.3201, 0.2630, 0.1847, 0.1496, 0.0049]],\n",
      "\n",
      "         [[0.0934, 0.0896, 0.2173, 0.0895, 0.1479, 0.0563, 0.2165, 0.0895],\n",
      "          [0.0023, 0.0013, 0.0553, 0.4188, 0.0808, 0.0705, 0.3688, 0.0022]],\n",
      "\n",
      "         [[0.1822, 0.1334, 0.1522, 0.0392, 0.0903, 0.0649, 0.1659, 0.1719],\n",
      "          [0.0243, 0.0079, 0.1133, 0.1692, 0.1563, 0.2083, 0.2969, 0.0236]],\n",
      "\n",
      "         [[0.1431, 0.1238, 0.1823, 0.0603, 0.1085, 0.1035, 0.1421, 0.1364],\n",
      "          [0.0062, 0.0062, 0.0970, 0.3009, 0.1446, 0.2202, 0.2186, 0.0062]],\n",
      "\n",
      "         [[0.0324, 0.0475, 0.2220, 0.1067, 0.1826, 0.0820, 0.2950, 0.0319],\n",
      "          [0.0781, 0.0624, 0.1624, 0.1702, 0.2831, 0.0987, 0.0651, 0.0799]],\n",
      "\n",
      "         [[0.0310, 0.0379, 0.1628, 0.0537, 0.2239, 0.1650, 0.2948, 0.0308],\n",
      "          [0.0228, 0.0172, 0.0694, 0.0530, 0.2407, 0.3568, 0.2177, 0.0225]]]]), tensor([[[[1.8088e-01, 2.8039e-01, 1.9378e-01, 3.0785e-02, 4.5251e-02,\n",
      "           5.0464e-02, 3.3565e-02, 1.8489e-01],\n",
      "          [7.5304e-03, 1.2202e-02, 1.0847e-01, 2.8553e-01, 1.2199e-01,\n",
      "           2.1229e-01, 2.4467e-01, 7.3144e-03],\n",
      "          [4.0077e-03, 3.8319e-03, 1.2366e-01, 4.3989e-01, 1.9551e-01,\n",
      "           5.4361e-02, 1.7468e-01, 4.0617e-03]],\n",
      "\n",
      "         [[3.4970e-02, 7.0678e-02, 1.6080e-01, 8.1224e-02, 1.9261e-01,\n",
      "           1.5945e-01, 2.6527e-01, 3.5008e-02],\n",
      "          [7.2603e-03, 5.0477e-03, 1.3985e-01, 4.0217e-01, 1.7541e-01,\n",
      "           9.2739e-02, 1.7028e-01, 7.2425e-03],\n",
      "          [9.7523e-03, 7.3225e-03, 2.1378e-01, 5.0259e-01, 1.1437e-01,\n",
      "           4.9757e-02, 9.2361e-02, 1.0067e-02]],\n",
      "\n",
      "         [[9.1086e-02, 5.9748e-02, 1.5627e-01, 7.8903e-02, 1.4400e-01,\n",
      "           1.2623e-01, 2.5652e-01, 8.7252e-02],\n",
      "          [4.7961e-03, 3.3490e-03, 6.9669e-02, 3.2010e-01, 2.6297e-01,\n",
      "           1.8468e-01, 1.4956e-01, 4.8790e-03],\n",
      "          [1.2246e-03, 5.0496e-04, 5.7768e-02, 6.5043e-01, 1.5751e-01,\n",
      "           7.6719e-02, 5.4536e-02, 1.3113e-03]],\n",
      "\n",
      "         [[9.3382e-02, 8.9572e-02, 2.1734e-01, 8.9489e-02, 1.4789e-01,\n",
      "           5.6300e-02, 2.1653e-01, 8.9501e-02],\n",
      "          [2.2735e-03, 1.3380e-03, 5.5319e-02, 4.1877e-01, 8.0788e-02,\n",
      "           7.0452e-02, 3.6885e-01, 2.2139e-03],\n",
      "          [1.3129e-03, 5.7109e-04, 4.5945e-02, 8.4918e-01, 3.2164e-02,\n",
      "           1.8211e-02, 5.1235e-02, 1.3813e-03]],\n",
      "\n",
      "         [[1.8224e-01, 1.3337e-01, 1.5220e-01, 3.9167e-02, 9.0343e-02,\n",
      "           6.4927e-02, 1.6589e-01, 1.7188e-01],\n",
      "          [2.4327e-02, 7.9471e-03, 1.1328e-01, 1.6921e-01, 1.5633e-01,\n",
      "           2.0835e-01, 2.9695e-01, 2.3605e-02],\n",
      "          [6.8597e-03, 5.7902e-03, 1.6078e-01, 3.3996e-01, 2.4150e-01,\n",
      "           9.2997e-02, 1.4498e-01, 7.1345e-03]],\n",
      "\n",
      "         [[1.4307e-01, 1.2381e-01, 1.8225e-01, 6.0313e-02, 1.0855e-01,\n",
      "           1.0353e-01, 1.4207e-01, 1.3641e-01],\n",
      "          [6.1675e-03, 6.2484e-03, 9.6974e-02, 3.0091e-01, 1.4462e-01,\n",
      "           2.2025e-01, 2.1863e-01, 6.2027e-03],\n",
      "          [3.6362e-03, 4.9105e-03, 1.0370e-01, 3.8515e-01, 1.9101e-01,\n",
      "           1.1090e-01, 1.9698e-01, 3.7075e-03]],\n",
      "\n",
      "         [[3.2358e-02, 4.7515e-02, 2.2199e-01, 1.0669e-01, 1.8258e-01,\n",
      "           8.2013e-02, 2.9499e-01, 3.1870e-02],\n",
      "          [7.8119e-02, 6.2411e-02, 1.6239e-01, 1.7023e-01, 2.8311e-01,\n",
      "           9.8709e-02, 6.5092e-02, 7.9932e-02],\n",
      "          [8.8919e-03, 4.8062e-03, 7.2250e-02, 3.7360e-01, 4.5085e-01,\n",
      "           5.6435e-02, 2.3503e-02, 9.6649e-03]],\n",
      "\n",
      "         [[3.1025e-02, 3.7944e-02, 1.6277e-01, 5.3668e-02, 2.2394e-01,\n",
      "           1.6504e-01, 2.9484e-01, 3.0779e-02],\n",
      "          [2.2778e-02, 1.7222e-02, 6.9377e-02, 5.2954e-02, 2.4066e-01,\n",
      "           3.5681e-01, 2.1767e-01, 2.2532e-02],\n",
      "          [1.0302e-02, 9.4600e-03, 1.1837e-01, 1.9120e-01, 3.9302e-01,\n",
      "           1.8360e-01, 8.3429e-02, 1.0631e-02]]]]), tensor([[[[1.8088e-01, 2.8039e-01, 1.9378e-01, 3.0785e-02, 4.5251e-02,\n",
      "           5.0464e-02, 3.3565e-02, 1.8489e-01],\n",
      "          [7.5304e-03, 1.2202e-02, 1.0847e-01, 2.8553e-01, 1.2199e-01,\n",
      "           2.1229e-01, 2.4467e-01, 7.3144e-03],\n",
      "          [4.0077e-03, 3.8319e-03, 1.2366e-01, 4.3989e-01, 1.9551e-01,\n",
      "           5.4361e-02, 1.7468e-01, 4.0617e-03],\n",
      "          [3.3900e-02, 2.5823e-02, 1.9126e-01, 3.5174e-01, 1.8483e-01,\n",
      "           6.6141e-02, 1.1116e-01, 3.5142e-02]],\n",
      "\n",
      "         [[3.4970e-02, 7.0678e-02, 1.6080e-01, 8.1224e-02, 1.9261e-01,\n",
      "           1.5945e-01, 2.6527e-01, 3.5008e-02],\n",
      "          [7.2603e-03, 5.0477e-03, 1.3985e-01, 4.0217e-01, 1.7541e-01,\n",
      "           9.2739e-02, 1.7028e-01, 7.2425e-03],\n",
      "          [9.7523e-03, 7.3225e-03, 2.1378e-01, 5.0259e-01, 1.1437e-01,\n",
      "           4.9757e-02, 9.2361e-02, 1.0067e-02],\n",
      "          [2.8251e-02, 3.6802e-02, 2.0533e-01, 3.8092e-01, 1.6616e-01,\n",
      "           4.6863e-02, 1.0710e-01, 2.8570e-02]],\n",
      "\n",
      "         [[9.1086e-02, 5.9748e-02, 1.5627e-01, 7.8903e-02, 1.4400e-01,\n",
      "           1.2623e-01, 2.5652e-01, 8.7252e-02],\n",
      "          [4.7961e-03, 3.3490e-03, 6.9669e-02, 3.2010e-01, 2.6297e-01,\n",
      "           1.8468e-01, 1.4956e-01, 4.8790e-03],\n",
      "          [1.2246e-03, 5.0496e-04, 5.7768e-02, 6.5043e-01, 1.5751e-01,\n",
      "           7.6719e-02, 5.4536e-02, 1.3113e-03],\n",
      "          [1.2996e-01, 7.3096e-02, 2.0284e-01, 1.9800e-01, 1.1690e-01,\n",
      "           9.9548e-02, 4.2558e-02, 1.3710e-01]],\n",
      "\n",
      "         [[9.3382e-02, 8.9572e-02, 2.1734e-01, 8.9489e-02, 1.4789e-01,\n",
      "           5.6300e-02, 2.1653e-01, 8.9501e-02],\n",
      "          [2.2735e-03, 1.3380e-03, 5.5319e-02, 4.1877e-01, 8.0788e-02,\n",
      "           7.0452e-02, 3.6885e-01, 2.2139e-03],\n",
      "          [1.3129e-03, 5.7109e-04, 4.5945e-02, 8.4918e-01, 3.2164e-02,\n",
      "           1.8211e-02, 5.1235e-02, 1.3813e-03],\n",
      "          [1.2883e-01, 6.2459e-02, 1.5678e-01, 3.2735e-01, 1.0482e-01,\n",
      "           2.4133e-02, 6.3885e-02, 1.3175e-01]],\n",
      "\n",
      "         [[1.8224e-01, 1.3337e-01, 1.5220e-01, 3.9167e-02, 9.0343e-02,\n",
      "           6.4927e-02, 1.6589e-01, 1.7188e-01],\n",
      "          [2.4327e-02, 7.9471e-03, 1.1328e-01, 1.6921e-01, 1.5633e-01,\n",
      "           2.0835e-01, 2.9695e-01, 2.3605e-02],\n",
      "          [6.8597e-03, 5.7902e-03, 1.6078e-01, 3.3996e-01, 2.4150e-01,\n",
      "           9.2997e-02, 1.4498e-01, 7.1345e-03],\n",
      "          [1.6629e-02, 1.3361e-02, 1.5583e-01, 5.6956e-01, 9.8352e-02,\n",
      "           5.7995e-02, 7.0956e-02, 1.7314e-02]],\n",
      "\n",
      "         [[1.4307e-01, 1.2381e-01, 1.8225e-01, 6.0313e-02, 1.0855e-01,\n",
      "           1.0353e-01, 1.4207e-01, 1.3641e-01],\n",
      "          [6.1675e-03, 6.2484e-03, 9.6974e-02, 3.0091e-01, 1.4462e-01,\n",
      "           2.2025e-01, 2.1863e-01, 6.2027e-03],\n",
      "          [3.6362e-03, 4.9105e-03, 1.0370e-01, 3.8515e-01, 1.9101e-01,\n",
      "           1.1090e-01, 1.9698e-01, 3.7075e-03],\n",
      "          [1.1283e-01, 9.1424e-02, 1.6952e-01, 1.1797e-01, 1.9653e-01,\n",
      "           6.8236e-02, 1.3095e-01, 1.1255e-01]],\n",
      "\n",
      "         [[3.2358e-02, 4.7515e-02, 2.2199e-01, 1.0669e-01, 1.8258e-01,\n",
      "           8.2013e-02, 2.9499e-01, 3.1870e-02],\n",
      "          [7.8119e-02, 6.2411e-02, 1.6239e-01, 1.7023e-01, 2.8311e-01,\n",
      "           9.8709e-02, 6.5092e-02, 7.9932e-02],\n",
      "          [8.8919e-03, 4.8062e-03, 7.2250e-02, 3.7360e-01, 4.5085e-01,\n",
      "           5.6435e-02, 2.3503e-02, 9.6649e-03],\n",
      "          [3.5152e-02, 2.4630e-02, 1.5207e-01, 4.0419e-01, 2.0576e-01,\n",
      "           7.8335e-02, 6.2017e-02, 3.7847e-02]],\n",
      "\n",
      "         [[3.1025e-02, 3.7944e-02, 1.6277e-01, 5.3668e-02, 2.2394e-01,\n",
      "           1.6504e-01, 2.9484e-01, 3.0779e-02],\n",
      "          [2.2778e-02, 1.7222e-02, 6.9377e-02, 5.2954e-02, 2.4066e-01,\n",
      "           3.5681e-01, 2.1767e-01, 2.2532e-02],\n",
      "          [1.0302e-02, 9.4600e-03, 1.1837e-01, 1.9120e-01, 3.9302e-01,\n",
      "           1.8360e-01, 8.3429e-02, 1.0631e-02],\n",
      "          [1.0883e-01, 8.8603e-02, 1.7749e-01, 1.7370e-01, 1.5306e-01,\n",
      "           1.1626e-01, 6.6375e-02, 1.1567e-01]]]]), tensor([[[[1.8088e-01, 2.8039e-01, 1.9378e-01, 3.0785e-02, 4.5251e-02,\n",
      "           5.0464e-02, 3.3565e-02, 1.8489e-01],\n",
      "          [7.5304e-03, 1.2202e-02, 1.0847e-01, 2.8553e-01, 1.2199e-01,\n",
      "           2.1229e-01, 2.4467e-01, 7.3144e-03],\n",
      "          [4.0077e-03, 3.8319e-03, 1.2366e-01, 4.3989e-01, 1.9551e-01,\n",
      "           5.4361e-02, 1.7468e-01, 4.0617e-03],\n",
      "          [3.3900e-02, 2.5823e-02, 1.9126e-01, 3.5174e-01, 1.8483e-01,\n",
      "           6.6141e-02, 1.1116e-01, 3.5142e-02],\n",
      "          [3.1719e-01, 3.3381e-01, 1.2389e-02, 3.2286e-03, 2.4507e-03,\n",
      "           1.9257e-03, 3.0085e-03, 3.2599e-01]],\n",
      "\n",
      "         [[3.4970e-02, 7.0678e-02, 1.6080e-01, 8.1224e-02, 1.9261e-01,\n",
      "           1.5945e-01, 2.6527e-01, 3.5008e-02],\n",
      "          [7.2603e-03, 5.0477e-03, 1.3985e-01, 4.0217e-01, 1.7541e-01,\n",
      "           9.2739e-02, 1.7028e-01, 7.2425e-03],\n",
      "          [9.7523e-03, 7.3225e-03, 2.1378e-01, 5.0259e-01, 1.1437e-01,\n",
      "           4.9757e-02, 9.2361e-02, 1.0067e-02],\n",
      "          [2.8251e-02, 3.6802e-02, 2.0533e-01, 3.8092e-01, 1.6616e-01,\n",
      "           4.6863e-02, 1.0710e-01, 2.8570e-02],\n",
      "          [2.3320e-01, 4.8366e-01, 2.6468e-02, 5.2339e-03, 6.2638e-03,\n",
      "           5.7362e-03, 5.8041e-03, 2.3364e-01]],\n",
      "\n",
      "         [[9.1086e-02, 5.9748e-02, 1.5627e-01, 7.8903e-02, 1.4400e-01,\n",
      "           1.2623e-01, 2.5652e-01, 8.7252e-02],\n",
      "          [4.7961e-03, 3.3490e-03, 6.9669e-02, 3.2010e-01, 2.6297e-01,\n",
      "           1.8468e-01, 1.4956e-01, 4.8790e-03],\n",
      "          [1.2246e-03, 5.0496e-04, 5.7768e-02, 6.5043e-01, 1.5751e-01,\n",
      "           7.6719e-02, 5.4536e-02, 1.3113e-03],\n",
      "          [1.2996e-01, 7.3096e-02, 2.0284e-01, 1.9800e-01, 1.1690e-01,\n",
      "           9.9548e-02, 4.2558e-02, 1.3710e-01],\n",
      "          [2.3285e-01, 4.8692e-01, 2.0276e-02, 4.2422e-03, 2.7398e-03,\n",
      "           5.4333e-03, 1.5220e-03, 2.4602e-01]],\n",
      "\n",
      "         [[9.3382e-02, 8.9572e-02, 2.1734e-01, 8.9489e-02, 1.4789e-01,\n",
      "           5.6300e-02, 2.1653e-01, 8.9501e-02],\n",
      "          [2.2735e-03, 1.3380e-03, 5.5319e-02, 4.1877e-01, 8.0788e-02,\n",
      "           7.0452e-02, 3.6885e-01, 2.2139e-03],\n",
      "          [1.3129e-03, 5.7109e-04, 4.5945e-02, 8.4918e-01, 3.2164e-02,\n",
      "           1.8211e-02, 5.1235e-02, 1.3813e-03],\n",
      "          [1.2883e-01, 6.2459e-02, 1.5678e-01, 3.2735e-01, 1.0482e-01,\n",
      "           2.4133e-02, 6.3885e-02, 1.3175e-01],\n",
      "          [2.9842e-01, 3.8031e-01, 6.5970e-03, 2.6692e-03, 8.8935e-04,\n",
      "           3.4799e-04, 6.7777e-04, 3.1009e-01]],\n",
      "\n",
      "         [[1.8224e-01, 1.3337e-01, 1.5220e-01, 3.9167e-02, 9.0343e-02,\n",
      "           6.4927e-02, 1.6589e-01, 1.7188e-01],\n",
      "          [2.4327e-02, 7.9471e-03, 1.1328e-01, 1.6921e-01, 1.5633e-01,\n",
      "           2.0835e-01, 2.9695e-01, 2.3605e-02],\n",
      "          [6.8597e-03, 5.7902e-03, 1.6078e-01, 3.3996e-01, 2.4150e-01,\n",
      "           9.2997e-02, 1.4498e-01, 7.1345e-03],\n",
      "          [1.6629e-02, 1.3361e-02, 1.5583e-01, 5.6956e-01, 9.8352e-02,\n",
      "           5.7995e-02, 7.0956e-02, 1.7314e-02],\n",
      "          [1.4306e-01, 5.4599e-01, 9.8338e-02, 2.3882e-02, 1.0093e-02,\n",
      "           1.3055e-02, 1.2191e-02, 1.5339e-01]],\n",
      "\n",
      "         [[1.4307e-01, 1.2381e-01, 1.8225e-01, 6.0313e-02, 1.0855e-01,\n",
      "           1.0353e-01, 1.4207e-01, 1.3641e-01],\n",
      "          [6.1674e-03, 6.2483e-03, 9.6974e-02, 3.0091e-01, 1.4462e-01,\n",
      "           2.2025e-01, 2.1863e-01, 6.2027e-03],\n",
      "          [3.6362e-03, 4.9105e-03, 1.0370e-01, 3.8515e-01, 1.9101e-01,\n",
      "           1.1090e-01, 1.9698e-01, 3.7075e-03],\n",
      "          [1.1283e-01, 9.1424e-02, 1.6952e-01, 1.1797e-01, 1.9653e-01,\n",
      "           6.8236e-02, 1.3095e-01, 1.1255e-01],\n",
      "          [2.1764e-01, 5.2619e-01, 1.5425e-02, 6.6703e-03, 4.4581e-03,\n",
      "           5.2528e-03, 7.2990e-03, 2.1706e-01]],\n",
      "\n",
      "         [[3.2358e-02, 4.7515e-02, 2.2199e-01, 1.0669e-01, 1.8258e-01,\n",
      "           8.2013e-02, 2.9499e-01, 3.1870e-02],\n",
      "          [7.8119e-02, 6.2411e-02, 1.6239e-01, 1.7023e-01, 2.8311e-01,\n",
      "           9.8709e-02, 6.5092e-02, 7.9932e-02],\n",
      "          [8.8919e-03, 4.8062e-03, 7.2250e-02, 3.7360e-01, 4.5085e-01,\n",
      "           5.6435e-02, 2.3503e-02, 9.6649e-03],\n",
      "          [3.5152e-02, 2.4630e-02, 1.5207e-01, 4.0419e-01, 2.0576e-01,\n",
      "           7.8335e-02, 6.2017e-02, 3.7847e-02],\n",
      "          [2.5079e-01, 4.4980e-01, 1.3253e-02, 6.6651e-03, 5.9986e-03,\n",
      "           3.6548e-03, 3.8146e-03, 2.6602e-01]],\n",
      "\n",
      "         [[3.1025e-02, 3.7944e-02, 1.6277e-01, 5.3668e-02, 2.2394e-01,\n",
      "           1.6504e-01, 2.9484e-01, 3.0779e-02],\n",
      "          [2.2778e-02, 1.7222e-02, 6.9377e-02, 5.2954e-02, 2.4066e-01,\n",
      "           3.5681e-01, 2.1767e-01, 2.2532e-02],\n",
      "          [1.0302e-02, 9.4600e-03, 1.1837e-01, 1.9120e-01, 3.9302e-01,\n",
      "           1.8360e-01, 8.3429e-02, 1.0631e-02],\n",
      "          [1.0883e-01, 8.8603e-02, 1.7749e-01, 1.7370e-01, 1.5306e-01,\n",
      "           1.1626e-01, 6.6374e-02, 1.1567e-01],\n",
      "          [3.0025e-01, 3.6333e-01, 1.2522e-02, 5.3565e-03, 2.7944e-03,\n",
      "           1.4495e-03, 2.7593e-03, 3.1154e-01]]]]), tensor([[[[1.8088e-01, 2.8039e-01, 1.9378e-01, 3.0785e-02, 4.5251e-02,\n",
      "           5.0464e-02, 3.3565e-02, 1.8489e-01],\n",
      "          [7.5304e-03, 1.2202e-02, 1.0847e-01, 2.8553e-01, 1.2199e-01,\n",
      "           2.1229e-01, 2.4467e-01, 7.3144e-03],\n",
      "          [4.0077e-03, 3.8319e-03, 1.2366e-01, 4.3989e-01, 1.9551e-01,\n",
      "           5.4361e-02, 1.7468e-01, 4.0617e-03],\n",
      "          [3.3900e-02, 2.5823e-02, 1.9126e-01, 3.5174e-01, 1.8483e-01,\n",
      "           6.6141e-02, 1.1116e-01, 3.5142e-02],\n",
      "          [3.1719e-01, 3.3381e-01, 1.2389e-02, 3.2286e-03, 2.4507e-03,\n",
      "           1.9257e-03, 3.0085e-03, 3.2599e-01],\n",
      "          [3.3881e-01, 2.8472e-01, 6.8819e-03, 1.6569e-03, 1.5887e-03,\n",
      "           2.3873e-03, 9.6115e-04, 3.6299e-01]],\n",
      "\n",
      "         [[3.4970e-02, 7.0678e-02, 1.6080e-01, 8.1224e-02, 1.9261e-01,\n",
      "           1.5945e-01, 2.6527e-01, 3.5008e-02],\n",
      "          [7.2603e-03, 5.0477e-03, 1.3985e-01, 4.0217e-01, 1.7541e-01,\n",
      "           9.2739e-02, 1.7028e-01, 7.2425e-03],\n",
      "          [9.7523e-03, 7.3225e-03, 2.1378e-01, 5.0259e-01, 1.1437e-01,\n",
      "           4.9757e-02, 9.2361e-02, 1.0067e-02],\n",
      "          [2.8251e-02, 3.6802e-02, 2.0533e-01, 3.8092e-01, 1.6616e-01,\n",
      "           4.6863e-02, 1.0710e-01, 2.8570e-02],\n",
      "          [2.3320e-01, 4.8366e-01, 2.6468e-02, 5.2339e-03, 6.2638e-03,\n",
      "           5.7362e-03, 5.8041e-03, 2.3364e-01],\n",
      "          [2.7920e-01, 4.2622e-01, 2.2668e-03, 7.4153e-04, 5.6009e-04,\n",
      "           1.5650e-03, 9.0140e-04, 2.8854e-01]],\n",
      "\n",
      "         [[9.1086e-02, 5.9748e-02, 1.5627e-01, 7.8903e-02, 1.4400e-01,\n",
      "           1.2623e-01, 2.5652e-01, 8.7252e-02],\n",
      "          [4.7961e-03, 3.3490e-03, 6.9669e-02, 3.2010e-01, 2.6297e-01,\n",
      "           1.8468e-01, 1.4956e-01, 4.8790e-03],\n",
      "          [1.2246e-03, 5.0496e-04, 5.7768e-02, 6.5043e-01, 1.5751e-01,\n",
      "           7.6719e-02, 5.4536e-02, 1.3113e-03],\n",
      "          [1.2996e-01, 7.3096e-02, 2.0284e-01, 1.9800e-01, 1.1690e-01,\n",
      "           9.9548e-02, 4.2558e-02, 1.3710e-01],\n",
      "          [2.3285e-01, 4.8692e-01, 2.0276e-02, 4.2422e-03, 2.7398e-03,\n",
      "           5.4333e-03, 1.5220e-03, 2.4602e-01],\n",
      "          [3.2079e-01, 3.2769e-01, 4.4881e-03, 1.1691e-03, 1.0446e-03,\n",
      "           1.0744e-03, 6.9654e-04, 3.4305e-01]],\n",
      "\n",
      "         [[9.3382e-02, 8.9572e-02, 2.1734e-01, 8.9489e-02, 1.4789e-01,\n",
      "           5.6300e-02, 2.1653e-01, 8.9501e-02],\n",
      "          [2.2735e-03, 1.3380e-03, 5.5319e-02, 4.1877e-01, 8.0788e-02,\n",
      "           7.0452e-02, 3.6885e-01, 2.2139e-03],\n",
      "          [1.3129e-03, 5.7109e-04, 4.5945e-02, 8.4918e-01, 3.2164e-02,\n",
      "           1.8211e-02, 5.1235e-02, 1.3813e-03],\n",
      "          [1.2883e-01, 6.2459e-02, 1.5678e-01, 3.2735e-01, 1.0482e-01,\n",
      "           2.4133e-02, 6.3885e-02, 1.3175e-01],\n",
      "          [2.9842e-01, 3.8031e-01, 6.5970e-03, 2.6692e-03, 8.8935e-04,\n",
      "           3.4799e-04, 6.7777e-04, 3.1009e-01],\n",
      "          [2.9393e-01, 3.6996e-01, 6.8506e-03, 2.4541e-03, 1.7781e-03,\n",
      "           1.9559e-03, 3.3847e-03, 3.1969e-01]],\n",
      "\n",
      "         [[1.8224e-01, 1.3337e-01, 1.5220e-01, 3.9167e-02, 9.0343e-02,\n",
      "           6.4927e-02, 1.6589e-01, 1.7188e-01],\n",
      "          [2.4327e-02, 7.9471e-03, 1.1328e-01, 1.6921e-01, 1.5633e-01,\n",
      "           2.0835e-01, 2.9695e-01, 2.3605e-02],\n",
      "          [6.8597e-03, 5.7902e-03, 1.6078e-01, 3.3996e-01, 2.4150e-01,\n",
      "           9.2997e-02, 1.4498e-01, 7.1345e-03],\n",
      "          [1.6629e-02, 1.3361e-02, 1.5583e-01, 5.6956e-01, 9.8352e-02,\n",
      "           5.7995e-02, 7.0956e-02, 1.7314e-02],\n",
      "          [1.4306e-01, 5.4599e-01, 9.8338e-02, 2.3882e-02, 1.0093e-02,\n",
      "           1.3055e-02, 1.2191e-02, 1.5339e-01],\n",
      "          [2.2756e-01, 4.5846e-01, 3.0955e-02, 1.3794e-02, 7.8202e-03,\n",
      "           1.0267e-02, 9.2755e-03, 2.4187e-01]],\n",
      "\n",
      "         [[1.4307e-01, 1.2381e-01, 1.8225e-01, 6.0313e-02, 1.0855e-01,\n",
      "           1.0353e-01, 1.4207e-01, 1.3641e-01],\n",
      "          [6.1674e-03, 6.2483e-03, 9.6974e-02, 3.0091e-01, 1.4462e-01,\n",
      "           2.2025e-01, 2.1863e-01, 6.2027e-03],\n",
      "          [3.6362e-03, 4.9105e-03, 1.0370e-01, 3.8515e-01, 1.9101e-01,\n",
      "           1.1090e-01, 1.9698e-01, 3.7075e-03],\n",
      "          [1.1283e-01, 9.1424e-02, 1.6952e-01, 1.1797e-01, 1.9653e-01,\n",
      "           6.8236e-02, 1.3095e-01, 1.1255e-01],\n",
      "          [2.1764e-01, 5.2619e-01, 1.5425e-02, 6.6703e-03, 4.4581e-03,\n",
      "           5.2528e-03, 7.2990e-03, 2.1706e-01],\n",
      "          [2.0158e-01, 5.6386e-01, 6.5561e-03, 3.3095e-03, 3.3723e-03,\n",
      "           5.4991e-03, 2.1671e-03, 2.1365e-01]],\n",
      "\n",
      "         [[3.2358e-02, 4.7515e-02, 2.2199e-01, 1.0669e-01, 1.8258e-01,\n",
      "           8.2013e-02, 2.9499e-01, 3.1870e-02],\n",
      "          [7.8119e-02, 6.2411e-02, 1.6239e-01, 1.7023e-01, 2.8311e-01,\n",
      "           9.8709e-02, 6.5092e-02, 7.9932e-02],\n",
      "          [8.8919e-03, 4.8062e-03, 7.2250e-02, 3.7360e-01, 4.5085e-01,\n",
      "           5.6435e-02, 2.3503e-02, 9.6649e-03],\n",
      "          [3.5152e-02, 2.4630e-02, 1.5207e-01, 4.0419e-01, 2.0576e-01,\n",
      "           7.8335e-02, 6.2017e-02, 3.7847e-02],\n",
      "          [2.5079e-01, 4.4980e-01, 1.3253e-02, 6.6651e-03, 5.9986e-03,\n",
      "           3.6548e-03, 3.8146e-03, 2.6602e-01],\n",
      "          [2.0661e-01, 5.7065e-01, 5.1815e-03, 1.5484e-03, 2.5201e-03,\n",
      "           1.0229e-03, 1.0770e-03, 2.1139e-01]],\n",
      "\n",
      "         [[3.1025e-02, 3.7944e-02, 1.6277e-01, 5.3668e-02, 2.2394e-01,\n",
      "           1.6504e-01, 2.9484e-01, 3.0779e-02],\n",
      "          [2.2778e-02, 1.7222e-02, 6.9377e-02, 5.2954e-02, 2.4066e-01,\n",
      "           3.5681e-01, 2.1767e-01, 2.2532e-02],\n",
      "          [1.0302e-02, 9.4600e-03, 1.1837e-01, 1.9120e-01, 3.9302e-01,\n",
      "           1.8360e-01, 8.3429e-02, 1.0631e-02],\n",
      "          [1.0883e-01, 8.8603e-02, 1.7749e-01, 1.7370e-01, 1.5306e-01,\n",
      "           1.1626e-01, 6.6374e-02, 1.1567e-01],\n",
      "          [3.0025e-01, 3.6333e-01, 1.2522e-02, 5.3565e-03, 2.7944e-03,\n",
      "           1.4495e-03, 2.7593e-03, 3.1154e-01],\n",
      "          [2.8017e-01, 4.1404e-01, 7.1818e-03, 2.9017e-03, 2.2469e-03,\n",
      "           1.4020e-03, 2.4073e-03, 2.8966e-01]]]]), tensor([[[[1.8088e-01, 2.8039e-01, 1.9378e-01, 3.0785e-02, 4.5251e-02,\n",
      "           5.0464e-02, 3.3565e-02, 1.8489e-01],\n",
      "          [7.5304e-03, 1.2202e-02, 1.0847e-01, 2.8553e-01, 1.2199e-01,\n",
      "           2.1229e-01, 2.4467e-01, 7.3144e-03],\n",
      "          [4.0077e-03, 3.8319e-03, 1.2366e-01, 4.3989e-01, 1.9551e-01,\n",
      "           5.4361e-02, 1.7468e-01, 4.0617e-03],\n",
      "          [3.3900e-02, 2.5823e-02, 1.9126e-01, 3.5174e-01, 1.8483e-01,\n",
      "           6.6141e-02, 1.1116e-01, 3.5142e-02],\n",
      "          [3.1719e-01, 3.3381e-01, 1.2389e-02, 3.2286e-03, 2.4507e-03,\n",
      "           1.9257e-03, 3.0085e-03, 3.2599e-01],\n",
      "          [3.3881e-01, 2.8472e-01, 6.8819e-03, 1.6569e-03, 1.5887e-03,\n",
      "           2.3873e-03, 9.6115e-04, 3.6299e-01],\n",
      "          [3.3588e-01, 2.6570e-01, 1.6715e-02, 5.7133e-03, 8.8207e-03,\n",
      "           2.0787e-02, 5.8224e-03, 3.4056e-01]],\n",
      "\n",
      "         [[3.4970e-02, 7.0678e-02, 1.6080e-01, 8.1224e-02, 1.9261e-01,\n",
      "           1.5945e-01, 2.6527e-01, 3.5008e-02],\n",
      "          [7.2603e-03, 5.0477e-03, 1.3985e-01, 4.0217e-01, 1.7541e-01,\n",
      "           9.2739e-02, 1.7028e-01, 7.2425e-03],\n",
      "          [9.7523e-03, 7.3225e-03, 2.1378e-01, 5.0259e-01, 1.1437e-01,\n",
      "           4.9757e-02, 9.2361e-02, 1.0067e-02],\n",
      "          [2.8251e-02, 3.6802e-02, 2.0533e-01, 3.8092e-01, 1.6616e-01,\n",
      "           4.6863e-02, 1.0710e-01, 2.8570e-02],\n",
      "          [2.3320e-01, 4.8366e-01, 2.6468e-02, 5.2339e-03, 6.2638e-03,\n",
      "           5.7362e-03, 5.8041e-03, 2.3364e-01],\n",
      "          [2.7920e-01, 4.2622e-01, 2.2668e-03, 7.4153e-04, 5.6009e-04,\n",
      "           1.5650e-03, 9.0140e-04, 2.8854e-01],\n",
      "          [2.2666e-01, 3.1859e-01, 4.1618e-02, 3.9897e-02, 4.9346e-02,\n",
      "           6.6939e-02, 2.5033e-02, 2.3192e-01]],\n",
      "\n",
      "         [[9.1086e-02, 5.9748e-02, 1.5627e-01, 7.8903e-02, 1.4400e-01,\n",
      "           1.2623e-01, 2.5652e-01, 8.7252e-02],\n",
      "          [4.7961e-03, 3.3490e-03, 6.9669e-02, 3.2010e-01, 2.6297e-01,\n",
      "           1.8468e-01, 1.4956e-01, 4.8790e-03],\n",
      "          [1.2246e-03, 5.0496e-04, 5.7768e-02, 6.5043e-01, 1.5751e-01,\n",
      "           7.6719e-02, 5.4536e-02, 1.3113e-03],\n",
      "          [1.2996e-01, 7.3096e-02, 2.0284e-01, 1.9800e-01, 1.1690e-01,\n",
      "           9.9548e-02, 4.2558e-02, 1.3710e-01],\n",
      "          [2.3285e-01, 4.8692e-01, 2.0276e-02, 4.2422e-03, 2.7398e-03,\n",
      "           5.4333e-03, 1.5220e-03, 2.4602e-01],\n",
      "          [3.2079e-01, 3.2769e-01, 4.4881e-03, 1.1691e-03, 1.0446e-03,\n",
      "           1.0744e-03, 6.9654e-04, 3.4305e-01],\n",
      "          [3.1611e-01, 2.5945e-01, 2.5582e-02, 9.2508e-03, 1.7874e-02,\n",
      "           3.2535e-02, 7.7488e-03, 3.3145e-01]],\n",
      "\n",
      "         [[9.3382e-02, 8.9572e-02, 2.1734e-01, 8.9489e-02, 1.4789e-01,\n",
      "           5.6300e-02, 2.1653e-01, 8.9501e-02],\n",
      "          [2.2735e-03, 1.3380e-03, 5.5319e-02, 4.1877e-01, 8.0788e-02,\n",
      "           7.0452e-02, 3.6885e-01, 2.2139e-03],\n",
      "          [1.3129e-03, 5.7109e-04, 4.5945e-02, 8.4918e-01, 3.2164e-02,\n",
      "           1.8211e-02, 5.1235e-02, 1.3813e-03],\n",
      "          [1.2883e-01, 6.2459e-02, 1.5678e-01, 3.2735e-01, 1.0482e-01,\n",
      "           2.4133e-02, 6.3885e-02, 1.3175e-01],\n",
      "          [2.9842e-01, 3.8031e-01, 6.5970e-03, 2.6692e-03, 8.8935e-04,\n",
      "           3.4799e-04, 6.7777e-04, 3.1009e-01],\n",
      "          [2.9393e-01, 3.6996e-01, 6.8506e-03, 2.4541e-03, 1.7781e-03,\n",
      "           1.9559e-03, 3.3847e-03, 3.1969e-01],\n",
      "          [2.6842e-01, 3.2377e-01, 4.2803e-02, 1.5874e-02, 1.0582e-02,\n",
      "           3.8199e-02, 9.2020e-03, 2.9114e-01]],\n",
      "\n",
      "         [[1.8224e-01, 1.3337e-01, 1.5220e-01, 3.9167e-02, 9.0343e-02,\n",
      "           6.4927e-02, 1.6589e-01, 1.7188e-01],\n",
      "          [2.4327e-02, 7.9471e-03, 1.1328e-01, 1.6921e-01, 1.5633e-01,\n",
      "           2.0835e-01, 2.9695e-01, 2.3605e-02],\n",
      "          [6.8597e-03, 5.7902e-03, 1.6078e-01, 3.3996e-01, 2.4150e-01,\n",
      "           9.2997e-02, 1.4498e-01, 7.1345e-03],\n",
      "          [1.6629e-02, 1.3361e-02, 1.5583e-01, 5.6956e-01, 9.8352e-02,\n",
      "           5.7995e-02, 7.0956e-02, 1.7314e-02],\n",
      "          [1.4306e-01, 5.4599e-01, 9.8338e-02, 2.3882e-02, 1.0093e-02,\n",
      "           1.3055e-02, 1.2191e-02, 1.5339e-01],\n",
      "          [2.2756e-01, 4.5846e-01, 3.0955e-02, 1.3794e-02, 7.8202e-03,\n",
      "           1.0267e-02, 9.2755e-03, 2.4187e-01],\n",
      "          [1.8329e-01, 6.0129e-01, 1.3796e-02, 1.6276e-03, 7.2870e-03,\n",
      "           3.5848e-03, 3.5226e-03, 1.8560e-01]],\n",
      "\n",
      "         [[1.4307e-01, 1.2381e-01, 1.8225e-01, 6.0313e-02, 1.0855e-01,\n",
      "           1.0353e-01, 1.4207e-01, 1.3641e-01],\n",
      "          [6.1674e-03, 6.2483e-03, 9.6974e-02, 3.0091e-01, 1.4462e-01,\n",
      "           2.2025e-01, 2.1863e-01, 6.2027e-03],\n",
      "          [3.6362e-03, 4.9105e-03, 1.0370e-01, 3.8515e-01, 1.9101e-01,\n",
      "           1.1090e-01, 1.9698e-01, 3.7075e-03],\n",
      "          [1.1283e-01, 9.1424e-02, 1.6952e-01, 1.1797e-01, 1.9653e-01,\n",
      "           6.8236e-02, 1.3095e-01, 1.1255e-01],\n",
      "          [2.1764e-01, 5.2619e-01, 1.5425e-02, 6.6703e-03, 4.4581e-03,\n",
      "           5.2528e-03, 7.2990e-03, 2.1706e-01],\n",
      "          [2.0158e-01, 5.6386e-01, 6.5561e-03, 3.3095e-03, 3.3723e-03,\n",
      "           5.4991e-03, 2.1671e-03, 2.1365e-01],\n",
      "          [3.1256e-01, 3.2547e-01, 1.5311e-02, 3.2308e-03, 5.6520e-03,\n",
      "           1.1633e-02, 2.9730e-03, 3.2317e-01]],\n",
      "\n",
      "         [[3.2358e-02, 4.7515e-02, 2.2199e-01, 1.0669e-01, 1.8258e-01,\n",
      "           8.2013e-02, 2.9499e-01, 3.1870e-02],\n",
      "          [7.8119e-02, 6.2411e-02, 1.6239e-01, 1.7023e-01, 2.8311e-01,\n",
      "           9.8709e-02, 6.5092e-02, 7.9932e-02],\n",
      "          [8.8919e-03, 4.8062e-03, 7.2250e-02, 3.7360e-01, 4.5085e-01,\n",
      "           5.6435e-02, 2.3503e-02, 9.6649e-03],\n",
      "          [3.5152e-02, 2.4630e-02, 1.5207e-01, 4.0419e-01, 2.0576e-01,\n",
      "           7.8335e-02, 6.2017e-02, 3.7847e-02],\n",
      "          [2.5079e-01, 4.4980e-01, 1.3253e-02, 6.6651e-03, 5.9986e-03,\n",
      "           3.6548e-03, 3.8146e-03, 2.6602e-01],\n",
      "          [2.0661e-01, 5.7065e-01, 5.1815e-03, 1.5484e-03, 2.5201e-03,\n",
      "           1.0229e-03, 1.0770e-03, 2.1139e-01],\n",
      "          [2.5044e-01, 4.4967e-01, 1.0937e-02, 2.0090e-03, 1.1023e-02,\n",
      "           5.0977e-03, 1.9640e-03, 2.6887e-01]],\n",
      "\n",
      "         [[3.1025e-02, 3.7944e-02, 1.6277e-01, 5.3668e-02, 2.2394e-01,\n",
      "           1.6504e-01, 2.9484e-01, 3.0779e-02],\n",
      "          [2.2778e-02, 1.7222e-02, 6.9377e-02, 5.2954e-02, 2.4066e-01,\n",
      "           3.5681e-01, 2.1767e-01, 2.2532e-02],\n",
      "          [1.0302e-02, 9.4600e-03, 1.1837e-01, 1.9120e-01, 3.9302e-01,\n",
      "           1.8360e-01, 8.3429e-02, 1.0631e-02],\n",
      "          [1.0883e-01, 8.8603e-02, 1.7749e-01, 1.7370e-01, 1.5306e-01,\n",
      "           1.1626e-01, 6.6374e-02, 1.1567e-01],\n",
      "          [3.0025e-01, 3.6333e-01, 1.2522e-02, 5.3565e-03, 2.7944e-03,\n",
      "           1.4495e-03, 2.7593e-03, 3.1154e-01],\n",
      "          [2.8017e-01, 4.1404e-01, 7.1818e-03, 2.9017e-03, 2.2469e-03,\n",
      "           1.4020e-03, 2.4073e-03, 2.8966e-01],\n",
      "          [2.6131e-01, 3.6739e-01, 3.0474e-02, 8.6945e-03, 3.8792e-02,\n",
      "           1.0954e-02, 1.5771e-02, 2.6661e-01]]]]), tensor([[[[1.8088e-01, 2.8039e-01, 1.9378e-01, 3.0785e-02, 4.5251e-02,\n",
      "           5.0464e-02, 3.3565e-02, 1.8489e-01],\n",
      "          [7.5304e-03, 1.2202e-02, 1.0847e-01, 2.8553e-01, 1.2199e-01,\n",
      "           2.1229e-01, 2.4467e-01, 7.3144e-03],\n",
      "          [4.0077e-03, 3.8319e-03, 1.2366e-01, 4.3989e-01, 1.9551e-01,\n",
      "           5.4361e-02, 1.7468e-01, 4.0617e-03],\n",
      "          [3.3900e-02, 2.5823e-02, 1.9126e-01, 3.5174e-01, 1.8483e-01,\n",
      "           6.6141e-02, 1.1116e-01, 3.5142e-02],\n",
      "          [3.1719e-01, 3.3381e-01, 1.2389e-02, 3.2286e-03, 2.4507e-03,\n",
      "           1.9257e-03, 3.0085e-03, 3.2599e-01],\n",
      "          [3.3881e-01, 2.8472e-01, 6.8819e-03, 1.6569e-03, 1.5887e-03,\n",
      "           2.3873e-03, 9.6115e-04, 3.6299e-01],\n",
      "          [3.3588e-01, 2.6570e-01, 1.6715e-02, 5.7133e-03, 8.8207e-03,\n",
      "           2.0787e-02, 5.8224e-03, 3.4056e-01],\n",
      "          [3.6154e-01, 1.4705e-01, 2.6193e-02, 1.3552e-02, 4.5739e-02,\n",
      "           2.2739e-02, 1.9942e-02, 3.6324e-01]],\n",
      "\n",
      "         [[3.4970e-02, 7.0678e-02, 1.6080e-01, 8.1224e-02, 1.9261e-01,\n",
      "           1.5945e-01, 2.6527e-01, 3.5008e-02],\n",
      "          [7.2603e-03, 5.0477e-03, 1.3985e-01, 4.0217e-01, 1.7541e-01,\n",
      "           9.2739e-02, 1.7028e-01, 7.2425e-03],\n",
      "          [9.7523e-03, 7.3225e-03, 2.1378e-01, 5.0259e-01, 1.1437e-01,\n",
      "           4.9757e-02, 9.2361e-02, 1.0067e-02],\n",
      "          [2.8251e-02, 3.6802e-02, 2.0533e-01, 3.8092e-01, 1.6616e-01,\n",
      "           4.6863e-02, 1.0710e-01, 2.8570e-02],\n",
      "          [2.3320e-01, 4.8366e-01, 2.6468e-02, 5.2339e-03, 6.2638e-03,\n",
      "           5.7362e-03, 5.8041e-03, 2.3364e-01],\n",
      "          [2.7920e-01, 4.2622e-01, 2.2668e-03, 7.4153e-04, 5.6009e-04,\n",
      "           1.5650e-03, 9.0140e-04, 2.8854e-01],\n",
      "          [2.2666e-01, 3.1859e-01, 4.1618e-02, 3.9897e-02, 4.9346e-02,\n",
      "           6.6939e-02, 2.5033e-02, 2.3192e-01],\n",
      "          [3.1552e-01, 2.1246e-01, 3.9184e-02, 1.4620e-02, 5.8632e-02,\n",
      "           2.3637e-02, 1.4178e-02, 3.2177e-01]],\n",
      "\n",
      "         [[9.1086e-02, 5.9748e-02, 1.5627e-01, 7.8903e-02, 1.4400e-01,\n",
      "           1.2623e-01, 2.5652e-01, 8.7252e-02],\n",
      "          [4.7961e-03, 3.3490e-03, 6.9669e-02, 3.2010e-01, 2.6297e-01,\n",
      "           1.8468e-01, 1.4956e-01, 4.8790e-03],\n",
      "          [1.2246e-03, 5.0496e-04, 5.7768e-02, 6.5043e-01, 1.5751e-01,\n",
      "           7.6719e-02, 5.4536e-02, 1.3113e-03],\n",
      "          [1.2996e-01, 7.3096e-02, 2.0284e-01, 1.9800e-01, 1.1690e-01,\n",
      "           9.9548e-02, 4.2558e-02, 1.3710e-01],\n",
      "          [2.3285e-01, 4.8692e-01, 2.0276e-02, 4.2422e-03, 2.7398e-03,\n",
      "           5.4333e-03, 1.5220e-03, 2.4602e-01],\n",
      "          [3.2079e-01, 3.2769e-01, 4.4881e-03, 1.1691e-03, 1.0446e-03,\n",
      "           1.0744e-03, 6.9654e-04, 3.4305e-01],\n",
      "          [3.1611e-01, 2.5945e-01, 2.5582e-02, 9.2508e-03, 1.7874e-02,\n",
      "           3.2535e-02, 7.7488e-03, 3.3145e-01],\n",
      "          [3.6181e-01, 1.8240e-01, 1.9111e-02, 5.6761e-03, 1.9551e-02,\n",
      "           1.6486e-02, 2.5952e-03, 3.9238e-01]],\n",
      "\n",
      "         [[9.3382e-02, 8.9572e-02, 2.1734e-01, 8.9489e-02, 1.4789e-01,\n",
      "           5.6300e-02, 2.1653e-01, 8.9501e-02],\n",
      "          [2.2735e-03, 1.3380e-03, 5.5319e-02, 4.1877e-01, 8.0788e-02,\n",
      "           7.0452e-02, 3.6885e-01, 2.2139e-03],\n",
      "          [1.3129e-03, 5.7109e-04, 4.5945e-02, 8.4918e-01, 3.2164e-02,\n",
      "           1.8211e-02, 5.1235e-02, 1.3813e-03],\n",
      "          [1.2883e-01, 6.2459e-02, 1.5678e-01, 3.2735e-01, 1.0482e-01,\n",
      "           2.4133e-02, 6.3885e-02, 1.3175e-01],\n",
      "          [2.9842e-01, 3.8031e-01, 6.5970e-03, 2.6692e-03, 8.8935e-04,\n",
      "           3.4799e-04, 6.7777e-04, 3.1009e-01],\n",
      "          [2.9393e-01, 3.6996e-01, 6.8506e-03, 2.4541e-03, 1.7781e-03,\n",
      "           1.9559e-03, 3.3847e-03, 3.1969e-01],\n",
      "          [2.6842e-01, 3.2377e-01, 4.2803e-02, 1.5874e-02, 1.0582e-02,\n",
      "           3.8199e-02, 9.2020e-03, 2.9114e-01],\n",
      "          [3.2928e-01, 2.3770e-01, 1.7026e-02, 2.9628e-03, 1.1480e-02,\n",
      "           3.6898e-02, 2.6151e-03, 3.6203e-01]],\n",
      "\n",
      "         [[1.8224e-01, 1.3337e-01, 1.5220e-01, 3.9167e-02, 9.0343e-02,\n",
      "           6.4927e-02, 1.6589e-01, 1.7188e-01],\n",
      "          [2.4327e-02, 7.9471e-03, 1.1328e-01, 1.6921e-01, 1.5633e-01,\n",
      "           2.0835e-01, 2.9695e-01, 2.3605e-02],\n",
      "          [6.8597e-03, 5.7902e-03, 1.6078e-01, 3.3996e-01, 2.4150e-01,\n",
      "           9.2997e-02, 1.4498e-01, 7.1345e-03],\n",
      "          [1.6629e-02, 1.3361e-02, 1.5583e-01, 5.6956e-01, 9.8352e-02,\n",
      "           5.7995e-02, 7.0956e-02, 1.7314e-02],\n",
      "          [1.4306e-01, 5.4599e-01, 9.8338e-02, 2.3882e-02, 1.0093e-02,\n",
      "           1.3055e-02, 1.2191e-02, 1.5339e-01],\n",
      "          [2.2756e-01, 4.5846e-01, 3.0955e-02, 1.3794e-02, 7.8202e-03,\n",
      "           1.0267e-02, 9.2755e-03, 2.4187e-01],\n",
      "          [1.8329e-01, 6.0129e-01, 1.3796e-02, 1.6276e-03, 7.2870e-03,\n",
      "           3.5848e-03, 3.5226e-03, 1.8560e-01],\n",
      "          [2.4669e-01, 3.4334e-01, 5.9231e-02, 2.3195e-02, 4.1030e-02,\n",
      "           1.6930e-02, 1.8365e-02, 2.5122e-01]],\n",
      "\n",
      "         [[1.4307e-01, 1.2381e-01, 1.8225e-01, 6.0313e-02, 1.0855e-01,\n",
      "           1.0353e-01, 1.4207e-01, 1.3641e-01],\n",
      "          [6.1674e-03, 6.2483e-03, 9.6974e-02, 3.0091e-01, 1.4462e-01,\n",
      "           2.2025e-01, 2.1863e-01, 6.2027e-03],\n",
      "          [3.6362e-03, 4.9105e-03, 1.0370e-01, 3.8515e-01, 1.9101e-01,\n",
      "           1.1090e-01, 1.9698e-01, 3.7075e-03],\n",
      "          [1.1283e-01, 9.1424e-02, 1.6952e-01, 1.1797e-01, 1.9653e-01,\n",
      "           6.8236e-02, 1.3095e-01, 1.1255e-01],\n",
      "          [2.1764e-01, 5.2619e-01, 1.5425e-02, 6.6703e-03, 4.4581e-03,\n",
      "           5.2528e-03, 7.2990e-03, 2.1706e-01],\n",
      "          [2.0158e-01, 5.6386e-01, 6.5561e-03, 3.3095e-03, 3.3723e-03,\n",
      "           5.4991e-03, 2.1671e-03, 2.1365e-01],\n",
      "          [3.1256e-01, 3.2547e-01, 1.5311e-02, 3.2308e-03, 5.6520e-03,\n",
      "           1.1633e-02, 2.9730e-03, 3.2317e-01],\n",
      "          [3.4622e-01, 2.6875e-01, 1.0161e-02, 1.4832e-03, 1.0456e-02,\n",
      "           9.6917e-03, 2.8803e-03, 3.5035e-01]],\n",
      "\n",
      "         [[3.2358e-02, 4.7515e-02, 2.2199e-01, 1.0669e-01, 1.8258e-01,\n",
      "           8.2013e-02, 2.9499e-01, 3.1870e-02],\n",
      "          [7.8119e-02, 6.2411e-02, 1.6239e-01, 1.7023e-01, 2.8311e-01,\n",
      "           9.8709e-02, 6.5092e-02, 7.9932e-02],\n",
      "          [8.8919e-03, 4.8062e-03, 7.2250e-02, 3.7360e-01, 4.5085e-01,\n",
      "           5.6435e-02, 2.3503e-02, 9.6649e-03],\n",
      "          [3.5152e-02, 2.4630e-02, 1.5207e-01, 4.0419e-01, 2.0576e-01,\n",
      "           7.8335e-02, 6.2017e-02, 3.7847e-02],\n",
      "          [2.5079e-01, 4.4980e-01, 1.3253e-02, 6.6651e-03, 5.9986e-03,\n",
      "           3.6548e-03, 3.8146e-03, 2.6602e-01],\n",
      "          [2.0661e-01, 5.7065e-01, 5.1815e-03, 1.5484e-03, 2.5201e-03,\n",
      "           1.0229e-03, 1.0770e-03, 2.1139e-01],\n",
      "          [2.5044e-01, 4.4967e-01, 1.0937e-02, 2.0090e-03, 1.1023e-02,\n",
      "           5.0977e-03, 1.9640e-03, 2.6887e-01],\n",
      "          [3.2297e-01, 1.9068e-01, 2.6560e-02, 2.3679e-02, 4.8405e-02,\n",
      "           1.9387e-02, 4.8099e-03, 3.6351e-01]],\n",
      "\n",
      "         [[3.1025e-02, 3.7944e-02, 1.6277e-01, 5.3668e-02, 2.2394e-01,\n",
      "           1.6504e-01, 2.9484e-01, 3.0779e-02],\n",
      "          [2.2778e-02, 1.7222e-02, 6.9377e-02, 5.2954e-02, 2.4066e-01,\n",
      "           3.5681e-01, 2.1767e-01, 2.2532e-02],\n",
      "          [1.0302e-02, 9.4600e-03, 1.1837e-01, 1.9120e-01, 3.9302e-01,\n",
      "           1.8360e-01, 8.3429e-02, 1.0631e-02],\n",
      "          [1.0883e-01, 8.8603e-02, 1.7749e-01, 1.7370e-01, 1.5306e-01,\n",
      "           1.1626e-01, 6.6374e-02, 1.1567e-01],\n",
      "          [3.0025e-01, 3.6333e-01, 1.2522e-02, 5.3565e-03, 2.7944e-03,\n",
      "           1.4495e-03, 2.7593e-03, 3.1154e-01],\n",
      "          [2.8017e-01, 4.1404e-01, 7.1818e-03, 2.9017e-03, 2.2469e-03,\n",
      "           1.4020e-03, 2.4073e-03, 2.8966e-01],\n",
      "          [2.6131e-01, 3.6739e-01, 3.0474e-02, 8.6945e-03, 3.8792e-02,\n",
      "           1.0954e-02, 1.5771e-02, 2.6661e-01],\n",
      "          [1.2672e-01, 1.6550e-01, 1.1642e-01, 8.3881e-02, 2.0957e-01,\n",
      "           1.1598e-01, 5.1068e-02, 1.3087e-01]]]]), tensor([[[[1.8088e-01, 2.8039e-01, 1.9378e-01, 3.0785e-02, 4.5251e-02,\n",
      "           5.0464e-02, 3.3565e-02, 1.8489e-01],\n",
      "          [7.5304e-03, 1.2202e-02, 1.0847e-01, 2.8553e-01, 1.2199e-01,\n",
      "           2.1229e-01, 2.4467e-01, 7.3144e-03],\n",
      "          [4.0077e-03, 3.8319e-03, 1.2366e-01, 4.3989e-01, 1.9551e-01,\n",
      "           5.4361e-02, 1.7468e-01, 4.0617e-03],\n",
      "          [3.3900e-02, 2.5823e-02, 1.9126e-01, 3.5174e-01, 1.8483e-01,\n",
      "           6.6141e-02, 1.1116e-01, 3.5142e-02],\n",
      "          [3.1719e-01, 3.3381e-01, 1.2389e-02, 3.2286e-03, 2.4507e-03,\n",
      "           1.9257e-03, 3.0085e-03, 3.2599e-01],\n",
      "          [3.3881e-01, 2.8472e-01, 6.8819e-03, 1.6569e-03, 1.5887e-03,\n",
      "           2.3873e-03, 9.6115e-04, 3.6299e-01],\n",
      "          [3.3588e-01, 2.6570e-01, 1.6715e-02, 5.7133e-03, 8.8207e-03,\n",
      "           2.0787e-02, 5.8224e-03, 3.4056e-01],\n",
      "          [3.6154e-01, 1.4705e-01, 2.6193e-02, 1.3552e-02, 4.5739e-02,\n",
      "           2.2739e-02, 1.9942e-02, 3.6324e-01],\n",
      "          [3.0318e-01, 2.0651e-01, 4.0947e-02, 2.8648e-02, 6.7562e-02,\n",
      "           1.5686e-02, 3.0499e-02, 3.0696e-01]],\n",
      "\n",
      "         [[3.4970e-02, 7.0678e-02, 1.6080e-01, 8.1224e-02, 1.9261e-01,\n",
      "           1.5945e-01, 2.6527e-01, 3.5008e-02],\n",
      "          [7.2603e-03, 5.0477e-03, 1.3985e-01, 4.0217e-01, 1.7541e-01,\n",
      "           9.2739e-02, 1.7028e-01, 7.2425e-03],\n",
      "          [9.7523e-03, 7.3225e-03, 2.1378e-01, 5.0259e-01, 1.1437e-01,\n",
      "           4.9757e-02, 9.2361e-02, 1.0067e-02],\n",
      "          [2.8251e-02, 3.6802e-02, 2.0533e-01, 3.8092e-01, 1.6616e-01,\n",
      "           4.6863e-02, 1.0710e-01, 2.8570e-02],\n",
      "          [2.3320e-01, 4.8366e-01, 2.6468e-02, 5.2339e-03, 6.2638e-03,\n",
      "           5.7362e-03, 5.8041e-03, 2.3364e-01],\n",
      "          [2.7920e-01, 4.2622e-01, 2.2668e-03, 7.4153e-04, 5.6009e-04,\n",
      "           1.5650e-03, 9.0140e-04, 2.8854e-01],\n",
      "          [2.2666e-01, 3.1859e-01, 4.1618e-02, 3.9897e-02, 4.9346e-02,\n",
      "           6.6939e-02, 2.5033e-02, 2.3192e-01],\n",
      "          [3.1552e-01, 2.1246e-01, 3.9184e-02, 1.4620e-02, 5.8632e-02,\n",
      "           2.3637e-02, 1.4178e-02, 3.2177e-01],\n",
      "          [3.6646e-01, 2.4778e-01, 3.7329e-03, 1.6858e-03, 7.4173e-03,\n",
      "           6.1691e-03, 3.6489e-03, 3.6310e-01]],\n",
      "\n",
      "         [[9.1086e-02, 5.9748e-02, 1.5627e-01, 7.8903e-02, 1.4400e-01,\n",
      "           1.2623e-01, 2.5652e-01, 8.7252e-02],\n",
      "          [4.7961e-03, 3.3490e-03, 6.9669e-02, 3.2010e-01, 2.6297e-01,\n",
      "           1.8468e-01, 1.4956e-01, 4.8790e-03],\n",
      "          [1.2246e-03, 5.0496e-04, 5.7768e-02, 6.5043e-01, 1.5751e-01,\n",
      "           7.6719e-02, 5.4536e-02, 1.3113e-03],\n",
      "          [1.2996e-01, 7.3096e-02, 2.0284e-01, 1.9800e-01, 1.1690e-01,\n",
      "           9.9548e-02, 4.2558e-02, 1.3710e-01],\n",
      "          [2.3285e-01, 4.8692e-01, 2.0276e-02, 4.2422e-03, 2.7398e-03,\n",
      "           5.4333e-03, 1.5220e-03, 2.4602e-01],\n",
      "          [3.2079e-01, 3.2769e-01, 4.4881e-03, 1.1691e-03, 1.0446e-03,\n",
      "           1.0744e-03, 6.9654e-04, 3.4305e-01],\n",
      "          [3.1611e-01, 2.5945e-01, 2.5582e-02, 9.2508e-03, 1.7874e-02,\n",
      "           3.2535e-02, 7.7488e-03, 3.3145e-01],\n",
      "          [3.6181e-01, 1.8240e-01, 1.9111e-02, 5.6761e-03, 1.9551e-02,\n",
      "           1.6486e-02, 2.5952e-03, 3.9238e-01],\n",
      "          [3.2749e-01, 9.8525e-02, 5.4292e-02, 6.2885e-02, 5.2239e-02,\n",
      "           3.3490e-02, 3.5282e-02, 3.3580e-01]],\n",
      "\n",
      "         [[9.3382e-02, 8.9572e-02, 2.1734e-01, 8.9489e-02, 1.4789e-01,\n",
      "           5.6300e-02, 2.1653e-01, 8.9501e-02],\n",
      "          [2.2735e-03, 1.3380e-03, 5.5319e-02, 4.1877e-01, 8.0788e-02,\n",
      "           7.0452e-02, 3.6885e-01, 2.2139e-03],\n",
      "          [1.3129e-03, 5.7109e-04, 4.5945e-02, 8.4918e-01, 3.2164e-02,\n",
      "           1.8211e-02, 5.1235e-02, 1.3813e-03],\n",
      "          [1.2883e-01, 6.2459e-02, 1.5678e-01, 3.2735e-01, 1.0482e-01,\n",
      "           2.4133e-02, 6.3885e-02, 1.3175e-01],\n",
      "          [2.9842e-01, 3.8031e-01, 6.5970e-03, 2.6692e-03, 8.8935e-04,\n",
      "           3.4799e-04, 6.7777e-04, 3.1009e-01],\n",
      "          [2.9393e-01, 3.6996e-01, 6.8506e-03, 2.4541e-03, 1.7781e-03,\n",
      "           1.9559e-03, 3.3847e-03, 3.1969e-01],\n",
      "          [2.6842e-01, 3.2377e-01, 4.2803e-02, 1.5874e-02, 1.0582e-02,\n",
      "           3.8199e-02, 9.2020e-03, 2.9114e-01],\n",
      "          [3.2928e-01, 2.3770e-01, 1.7026e-02, 2.9628e-03, 1.1480e-02,\n",
      "           3.6898e-02, 2.6151e-03, 3.6203e-01],\n",
      "          [2.4862e-01, 2.3735e-01, 5.7891e-02, 1.1623e-01, 3.6856e-02,\n",
      "           2.1417e-02, 1.5669e-02, 2.6597e-01]],\n",
      "\n",
      "         [[1.8224e-01, 1.3337e-01, 1.5220e-01, 3.9167e-02, 9.0343e-02,\n",
      "           6.4927e-02, 1.6589e-01, 1.7188e-01],\n",
      "          [2.4327e-02, 7.9471e-03, 1.1328e-01, 1.6921e-01, 1.5633e-01,\n",
      "           2.0835e-01, 2.9695e-01, 2.3605e-02],\n",
      "          [6.8597e-03, 5.7902e-03, 1.6078e-01, 3.3996e-01, 2.4150e-01,\n",
      "           9.2997e-02, 1.4498e-01, 7.1345e-03],\n",
      "          [1.6629e-02, 1.3361e-02, 1.5583e-01, 5.6956e-01, 9.8352e-02,\n",
      "           5.7995e-02, 7.0956e-02, 1.7314e-02],\n",
      "          [1.4306e-01, 5.4599e-01, 9.8338e-02, 2.3882e-02, 1.0093e-02,\n",
      "           1.3055e-02, 1.2191e-02, 1.5339e-01],\n",
      "          [2.2756e-01, 4.5846e-01, 3.0955e-02, 1.3794e-02, 7.8202e-03,\n",
      "           1.0267e-02, 9.2755e-03, 2.4187e-01],\n",
      "          [1.8329e-01, 6.0129e-01, 1.3796e-02, 1.6276e-03, 7.2870e-03,\n",
      "           3.5848e-03, 3.5226e-03, 1.8560e-01],\n",
      "          [2.4669e-01, 3.4334e-01, 5.9231e-02, 2.3195e-02, 4.1030e-02,\n",
      "           1.6930e-02, 1.8365e-02, 2.5122e-01],\n",
      "          [2.0917e-01, 1.1754e-01, 1.4295e-01, 5.3780e-02, 1.3896e-01,\n",
      "           5.3471e-02, 7.5645e-02, 2.0848e-01]],\n",
      "\n",
      "         [[1.4307e-01, 1.2381e-01, 1.8225e-01, 6.0313e-02, 1.0855e-01,\n",
      "           1.0353e-01, 1.4207e-01, 1.3641e-01],\n",
      "          [6.1674e-03, 6.2483e-03, 9.6974e-02, 3.0091e-01, 1.4462e-01,\n",
      "           2.2025e-01, 2.1863e-01, 6.2027e-03],\n",
      "          [3.6362e-03, 4.9105e-03, 1.0370e-01, 3.8515e-01, 1.9100e-01,\n",
      "           1.1090e-01, 1.9698e-01, 3.7075e-03],\n",
      "          [1.1283e-01, 9.1424e-02, 1.6952e-01, 1.1797e-01, 1.9653e-01,\n",
      "           6.8236e-02, 1.3095e-01, 1.1255e-01],\n",
      "          [2.1764e-01, 5.2619e-01, 1.5425e-02, 6.6703e-03, 4.4581e-03,\n",
      "           5.2528e-03, 7.2990e-03, 2.1706e-01],\n",
      "          [2.0158e-01, 5.6386e-01, 6.5561e-03, 3.3095e-03, 3.3723e-03,\n",
      "           5.4991e-03, 2.1671e-03, 2.1365e-01],\n",
      "          [3.1256e-01, 3.2547e-01, 1.5311e-02, 3.2308e-03, 5.6520e-03,\n",
      "           1.1633e-02, 2.9730e-03, 3.2317e-01],\n",
      "          [3.4622e-01, 2.6875e-01, 1.0161e-02, 1.4832e-03, 1.0456e-02,\n",
      "           9.6917e-03, 2.8803e-03, 3.5035e-01],\n",
      "          [2.2513e-01, 1.0586e-01, 8.7546e-02, 1.1912e-01, 8.1550e-02,\n",
      "           6.4449e-02, 9.4959e-02, 2.2139e-01]],\n",
      "\n",
      "         [[3.2358e-02, 4.7515e-02, 2.2199e-01, 1.0669e-01, 1.8258e-01,\n",
      "           8.2013e-02, 2.9499e-01, 3.1870e-02],\n",
      "          [7.8119e-02, 6.2411e-02, 1.6239e-01, 1.7023e-01, 2.8311e-01,\n",
      "           9.8709e-02, 6.5092e-02, 7.9932e-02],\n",
      "          [8.8919e-03, 4.8062e-03, 7.2250e-02, 3.7359e-01, 4.5085e-01,\n",
      "           5.6435e-02, 2.3503e-02, 9.6649e-03],\n",
      "          [3.5152e-02, 2.4630e-02, 1.5207e-01, 4.0419e-01, 2.0576e-01,\n",
      "           7.8335e-02, 6.2017e-02, 3.7847e-02],\n",
      "          [2.5079e-01, 4.4980e-01, 1.3253e-02, 6.6651e-03, 5.9986e-03,\n",
      "           3.6548e-03, 3.8146e-03, 2.6602e-01],\n",
      "          [2.0661e-01, 5.7065e-01, 5.1815e-03, 1.5484e-03, 2.5201e-03,\n",
      "           1.0229e-03, 1.0770e-03, 2.1139e-01],\n",
      "          [2.5044e-01, 4.4967e-01, 1.0937e-02, 2.0090e-03, 1.1023e-02,\n",
      "           5.0977e-03, 1.9640e-03, 2.6887e-01],\n",
      "          [3.2297e-01, 1.9068e-01, 2.6560e-02, 2.3679e-02, 4.8405e-02,\n",
      "           1.9387e-02, 4.8099e-03, 3.6351e-01],\n",
      "          [2.1158e-01, 3.1406e-01, 5.2893e-02, 4.0028e-02, 1.0282e-01,\n",
      "           3.8754e-02, 2.2368e-02, 2.1750e-01]],\n",
      "\n",
      "         [[3.1025e-02, 3.7944e-02, 1.6277e-01, 5.3668e-02, 2.2394e-01,\n",
      "           1.6504e-01, 2.9484e-01, 3.0779e-02],\n",
      "          [2.2778e-02, 1.7222e-02, 6.9377e-02, 5.2954e-02, 2.4066e-01,\n",
      "           3.5681e-01, 2.1767e-01, 2.2532e-02],\n",
      "          [1.0302e-02, 9.4600e-03, 1.1837e-01, 1.9120e-01, 3.9302e-01,\n",
      "           1.8360e-01, 8.3429e-02, 1.0631e-02],\n",
      "          [1.0883e-01, 8.8603e-02, 1.7749e-01, 1.7370e-01, 1.5306e-01,\n",
      "           1.1626e-01, 6.6374e-02, 1.1567e-01],\n",
      "          [3.0025e-01, 3.6333e-01, 1.2522e-02, 5.3565e-03, 2.7944e-03,\n",
      "           1.4495e-03, 2.7593e-03, 3.1154e-01],\n",
      "          [2.8017e-01, 4.1404e-01, 7.1818e-03, 2.9017e-03, 2.2469e-03,\n",
      "           1.4020e-03, 2.4073e-03, 2.8966e-01],\n",
      "          [2.6131e-01, 3.6739e-01, 3.0474e-02, 8.6945e-03, 3.8792e-02,\n",
      "           1.0954e-02, 1.5771e-02, 2.6661e-01],\n",
      "          [1.2672e-01, 1.6550e-01, 1.1642e-01, 8.3881e-02, 2.0957e-01,\n",
      "           1.1598e-01, 5.1068e-02, 1.3087e-01],\n",
      "          [2.4612e-01, 2.4689e-01, 6.4749e-02, 3.7108e-02, 8.7008e-02,\n",
      "           2.3225e-02, 4.7364e-02, 2.4753e-01]]]])]), (['<sos>', 'can', 'i', 'get', 'off', 'at', 'the', 'seouryeoksabangmulgwan', '?', '<eos>'], [tensor([[[[3.1463e-03, 4.8807e-03, 2.8232e-03, 1.9911e-03, 6.3559e-02,\n",
      "           2.8466e-02, 2.5192e-01, 3.6398e-01, 1.2386e-01, 1.5234e-01,\n",
      "           3.0337e-03]],\n",
      "\n",
      "         [[2.2069e-02, 3.4022e-02, 1.1153e-02, 1.0452e-02, 7.9929e-02,\n",
      "           1.4591e-02, 2.2788e-01, 2.8653e-01, 1.8589e-01, 1.0547e-01,\n",
      "           2.2008e-02]],\n",
      "\n",
      "         [[1.6908e-03, 1.4467e-03, 6.9412e-04, 1.5117e-03, 1.9361e-02,\n",
      "           9.4148e-03, 1.4902e-01, 2.9468e-01, 2.6430e-01, 2.5609e-01,\n",
      "           1.7935e-03]],\n",
      "\n",
      "         [[1.0087e-03, 1.0757e-03, 2.8140e-04, 6.5788e-04, 5.8029e-02,\n",
      "           4.1349e-02, 3.6735e-01, 3.1825e-01, 1.2605e-01, 8.4957e-02,\n",
      "           9.9056e-04]],\n",
      "\n",
      "         [[4.5568e-03, 3.0560e-03, 1.9296e-03, 1.4549e-03, 5.0402e-02,\n",
      "           1.7042e-02, 1.5789e-01, 4.3275e-01, 1.6861e-01, 1.5809e-01,\n",
      "           4.2139e-03]],\n",
      "\n",
      "         [[1.3674e-03, 7.5639e-04, 7.1730e-04, 7.4899e-04, 1.3694e-02,\n",
      "           1.4394e-02, 1.0560e-01, 2.7270e-01, 1.7882e-01, 4.0958e-01,\n",
      "           1.6248e-03]],\n",
      "\n",
      "         [[6.1914e-04, 5.1572e-04, 1.0208e-04, 3.6718e-04, 4.2726e-02,\n",
      "           1.7168e-02, 3.4199e-01, 3.7539e-01, 1.4622e-01, 7.4273e-02,\n",
      "           6.3357e-04]],\n",
      "\n",
      "         [[8.7465e-04, 5.5213e-04, 5.3893e-04, 8.7702e-04, 1.4588e-01,\n",
      "           9.7495e-02, 2.3745e-01, 2.2946e-01, 1.9801e-01, 8.8074e-02,\n",
      "           7.8902e-04]]]]), tensor([[[[3.1463e-03, 4.8807e-03, 2.8232e-03, 1.9911e-03, 6.3559e-02,\n",
      "           2.8466e-02, 2.5192e-01, 3.6398e-01, 1.2386e-01, 1.5234e-01,\n",
      "           3.0337e-03],\n",
      "          [8.2186e-04, 1.5400e-03, 1.0818e-03, 4.8190e-04, 2.0015e-02,\n",
      "           2.5287e-03, 3.3684e-01, 3.3960e-01, 1.7474e-01, 1.2155e-01,\n",
      "           8.0376e-04]],\n",
      "\n",
      "         [[2.2069e-02, 3.4022e-02, 1.1153e-02, 1.0452e-02, 7.9929e-02,\n",
      "           1.4591e-02, 2.2788e-01, 2.8653e-01, 1.8589e-01, 1.0547e-01,\n",
      "           2.2008e-02],\n",
      "          [1.1993e-01, 4.0426e-02, 2.6992e-01, 9.1956e-02, 1.7506e-01,\n",
      "           2.6440e-02, 8.5125e-02, 2.1970e-02, 2.5174e-02, 2.5401e-02,\n",
      "           1.1860e-01]],\n",
      "\n",
      "         [[1.6908e-03, 1.4467e-03, 6.9412e-04, 1.5117e-03, 1.9361e-02,\n",
      "           9.4148e-03, 1.4902e-01, 2.9468e-01, 2.6430e-01, 2.5609e-01,\n",
      "           1.7935e-03],\n",
      "          [6.5195e-03, 1.3313e-03, 5.5494e-03, 2.5668e-03, 1.5586e-01,\n",
      "           6.4921e-02, 4.8035e-01, 8.8519e-02, 5.3265e-02, 1.3614e-01,\n",
      "           4.9750e-03]],\n",
      "\n",
      "         [[1.0087e-03, 1.0757e-03, 2.8140e-04, 6.5788e-04, 5.8029e-02,\n",
      "           4.1349e-02, 3.6735e-01, 3.1825e-01, 1.2605e-01, 8.4957e-02,\n",
      "           9.9056e-04],\n",
      "          [2.8110e-04, 8.4849e-05, 1.3130e-04, 6.6385e-05, 1.3857e-02,\n",
      "           5.0771e-03, 3.4643e-01, 3.5363e-01, 1.6866e-01, 1.1154e-01,\n",
      "           2.4698e-04]],\n",
      "\n",
      "         [[4.5568e-03, 3.0560e-03, 1.9296e-03, 1.4549e-03, 5.0402e-02,\n",
      "           1.7042e-02, 1.5789e-01, 4.3275e-01, 1.6861e-01, 1.5809e-01,\n",
      "           4.2139e-03],\n",
      "          [9.0610e-02, 4.7629e-02, 6.7512e-01, 9.9980e-02, 1.7882e-03,\n",
      "           5.7073e-05, 6.5269e-04, 5.3802e-04, 9.5373e-04, 4.7758e-03,\n",
      "           7.7896e-02]],\n",
      "\n",
      "         [[1.3674e-03, 7.5639e-04, 7.1731e-04, 7.4899e-04, 1.3694e-02,\n",
      "           1.4394e-02, 1.0560e-01, 2.7270e-01, 1.7882e-01, 4.0958e-01,\n",
      "           1.6248e-03],\n",
      "          [2.4658e-02, 9.9394e-03, 1.2389e-02, 1.0344e-02, 3.6215e-01,\n",
      "           4.2989e-02, 1.5635e-01, 1.1539e-01, 7.0509e-02, 1.7084e-01,\n",
      "           2.4451e-02]],\n",
      "\n",
      "         [[6.1914e-04, 5.1572e-04, 1.0208e-04, 3.6718e-04, 4.2726e-02,\n",
      "           1.7168e-02, 3.4199e-01, 3.7539e-01, 1.4622e-01, 7.4273e-02,\n",
      "           6.3357e-04],\n",
      "          [5.7161e-05, 6.6234e-06, 3.5118e-05, 1.7652e-05, 1.9989e-02,\n",
      "           3.8852e-04, 6.6034e-01, 1.4828e-01, 1.2213e-01, 4.8704e-02,\n",
      "           4.7172e-05]],\n",
      "\n",
      "         [[8.7465e-04, 5.5213e-04, 5.3893e-04, 8.7702e-04, 1.4588e-01,\n",
      "           9.7495e-02, 2.3745e-01, 2.2946e-01, 1.9801e-01, 8.8074e-02,\n",
      "           7.8902e-04],\n",
      "          [2.0608e-04, 1.5240e-04, 1.6504e-04, 8.6065e-05, 2.2966e-02,\n",
      "           1.2485e-02, 2.4784e-01, 5.4725e-01, 1.0169e-01, 6.6983e-02,\n",
      "           1.8612e-04]]]]), tensor([[[[3.1463e-03, 4.8807e-03, 2.8232e-03, 1.9911e-03, 6.3559e-02,\n",
      "           2.8466e-02, 2.5192e-01, 3.6398e-01, 1.2386e-01, 1.5234e-01,\n",
      "           3.0337e-03],\n",
      "          [8.2186e-04, 1.5400e-03, 1.0818e-03, 4.8190e-04, 2.0015e-02,\n",
      "           2.5287e-03, 3.3684e-01, 3.3960e-01, 1.7474e-01, 1.2155e-01,\n",
      "           8.0376e-04],\n",
      "          [5.7737e-06, 1.1360e-06, 2.3544e-06, 8.1775e-06, 7.0152e-03,\n",
      "           9.8961e-01, 2.5704e-03, 5.8056e-04, 1.6876e-04, 3.3153e-05,\n",
      "           7.7871e-06]],\n",
      "\n",
      "         [[2.2069e-02, 3.4022e-02, 1.1153e-02, 1.0452e-02, 7.9929e-02,\n",
      "           1.4591e-02, 2.2788e-01, 2.8653e-01, 1.8589e-01, 1.0547e-01,\n",
      "           2.2008e-02],\n",
      "          [1.1993e-01, 4.0426e-02, 2.6992e-01, 9.1956e-02, 1.7506e-01,\n",
      "           2.6440e-02, 8.5125e-02, 2.1970e-02, 2.5174e-02, 2.5401e-02,\n",
      "           1.1860e-01],\n",
      "          [4.8049e-03, 2.6281e-03, 3.4883e-03, 4.2358e-03, 4.3830e-01,\n",
      "           3.5349e-01, 1.2749e-01, 3.3562e-02, 2.1178e-02, 5.5271e-03,\n",
      "           5.2930e-03]],\n",
      "\n",
      "         [[1.6908e-03, 1.4467e-03, 6.9412e-04, 1.5117e-03, 1.9361e-02,\n",
      "           9.4148e-03, 1.4902e-01, 2.9468e-01, 2.6430e-01, 2.5609e-01,\n",
      "           1.7935e-03],\n",
      "          [6.5195e-03, 1.3313e-03, 5.5494e-03, 2.5668e-03, 1.5586e-01,\n",
      "           6.4921e-02, 4.8035e-01, 8.8519e-02, 5.3265e-02, 1.3614e-01,\n",
      "           4.9750e-03],\n",
      "          [6.8641e-04, 5.2134e-04, 3.6230e-04, 3.6309e-04, 5.6362e-01,\n",
      "           3.4869e-01, 5.9199e-02, 1.9372e-02, 4.2511e-03, 2.1957e-03,\n",
      "           7.3896e-04]],\n",
      "\n",
      "         [[1.0087e-03, 1.0757e-03, 2.8140e-04, 6.5788e-04, 5.8029e-02,\n",
      "           4.1349e-02, 3.6735e-01, 3.1825e-01, 1.2605e-01, 8.4957e-02,\n",
      "           9.9056e-04],\n",
      "          [2.8110e-04, 8.4849e-05, 1.3130e-04, 6.6385e-05, 1.3857e-02,\n",
      "           5.0771e-03, 3.4643e-01, 3.5363e-01, 1.6866e-01, 1.1154e-01,\n",
      "           2.4698e-04],\n",
      "          [6.4882e-03, 1.2730e-03, 2.3356e-03, 8.1065e-03, 1.5827e-01,\n",
      "           5.3585e-01, 1.5541e-01, 9.6808e-02, 1.9414e-02, 9.1355e-03,\n",
      "           6.9080e-03]],\n",
      "\n",
      "         [[4.5568e-03, 3.0560e-03, 1.9296e-03, 1.4549e-03, 5.0402e-02,\n",
      "           1.7042e-02, 1.5789e-01, 4.3275e-01, 1.6861e-01, 1.5809e-01,\n",
      "           4.2139e-03],\n",
      "          [9.0610e-02, 4.7629e-02, 6.7512e-01, 9.9980e-02, 1.7882e-03,\n",
      "           5.7073e-05, 6.5269e-04, 5.3802e-04, 9.5373e-04, 4.7758e-03,\n",
      "           7.7896e-02],\n",
      "          [1.6019e-04, 3.0937e-04, 4.9784e-05, 8.5614e-05, 4.1716e-01,\n",
      "           1.4661e-01, 3.3530e-01, 7.7166e-02, 1.4857e-02, 8.1553e-03,\n",
      "           1.4486e-04]],\n",
      "\n",
      "         [[1.3674e-03, 7.5639e-04, 7.1731e-04, 7.4899e-04, 1.3694e-02,\n",
      "           1.4394e-02, 1.0560e-01, 2.7270e-01, 1.7882e-01, 4.0958e-01,\n",
      "           1.6248e-03],\n",
      "          [2.4658e-02, 9.9394e-03, 1.2389e-02, 1.0344e-02, 3.6215e-01,\n",
      "           4.2989e-02, 1.5635e-01, 1.1539e-01, 7.0509e-02, 1.7084e-01,\n",
      "           2.4451e-02],\n",
      "          [2.1598e-04, 1.1942e-04, 1.4052e-04, 1.4711e-04, 3.5829e-01,\n",
      "           4.7412e-01, 1.3840e-01, 2.1115e-02, 5.5942e-03, 1.5877e-03,\n",
      "           2.6569e-04]],\n",
      "\n",
      "         [[6.1914e-04, 5.1572e-04, 1.0208e-04, 3.6718e-04, 4.2726e-02,\n",
      "           1.7168e-02, 3.4199e-01, 3.7539e-01, 1.4622e-01, 7.4273e-02,\n",
      "           6.3357e-04],\n",
      "          [5.7161e-05, 6.6234e-06, 3.5118e-05, 1.7652e-05, 1.9989e-02,\n",
      "           3.8852e-04, 6.6034e-01, 1.4828e-01, 1.2213e-01, 4.8704e-02,\n",
      "           4.7172e-05],\n",
      "          [7.1265e-04, 7.5033e-05, 2.7719e-04, 4.9727e-04, 4.2960e-01,\n",
      "           1.1244e-01, 3.5773e-01, 6.1942e-02, 3.0815e-02, 5.1873e-03,\n",
      "           7.1023e-04]],\n",
      "\n",
      "         [[8.7465e-04, 5.5213e-04, 5.3893e-04, 8.7702e-04, 1.4588e-01,\n",
      "           9.7495e-02, 2.3745e-01, 2.2946e-01, 1.9801e-01, 8.8074e-02,\n",
      "           7.8902e-04],\n",
      "          [2.0608e-04, 1.5240e-04, 1.6504e-04, 8.6065e-05, 2.2966e-02,\n",
      "           1.2485e-02, 2.4784e-01, 5.4725e-01, 1.0169e-01, 6.6983e-02,\n",
      "           1.8612e-04],\n",
      "          [1.4811e-03, 3.9096e-04, 8.8826e-04, 1.9774e-03, 5.8172e-01,\n",
      "           1.6528e-01, 1.8980e-01, 3.7363e-02, 1.3966e-02, 5.4836e-03,\n",
      "           1.6541e-03]]]]), tensor([[[[3.1463e-03, 4.8807e-03, 2.8232e-03, 1.9911e-03, 6.3559e-02,\n",
      "           2.8466e-02, 2.5192e-01, 3.6398e-01, 1.2386e-01, 1.5234e-01,\n",
      "           3.0337e-03],\n",
      "          [8.2186e-04, 1.5400e-03, 1.0818e-03, 4.8190e-04, 2.0015e-02,\n",
      "           2.5287e-03, 3.3684e-01, 3.3960e-01, 1.7474e-01, 1.2155e-01,\n",
      "           8.0376e-04],\n",
      "          [5.7737e-06, 1.1360e-06, 2.3544e-06, 8.1775e-06, 7.0152e-03,\n",
      "           9.8961e-01, 2.5704e-03, 5.8056e-04, 1.6876e-04, 3.3153e-05,\n",
      "           7.7871e-06],\n",
      "          [1.0475e-03, 1.3335e-04, 5.5654e-04, 7.9319e-03, 6.4271e-02,\n",
      "           8.9064e-01, 2.3618e-02, 7.4127e-03, 2.4690e-03, 7.2102e-04,\n",
      "           1.1976e-03]],\n",
      "\n",
      "         [[2.2069e-02, 3.4022e-02, 1.1153e-02, 1.0452e-02, 7.9929e-02,\n",
      "           1.4591e-02, 2.2788e-01, 2.8653e-01, 1.8589e-01, 1.0547e-01,\n",
      "           2.2008e-02],\n",
      "          [1.1993e-01, 4.0426e-02, 2.6992e-01, 9.1956e-02, 1.7506e-01,\n",
      "           2.6440e-02, 8.5125e-02, 2.1970e-02, 2.5174e-02, 2.5401e-02,\n",
      "           1.1860e-01],\n",
      "          [4.8049e-03, 2.6281e-03, 3.4883e-03, 4.2358e-03, 4.3830e-01,\n",
      "           3.5349e-01, 1.2749e-01, 3.3562e-02, 2.1178e-02, 5.5271e-03,\n",
      "           5.2930e-03],\n",
      "          [1.3612e-04, 7.5279e-05, 4.5362e-05, 5.3251e-04, 7.1381e-02,\n",
      "           9.1831e-01, 5.5835e-03, 2.4914e-03, 1.1060e-03, 2.0686e-04,\n",
      "           1.3436e-04]],\n",
      "\n",
      "         [[1.6908e-03, 1.4467e-03, 6.9412e-04, 1.5117e-03, 1.9361e-02,\n",
      "           9.4148e-03, 1.4902e-01, 2.9468e-01, 2.6430e-01, 2.5609e-01,\n",
      "           1.7935e-03],\n",
      "          [6.5195e-03, 1.3313e-03, 5.5494e-03, 2.5668e-03, 1.5586e-01,\n",
      "           6.4921e-02, 4.8035e-01, 8.8519e-02, 5.3265e-02, 1.3614e-01,\n",
      "           4.9750e-03],\n",
      "          [6.8641e-04, 5.2134e-04, 3.6230e-04, 3.6309e-04, 5.6362e-01,\n",
      "           3.4869e-01, 5.9199e-02, 1.9372e-02, 4.2511e-03, 2.1957e-03,\n",
      "           7.3896e-04],\n",
      "          [7.5856e-03, 1.2385e-03, 4.0042e-03, 4.1666e-02, 6.9289e-01,\n",
      "           2.3641e-01, 3.5231e-03, 2.4355e-03, 8.3233e-04, 4.9467e-04,\n",
      "           8.9219e-03]],\n",
      "\n",
      "         [[1.0087e-03, 1.0757e-03, 2.8140e-04, 6.5788e-04, 5.8029e-02,\n",
      "           4.1349e-02, 3.6735e-01, 3.1825e-01, 1.2605e-01, 8.4957e-02,\n",
      "           9.9056e-04],\n",
      "          [2.8110e-04, 8.4849e-05, 1.3130e-04, 6.6385e-05, 1.3857e-02,\n",
      "           5.0771e-03, 3.4643e-01, 3.5363e-01, 1.6866e-01, 1.1154e-01,\n",
      "           2.4698e-04],\n",
      "          [6.4882e-03, 1.2730e-03, 2.3356e-03, 8.1065e-03, 1.5827e-01,\n",
      "           5.3585e-01, 1.5541e-01, 9.6808e-02, 1.9414e-02, 9.1355e-03,\n",
      "           6.9080e-03],\n",
      "          [1.8458e-04, 1.6526e-05, 2.7456e-05, 2.0490e-04, 2.7310e-02,\n",
      "           9.6750e-01, 3.5618e-03, 7.7272e-04, 1.5029e-04, 7.4872e-05,\n",
      "           1.9256e-04]],\n",
      "\n",
      "         [[4.5568e-03, 3.0560e-03, 1.9296e-03, 1.4549e-03, 5.0402e-02,\n",
      "           1.7042e-02, 1.5789e-01, 4.3275e-01, 1.6861e-01, 1.5809e-01,\n",
      "           4.2139e-03],\n",
      "          [9.0610e-02, 4.7629e-02, 6.7512e-01, 9.9980e-02, 1.7882e-03,\n",
      "           5.7073e-05, 6.5269e-04, 5.3802e-04, 9.5373e-04, 4.7758e-03,\n",
      "           7.7896e-02],\n",
      "          [1.6019e-04, 3.0937e-04, 4.9784e-05, 8.5614e-05, 4.1716e-01,\n",
      "           1.4661e-01, 3.3530e-01, 7.7166e-02, 1.4857e-02, 8.1553e-03,\n",
      "           1.4486e-04],\n",
      "          [6.5427e-04, 5.2038e-04, 3.6886e-04, 7.4865e-04, 2.9515e-01,\n",
      "           6.8199e-01, 1.6670e-02, 2.1794e-03, 7.8078e-04, 1.8449e-04,\n",
      "           7.5471e-04]],\n",
      "\n",
      "         [[1.3674e-03, 7.5639e-04, 7.1731e-04, 7.4899e-04, 1.3694e-02,\n",
      "           1.4394e-02, 1.0560e-01, 2.7270e-01, 1.7882e-01, 4.0958e-01,\n",
      "           1.6248e-03],\n",
      "          [2.4658e-02, 9.9394e-03, 1.2389e-02, 1.0344e-02, 3.6215e-01,\n",
      "           4.2989e-02, 1.5635e-01, 1.1539e-01, 7.0509e-02, 1.7084e-01,\n",
      "           2.4451e-02],\n",
      "          [2.1598e-04, 1.1942e-04, 1.4052e-04, 1.4711e-04, 3.5829e-01,\n",
      "           4.7412e-01, 1.3840e-01, 2.1115e-02, 5.5942e-03, 1.5877e-03,\n",
      "           2.6569e-04],\n",
      "          [3.0929e-02, 1.0578e-02, 8.2094e-03, 3.6704e-02, 7.0874e-01,\n",
      "           7.7011e-02, 2.5327e-02, 2.3929e-02, 2.1494e-02, 2.3347e-02,\n",
      "           3.3727e-02]],\n",
      "\n",
      "         [[6.1914e-04, 5.1572e-04, 1.0208e-04, 3.6718e-04, 4.2726e-02,\n",
      "           1.7168e-02, 3.4199e-01, 3.7539e-01, 1.4622e-01, 7.4273e-02,\n",
      "           6.3357e-04],\n",
      "          [5.7161e-05, 6.6234e-06, 3.5118e-05, 1.7652e-05, 1.9989e-02,\n",
      "           3.8852e-04, 6.6034e-01, 1.4828e-01, 1.2213e-01, 4.8704e-02,\n",
      "           4.7172e-05],\n",
      "          [7.1265e-04, 7.5033e-05, 2.7719e-04, 4.9727e-04, 4.2960e-01,\n",
      "           1.1244e-01, 3.5773e-01, 6.1942e-02, 3.0815e-02, 5.1873e-03,\n",
      "           7.1023e-04],\n",
      "          [8.2999e-03, 4.4688e-04, 2.7274e-03, 1.0476e-02, 4.0112e-01,\n",
      "           5.3557e-01, 2.2495e-02, 3.7412e-03, 4.9873e-03, 1.2114e-03,\n",
      "           8.9298e-03]],\n",
      "\n",
      "         [[8.7465e-04, 5.5213e-04, 5.3893e-04, 8.7702e-04, 1.4588e-01,\n",
      "           9.7495e-02, 2.3745e-01, 2.2946e-01, 1.9801e-01, 8.8074e-02,\n",
      "           7.8902e-04],\n",
      "          [2.0608e-04, 1.5240e-04, 1.6504e-04, 8.6065e-05, 2.2966e-02,\n",
      "           1.2485e-02, 2.4784e-01, 5.4725e-01, 1.0169e-01, 6.6983e-02,\n",
      "           1.8612e-04],\n",
      "          [1.4811e-03, 3.9096e-04, 8.8826e-04, 1.9774e-03, 5.8172e-01,\n",
      "           1.6528e-01, 1.8980e-01, 3.7363e-02, 1.3966e-02, 5.4836e-03,\n",
      "           1.6541e-03],\n",
      "          [9.7496e-04, 7.2677e-04, 2.2738e-04, 2.2672e-03, 2.3556e-01,\n",
      "           6.0748e-02, 5.3263e-01, 1.0118e-01, 5.4796e-02, 9.7754e-03,\n",
      "           1.1149e-03]]]]), tensor([[[[3.1463e-03, 4.8807e-03, 2.8232e-03, 1.9911e-03, 6.3559e-02,\n",
      "           2.8466e-02, 2.5192e-01, 3.6398e-01, 1.2386e-01, 1.5234e-01,\n",
      "           3.0337e-03],\n",
      "          [8.2186e-04, 1.5400e-03, 1.0818e-03, 4.8190e-04, 2.0015e-02,\n",
      "           2.5287e-03, 3.3684e-01, 3.3960e-01, 1.7474e-01, 1.2155e-01,\n",
      "           8.0376e-04],\n",
      "          [5.7737e-06, 1.1360e-06, 2.3544e-06, 8.1774e-06, 7.0152e-03,\n",
      "           9.8961e-01, 2.5704e-03, 5.8056e-04, 1.6876e-04, 3.3153e-05,\n",
      "           7.7870e-06],\n",
      "          [1.0475e-03, 1.3335e-04, 5.5654e-04, 7.9319e-03, 6.4271e-02,\n",
      "           8.9064e-01, 2.3618e-02, 7.4127e-03, 2.4690e-03, 7.2102e-04,\n",
      "           1.1976e-03],\n",
      "          [5.7931e-03, 2.6612e-03, 7.9289e-03, 5.4315e-03, 7.0144e-01,\n",
      "           1.0099e-01, 9.9837e-02, 4.2141e-02, 1.6560e-02, 1.1802e-02,\n",
      "           5.4134e-03]],\n",
      "\n",
      "         [[2.2069e-02, 3.4022e-02, 1.1153e-02, 1.0452e-02, 7.9929e-02,\n",
      "           1.4591e-02, 2.2788e-01, 2.8653e-01, 1.8589e-01, 1.0547e-01,\n",
      "           2.2008e-02],\n",
      "          [1.1993e-01, 4.0426e-02, 2.6992e-01, 9.1956e-02, 1.7506e-01,\n",
      "           2.6440e-02, 8.5125e-02, 2.1970e-02, 2.5174e-02, 2.5401e-02,\n",
      "           1.1860e-01],\n",
      "          [4.8049e-03, 2.6281e-03, 3.4883e-03, 4.2358e-03, 4.3830e-01,\n",
      "           3.5349e-01, 1.2749e-01, 3.3562e-02, 2.1178e-02, 5.5271e-03,\n",
      "           5.2930e-03],\n",
      "          [1.3612e-04, 7.5279e-05, 4.5362e-05, 5.3250e-04, 7.1381e-02,\n",
      "           9.1831e-01, 5.5835e-03, 2.4914e-03, 1.1060e-03, 2.0686e-04,\n",
      "           1.3436e-04],\n",
      "          [2.6580e-04, 2.9633e-04, 4.1325e-04, 5.8770e-04, 6.6235e-01,\n",
      "           3.2131e-01, 9.3847e-03, 2.7951e-03, 1.5609e-03, 7.9497e-04,\n",
      "           2.3878e-04]],\n",
      "\n",
      "         [[1.6908e-03, 1.4467e-03, 6.9412e-04, 1.5117e-03, 1.9361e-02,\n",
      "           9.4148e-03, 1.4902e-01, 2.9468e-01, 2.6430e-01, 2.5609e-01,\n",
      "           1.7935e-03],\n",
      "          [6.5195e-03, 1.3313e-03, 5.5494e-03, 2.5668e-03, 1.5586e-01,\n",
      "           6.4921e-02, 4.8035e-01, 8.8519e-02, 5.3265e-02, 1.3614e-01,\n",
      "           4.9750e-03],\n",
      "          [6.8641e-04, 5.2134e-04, 3.6230e-04, 3.6309e-04, 5.6362e-01,\n",
      "           3.4869e-01, 5.9199e-02, 1.9372e-02, 4.2511e-03, 2.1957e-03,\n",
      "           7.3896e-04],\n",
      "          [7.5856e-03, 1.2385e-03, 4.0042e-03, 4.1666e-02, 6.9289e-01,\n",
      "           2.3641e-01, 3.5231e-03, 2.4355e-03, 8.3233e-04, 4.9467e-04,\n",
      "           8.9219e-03],\n",
      "          [1.9306e-03, 1.4239e-03, 5.5764e-03, 1.3963e-03, 9.0617e-01,\n",
      "           5.8418e-03, 2.6882e-02, 2.2972e-02, 1.6731e-02, 9.4478e-03,\n",
      "           1.6314e-03]],\n",
      "\n",
      "         [[1.0087e-03, 1.0757e-03, 2.8140e-04, 6.5788e-04, 5.8029e-02,\n",
      "           4.1349e-02, 3.6735e-01, 3.1825e-01, 1.2605e-01, 8.4957e-02,\n",
      "           9.9056e-04],\n",
      "          [2.8110e-04, 8.4849e-05, 1.3130e-04, 6.6385e-05, 1.3857e-02,\n",
      "           5.0771e-03, 3.4643e-01, 3.5363e-01, 1.6866e-01, 1.1154e-01,\n",
      "           2.4698e-04],\n",
      "          [6.4882e-03, 1.2730e-03, 2.3356e-03, 8.1064e-03, 1.5827e-01,\n",
      "           5.3585e-01, 1.5541e-01, 9.6808e-02, 1.9414e-02, 9.1355e-03,\n",
      "           6.9080e-03],\n",
      "          [1.8458e-04, 1.6526e-05, 2.7456e-05, 2.0490e-04, 2.7310e-02,\n",
      "           9.6750e-01, 3.5618e-03, 7.7272e-04, 1.5029e-04, 7.4872e-05,\n",
      "           1.9256e-04],\n",
      "          [1.9754e-02, 2.8845e-03, 5.2545e-03, 1.0331e-02, 2.6157e-01,\n",
      "           2.2916e-01, 2.0804e-01, 1.2392e-01, 5.4515e-02, 6.5191e-02,\n",
      "           1.9383e-02]],\n",
      "\n",
      "         [[4.5568e-03, 3.0560e-03, 1.9296e-03, 1.4549e-03, 5.0402e-02,\n",
      "           1.7042e-02, 1.5789e-01, 4.3275e-01, 1.6861e-01, 1.5809e-01,\n",
      "           4.2139e-03],\n",
      "          [9.0610e-02, 4.7629e-02, 6.7512e-01, 9.9980e-02, 1.7882e-03,\n",
      "           5.7073e-05, 6.5269e-04, 5.3802e-04, 9.5373e-04, 4.7758e-03,\n",
      "           7.7896e-02],\n",
      "          [1.6019e-04, 3.0937e-04, 4.9784e-05, 8.5614e-05, 4.1716e-01,\n",
      "           1.4661e-01, 3.3530e-01, 7.7166e-02, 1.4857e-02, 8.1553e-03,\n",
      "           1.4486e-04],\n",
      "          [6.5427e-04, 5.2038e-04, 3.6886e-04, 7.4865e-04, 2.9515e-01,\n",
      "           6.8199e-01, 1.6670e-02, 2.1794e-03, 7.8078e-04, 1.8449e-04,\n",
      "           7.5471e-04],\n",
      "          [6.6102e-04, 1.9571e-04, 5.3970e-04, 3.3842e-04, 5.8702e-01,\n",
      "           1.7200e-02, 3.2729e-01, 3.4570e-02, 2.0435e-02, 1.1193e-02,\n",
      "           5.5140e-04]],\n",
      "\n",
      "         [[1.3674e-03, 7.5639e-04, 7.1731e-04, 7.4899e-04, 1.3694e-02,\n",
      "           1.4394e-02, 1.0560e-01, 2.7270e-01, 1.7882e-01, 4.0958e-01,\n",
      "           1.6248e-03],\n",
      "          [2.4658e-02, 9.9393e-03, 1.2389e-02, 1.0344e-02, 3.6215e-01,\n",
      "           4.2989e-02, 1.5635e-01, 1.1539e-01, 7.0509e-02, 1.7084e-01,\n",
      "           2.4451e-02],\n",
      "          [2.1598e-04, 1.1942e-04, 1.4052e-04, 1.4711e-04, 3.5829e-01,\n",
      "           4.7412e-01, 1.3840e-01, 2.1115e-02, 5.5942e-03, 1.5877e-03,\n",
      "           2.6569e-04],\n",
      "          [3.0929e-02, 1.0578e-02, 8.2094e-03, 3.6704e-02, 7.0874e-01,\n",
      "           7.7011e-02, 2.5327e-02, 2.3929e-02, 2.1494e-02, 2.3347e-02,\n",
      "           3.3727e-02],\n",
      "          [1.2620e-02, 4.1768e-03, 1.2820e-02, 1.4687e-02, 6.4679e-01,\n",
      "           2.4881e-02, 8.2604e-02, 4.1242e-02, 5.5090e-02, 9.4099e-02,\n",
      "           1.0988e-02]],\n",
      "\n",
      "         [[6.1914e-04, 5.1572e-04, 1.0208e-04, 3.6718e-04, 4.2726e-02,\n",
      "           1.7168e-02, 3.4199e-01, 3.7539e-01, 1.4622e-01, 7.4273e-02,\n",
      "           6.3357e-04],\n",
      "          [5.7161e-05, 6.6234e-06, 3.5118e-05, 1.7652e-05, 1.9989e-02,\n",
      "           3.8852e-04, 6.6034e-01, 1.4828e-01, 1.2213e-01, 4.8704e-02,\n",
      "           4.7172e-05],\n",
      "          [7.1264e-04, 7.5033e-05, 2.7719e-04, 4.9727e-04, 4.2960e-01,\n",
      "           1.1244e-01, 3.5773e-01, 6.1942e-02, 3.0815e-02, 5.1873e-03,\n",
      "           7.1023e-04],\n",
      "          [8.2999e-03, 4.4688e-04, 2.7274e-03, 1.0476e-02, 4.0112e-01,\n",
      "           5.3557e-01, 2.2495e-02, 3.7412e-03, 4.9873e-03, 1.2114e-03,\n",
      "           8.9297e-03],\n",
      "          [1.2386e-01, 3.3863e-02, 9.0434e-02, 5.7255e-02, 3.7584e-01,\n",
      "           1.2757e-01, 4.8062e-02, 1.2595e-02, 1.4940e-02, 9.6308e-03,\n",
      "           1.0595e-01]],\n",
      "\n",
      "         [[8.7465e-04, 5.5213e-04, 5.3893e-04, 8.7702e-04, 1.4588e-01,\n",
      "           9.7495e-02, 2.3745e-01, 2.2946e-01, 1.9801e-01, 8.8074e-02,\n",
      "           7.8902e-04],\n",
      "          [2.0608e-04, 1.5240e-04, 1.6504e-04, 8.6065e-05, 2.2966e-02,\n",
      "           1.2485e-02, 2.4784e-01, 5.4725e-01, 1.0169e-01, 6.6983e-02,\n",
      "           1.8612e-04],\n",
      "          [1.4811e-03, 3.9096e-04, 8.8826e-04, 1.9774e-03, 5.8172e-01,\n",
      "           1.6528e-01, 1.8980e-01, 3.7363e-02, 1.3966e-02, 5.4836e-03,\n",
      "           1.6541e-03],\n",
      "          [9.7496e-04, 7.2677e-04, 2.2738e-04, 2.2672e-03, 2.3556e-01,\n",
      "           6.0748e-02, 5.3263e-01, 1.0118e-01, 5.4796e-02, 9.7754e-03,\n",
      "           1.1149e-03],\n",
      "          [9.1177e-03, 2.1350e-03, 1.3462e-02, 1.6876e-02, 5.3900e-01,\n",
      "           2.7096e-02, 3.2797e-01, 3.3092e-02, 1.5970e-02, 8.2831e-03,\n",
      "           6.9980e-03]]]]), tensor([[[[3.1463e-03, 4.8807e-03, 2.8232e-03, 1.9911e-03, 6.3559e-02,\n",
      "           2.8466e-02, 2.5192e-01, 3.6398e-01, 1.2386e-01, 1.5234e-01,\n",
      "           3.0337e-03],\n",
      "          [8.2186e-04, 1.5400e-03, 1.0818e-03, 4.8190e-04, 2.0015e-02,\n",
      "           2.5287e-03, 3.3684e-01, 3.3960e-01, 1.7474e-01, 1.2155e-01,\n",
      "           8.0376e-04],\n",
      "          [5.7737e-06, 1.1360e-06, 2.3544e-06, 8.1774e-06, 7.0152e-03,\n",
      "           9.8961e-01, 2.5704e-03, 5.8056e-04, 1.6876e-04, 3.3153e-05,\n",
      "           7.7870e-06],\n",
      "          [1.0475e-03, 1.3335e-04, 5.5654e-04, 7.9319e-03, 6.4271e-02,\n",
      "           8.9064e-01, 2.3618e-02, 7.4127e-03, 2.4690e-03, 7.2102e-04,\n",
      "           1.1976e-03],\n",
      "          [5.7931e-03, 2.6612e-03, 7.9289e-03, 5.4315e-03, 7.0144e-01,\n",
      "           1.0099e-01, 9.9837e-02, 4.2141e-02, 1.6560e-02, 1.1802e-02,\n",
      "           5.4134e-03],\n",
      "          [1.1752e-01, 5.0375e-02, 7.9916e-02, 4.9886e-02, 5.6788e-02,\n",
      "           5.4993e-02, 1.3001e-01, 1.9941e-01, 1.2893e-01, 2.9106e-02,\n",
      "           1.0306e-01]],\n",
      "\n",
      "         [[2.2069e-02, 3.4022e-02, 1.1153e-02, 1.0452e-02, 7.9929e-02,\n",
      "           1.4591e-02, 2.2788e-01, 2.8653e-01, 1.8589e-01, 1.0547e-01,\n",
      "           2.2008e-02],\n",
      "          [1.1993e-01, 4.0426e-02, 2.6992e-01, 9.1956e-02, 1.7506e-01,\n",
      "           2.6440e-02, 8.5125e-02, 2.1970e-02, 2.5174e-02, 2.5401e-02,\n",
      "           1.1860e-01],\n",
      "          [4.8049e-03, 2.6281e-03, 3.4883e-03, 4.2358e-03, 4.3830e-01,\n",
      "           3.5349e-01, 1.2749e-01, 3.3562e-02, 2.1178e-02, 5.5271e-03,\n",
      "           5.2930e-03],\n",
      "          [1.3612e-04, 7.5279e-05, 4.5362e-05, 5.3250e-04, 7.1381e-02,\n",
      "           9.1831e-01, 5.5835e-03, 2.4914e-03, 1.1060e-03, 2.0686e-04,\n",
      "           1.3436e-04],\n",
      "          [2.6580e-04, 2.9633e-04, 4.1325e-04, 5.8770e-04, 6.6235e-01,\n",
      "           3.2131e-01, 9.3847e-03, 2.7951e-03, 1.5609e-03, 7.9497e-04,\n",
      "           2.3878e-04],\n",
      "          [1.7867e-01, 1.4918e-01, 1.9889e-01, 2.7258e-01, 8.4932e-03,\n",
      "           6.3507e-04, 5.9682e-03, 5.7982e-03, 6.1746e-03, 4.5077e-03,\n",
      "           1.6912e-01]],\n",
      "\n",
      "         [[1.6908e-03, 1.4467e-03, 6.9412e-04, 1.5117e-03, 1.9361e-02,\n",
      "           9.4148e-03, 1.4902e-01, 2.9468e-01, 2.6430e-01, 2.5609e-01,\n",
      "           1.7935e-03],\n",
      "          [6.5195e-03, 1.3313e-03, 5.5494e-03, 2.5668e-03, 1.5586e-01,\n",
      "           6.4921e-02, 4.8035e-01, 8.8519e-02, 5.3265e-02, 1.3614e-01,\n",
      "           4.9750e-03],\n",
      "          [6.8641e-04, 5.2134e-04, 3.6230e-04, 3.6309e-04, 5.6362e-01,\n",
      "           3.4869e-01, 5.9199e-02, 1.9372e-02, 4.2511e-03, 2.1957e-03,\n",
      "           7.3896e-04],\n",
      "          [7.5856e-03, 1.2385e-03, 4.0042e-03, 4.1666e-02, 6.9289e-01,\n",
      "           2.3641e-01, 3.5231e-03, 2.4355e-03, 8.3233e-04, 4.9467e-04,\n",
      "           8.9219e-03],\n",
      "          [1.9306e-03, 1.4239e-03, 5.5764e-03, 1.3963e-03, 9.0617e-01,\n",
      "           5.8418e-03, 2.6882e-02, 2.2972e-02, 1.6731e-02, 9.4478e-03,\n",
      "           1.6314e-03],\n",
      "          [6.9263e-02, 2.6118e-02, 2.0953e-01, 1.7045e-02, 4.7654e-01,\n",
      "           1.0154e-02, 4.2040e-02, 2.2766e-02, 4.2650e-02, 2.0826e-02,\n",
      "           6.3066e-02]],\n",
      "\n",
      "         [[1.0087e-03, 1.0757e-03, 2.8140e-04, 6.5788e-04, 5.8029e-02,\n",
      "           4.1349e-02, 3.6735e-01, 3.1825e-01, 1.2605e-01, 8.4957e-02,\n",
      "           9.9056e-04],\n",
      "          [2.8110e-04, 8.4849e-05, 1.3130e-04, 6.6385e-05, 1.3857e-02,\n",
      "           5.0771e-03, 3.4643e-01, 3.5363e-01, 1.6866e-01, 1.1154e-01,\n",
      "           2.4698e-04],\n",
      "          [6.4882e-03, 1.2730e-03, 2.3356e-03, 8.1064e-03, 1.5827e-01,\n",
      "           5.3585e-01, 1.5541e-01, 9.6808e-02, 1.9414e-02, 9.1355e-03,\n",
      "           6.9080e-03],\n",
      "          [1.8458e-04, 1.6526e-05, 2.7456e-05, 2.0490e-04, 2.7310e-02,\n",
      "           9.6750e-01, 3.5618e-03, 7.7272e-04, 1.5029e-04, 7.4872e-05,\n",
      "           1.9256e-04],\n",
      "          [1.9754e-02, 2.8845e-03, 5.2545e-03, 1.0331e-02, 2.6157e-01,\n",
      "           2.2916e-01, 2.0804e-01, 1.2392e-01, 5.4515e-02, 6.5191e-02,\n",
      "           1.9383e-02],\n",
      "          [1.0859e-01, 6.6936e-01, 3.8471e-02, 8.2930e-02, 1.0743e-03,\n",
      "           4.8902e-04, 3.0292e-04, 1.4678e-04, 9.6933e-05, 1.9486e-04,\n",
      "           9.8344e-02]],\n",
      "\n",
      "         [[4.5568e-03, 3.0560e-03, 1.9296e-03, 1.4549e-03, 5.0402e-02,\n",
      "           1.7042e-02, 1.5789e-01, 4.3275e-01, 1.6861e-01, 1.5809e-01,\n",
      "           4.2139e-03],\n",
      "          [9.0610e-02, 4.7629e-02, 6.7512e-01, 9.9980e-02, 1.7882e-03,\n",
      "           5.7073e-05, 6.5269e-04, 5.3802e-04, 9.5373e-04, 4.7758e-03,\n",
      "           7.7896e-02],\n",
      "          [1.6019e-04, 3.0937e-04, 4.9784e-05, 8.5614e-05, 4.1716e-01,\n",
      "           1.4661e-01, 3.3530e-01, 7.7166e-02, 1.4857e-02, 8.1553e-03,\n",
      "           1.4486e-04],\n",
      "          [6.5427e-04, 5.2038e-04, 3.6886e-04, 7.4865e-04, 2.9515e-01,\n",
      "           6.8199e-01, 1.6670e-02, 2.1794e-03, 7.8078e-04, 1.8449e-04,\n",
      "           7.5471e-04],\n",
      "          [6.6102e-04, 1.9571e-04, 5.3970e-04, 3.3842e-04, 5.8702e-01,\n",
      "           1.7200e-02, 3.2729e-01, 3.4570e-02, 2.0435e-02, 1.1193e-02,\n",
      "           5.5140e-04],\n",
      "          [7.0721e-03, 7.3487e-03, 6.9010e-03, 3.2509e-03, 1.8809e-01,\n",
      "           1.5186e-02, 4.9561e-01, 1.1271e-01, 1.0342e-01, 5.4925e-02,\n",
      "           5.5004e-03]],\n",
      "\n",
      "         [[1.3674e-03, 7.5639e-04, 7.1731e-04, 7.4899e-04, 1.3694e-02,\n",
      "           1.4394e-02, 1.0560e-01, 2.7270e-01, 1.7882e-01, 4.0958e-01,\n",
      "           1.6248e-03],\n",
      "          [2.4658e-02, 9.9393e-03, 1.2389e-02, 1.0344e-02, 3.6215e-01,\n",
      "           4.2989e-02, 1.5635e-01, 1.1539e-01, 7.0509e-02, 1.7084e-01,\n",
      "           2.4451e-02],\n",
      "          [2.1598e-04, 1.1942e-04, 1.4052e-04, 1.4711e-04, 3.5829e-01,\n",
      "           4.7412e-01, 1.3840e-01, 2.1115e-02, 5.5942e-03, 1.5877e-03,\n",
      "           2.6569e-04],\n",
      "          [3.0929e-02, 1.0578e-02, 8.2094e-03, 3.6704e-02, 7.0874e-01,\n",
      "           7.7011e-02, 2.5327e-02, 2.3929e-02, 2.1494e-02, 2.3347e-02,\n",
      "           3.3727e-02],\n",
      "          [1.2620e-02, 4.1768e-03, 1.2820e-02, 1.4687e-02, 6.4679e-01,\n",
      "           2.4881e-02, 8.2604e-02, 4.1242e-02, 5.5090e-02, 9.4099e-02,\n",
      "           1.0988e-02],\n",
      "          [7.5406e-02, 7.4420e-01, 1.8405e-02, 4.2707e-02, 4.0861e-03,\n",
      "           2.6068e-03, 5.3768e-03, 1.0639e-02, 1.1984e-02, 1.4652e-02,\n",
      "           6.9939e-02]],\n",
      "\n",
      "         [[6.1914e-04, 5.1572e-04, 1.0208e-04, 3.6718e-04, 4.2726e-02,\n",
      "           1.7168e-02, 3.4199e-01, 3.7539e-01, 1.4622e-01, 7.4273e-02,\n",
      "           6.3357e-04],\n",
      "          [5.7161e-05, 6.6234e-06, 3.5118e-05, 1.7652e-05, 1.9989e-02,\n",
      "           3.8852e-04, 6.6034e-01, 1.4828e-01, 1.2213e-01, 4.8704e-02,\n",
      "           4.7172e-05],\n",
      "          [7.1264e-04, 7.5033e-05, 2.7719e-04, 4.9727e-04, 4.2960e-01,\n",
      "           1.1244e-01, 3.5773e-01, 6.1942e-02, 3.0815e-02, 5.1873e-03,\n",
      "           7.1023e-04],\n",
      "          [8.2999e-03, 4.4688e-04, 2.7274e-03, 1.0476e-02, 4.0112e-01,\n",
      "           5.3557e-01, 2.2495e-02, 3.7412e-03, 4.9873e-03, 1.2114e-03,\n",
      "           8.9297e-03],\n",
      "          [1.2386e-01, 3.3863e-02, 9.0434e-02, 5.7255e-02, 3.7584e-01,\n",
      "           1.2757e-01, 4.8062e-02, 1.2595e-02, 1.4940e-02, 9.6308e-03,\n",
      "           1.0595e-01],\n",
      "          [1.6127e-01, 1.7385e-01, 1.0082e-01, 1.4378e-01, 4.0105e-02,\n",
      "           2.2487e-02, 9.3175e-02, 4.0765e-02, 4.2548e-02, 1.7513e-02,\n",
      "           1.6368e-01]],\n",
      "\n",
      "         [[8.7465e-04, 5.5213e-04, 5.3893e-04, 8.7702e-04, 1.4588e-01,\n",
      "           9.7495e-02, 2.3745e-01, 2.2946e-01, 1.9801e-01, 8.8074e-02,\n",
      "           7.8902e-04],\n",
      "          [2.0608e-04, 1.5240e-04, 1.6504e-04, 8.6065e-05, 2.2966e-02,\n",
      "           1.2485e-02, 2.4784e-01, 5.4725e-01, 1.0169e-01, 6.6983e-02,\n",
      "           1.8612e-04],\n",
      "          [1.4811e-03, 3.9096e-04, 8.8826e-04, 1.9774e-03, 5.8172e-01,\n",
      "           1.6528e-01, 1.8980e-01, 3.7363e-02, 1.3966e-02, 5.4836e-03,\n",
      "           1.6541e-03],\n",
      "          [9.7496e-04, 7.2677e-04, 2.2738e-04, 2.2672e-03, 2.3556e-01,\n",
      "           6.0748e-02, 5.3263e-01, 1.0118e-01, 5.4796e-02, 9.7754e-03,\n",
      "           1.1149e-03],\n",
      "          [9.1177e-03, 2.1350e-03, 1.3462e-02, 1.6876e-02, 5.3900e-01,\n",
      "           2.7096e-02, 3.2797e-01, 3.3092e-02, 1.5970e-02, 8.2831e-03,\n",
      "           6.9980e-03],\n",
      "          [2.2400e-01, 1.2511e-01, 1.7143e-01, 2.7496e-01, 6.1444e-03,\n",
      "           5.1560e-04, 5.6612e-03, 9.9144e-04, 9.4555e-04, 7.0092e-04,\n",
      "           1.8954e-01]]]]), tensor([[[[3.1463e-03, 4.8807e-03, 2.8232e-03, 1.9911e-03, 6.3559e-02,\n",
      "           2.8466e-02, 2.5192e-01, 3.6398e-01, 1.2386e-01, 1.5234e-01,\n",
      "           3.0337e-03],\n",
      "          [8.2186e-04, 1.5400e-03, 1.0818e-03, 4.8190e-04, 2.0015e-02,\n",
      "           2.5287e-03, 3.3684e-01, 3.3960e-01, 1.7474e-01, 1.2155e-01,\n",
      "           8.0376e-04],\n",
      "          [5.7737e-06, 1.1360e-06, 2.3544e-06, 8.1774e-06, 7.0152e-03,\n",
      "           9.8961e-01, 2.5704e-03, 5.8056e-04, 1.6876e-04, 3.3153e-05,\n",
      "           7.7870e-06],\n",
      "          [1.0475e-03, 1.3335e-04, 5.5654e-04, 7.9319e-03, 6.4271e-02,\n",
      "           8.9064e-01, 2.3618e-02, 7.4127e-03, 2.4690e-03, 7.2102e-04,\n",
      "           1.1976e-03],\n",
      "          [5.7931e-03, 2.6612e-03, 7.9289e-03, 5.4315e-03, 7.0144e-01,\n",
      "           1.0099e-01, 9.9837e-02, 4.2141e-02, 1.6560e-02, 1.1802e-02,\n",
      "           5.4134e-03],\n",
      "          [1.1752e-01, 5.0375e-02, 7.9916e-02, 4.9886e-02, 5.6788e-02,\n",
      "           5.4993e-02, 1.3001e-01, 1.9941e-01, 1.2893e-01, 2.9106e-02,\n",
      "           1.0306e-01],\n",
      "          [7.2511e-02, 5.3683e-02, 8.0276e-02, 7.0218e-01, 1.9445e-04,\n",
      "           2.5987e-03, 1.3162e-04, 1.0059e-04, 2.1158e-04, 1.4226e-04,\n",
      "           8.7970e-02]],\n",
      "\n",
      "         [[2.2069e-02, 3.4022e-02, 1.1153e-02, 1.0452e-02, 7.9929e-02,\n",
      "           1.4591e-02, 2.2788e-01, 2.8653e-01, 1.8589e-01, 1.0547e-01,\n",
      "           2.2008e-02],\n",
      "          [1.1993e-01, 4.0426e-02, 2.6992e-01, 9.1956e-02, 1.7506e-01,\n",
      "           2.6440e-02, 8.5125e-02, 2.1970e-02, 2.5174e-02, 2.5401e-02,\n",
      "           1.1860e-01],\n",
      "          [4.8049e-03, 2.6281e-03, 3.4883e-03, 4.2358e-03, 4.3830e-01,\n",
      "           3.5349e-01, 1.2749e-01, 3.3562e-02, 2.1178e-02, 5.5271e-03,\n",
      "           5.2930e-03],\n",
      "          [1.3612e-04, 7.5279e-05, 4.5362e-05, 5.3250e-04, 7.1381e-02,\n",
      "           9.1831e-01, 5.5835e-03, 2.4914e-03, 1.1060e-03, 2.0686e-04,\n",
      "           1.3436e-04],\n",
      "          [2.6580e-04, 2.9633e-04, 4.1325e-04, 5.8770e-04, 6.6235e-01,\n",
      "           3.2131e-01, 9.3847e-03, 2.7951e-03, 1.5609e-03, 7.9497e-04,\n",
      "           2.3878e-04],\n",
      "          [1.7867e-01, 1.4918e-01, 1.9889e-01, 2.7258e-01, 8.4932e-03,\n",
      "           6.3507e-04, 5.9682e-03, 5.7982e-03, 6.1746e-03, 4.5077e-03,\n",
      "           1.6912e-01],\n",
      "          [1.7155e-01, 1.0497e-01, 9.0988e-02, 4.6727e-01, 5.4778e-04,\n",
      "           3.5050e-04, 2.2927e-04, 1.6535e-04, 4.4670e-04, 4.2240e-04,\n",
      "           1.6305e-01]],\n",
      "\n",
      "         [[1.6908e-03, 1.4467e-03, 6.9412e-04, 1.5117e-03, 1.9361e-02,\n",
      "           9.4148e-03, 1.4902e-01, 2.9468e-01, 2.6430e-01, 2.5609e-01,\n",
      "           1.7935e-03],\n",
      "          [6.5195e-03, 1.3313e-03, 5.5494e-03, 2.5668e-03, 1.5586e-01,\n",
      "           6.4921e-02, 4.8035e-01, 8.8519e-02, 5.3265e-02, 1.3614e-01,\n",
      "           4.9750e-03],\n",
      "          [6.8641e-04, 5.2134e-04, 3.6230e-04, 3.6309e-04, 5.6362e-01,\n",
      "           3.4869e-01, 5.9199e-02, 1.9372e-02, 4.2511e-03, 2.1957e-03,\n",
      "           7.3896e-04],\n",
      "          [7.5856e-03, 1.2385e-03, 4.0042e-03, 4.1666e-02, 6.9289e-01,\n",
      "           2.3641e-01, 3.5231e-03, 2.4355e-03, 8.3233e-04, 4.9467e-04,\n",
      "           8.9219e-03],\n",
      "          [1.9306e-03, 1.4239e-03, 5.5764e-03, 1.3963e-03, 9.0617e-01,\n",
      "           5.8418e-03, 2.6882e-02, 2.2972e-02, 1.6731e-02, 9.4478e-03,\n",
      "           1.6314e-03],\n",
      "          [6.9263e-02, 2.6118e-02, 2.0953e-01, 1.7045e-02, 4.7654e-01,\n",
      "           1.0154e-02, 4.2040e-02, 2.2766e-02, 4.2650e-02, 2.0826e-02,\n",
      "           6.3066e-02],\n",
      "          [6.4414e-02, 1.3122e-02, 1.9929e-01, 6.4859e-01, 3.5370e-04,\n",
      "           1.3373e-03, 8.9793e-05, 2.8804e-05, 7.4523e-05, 9.7373e-05,\n",
      "           7.2608e-02]],\n",
      "\n",
      "         [[1.0087e-03, 1.0757e-03, 2.8140e-04, 6.5788e-04, 5.8029e-02,\n",
      "           4.1349e-02, 3.6735e-01, 3.1825e-01, 1.2605e-01, 8.4957e-02,\n",
      "           9.9056e-04],\n",
      "          [2.8110e-04, 8.4849e-05, 1.3130e-04, 6.6385e-05, 1.3857e-02,\n",
      "           5.0771e-03, 3.4643e-01, 3.5363e-01, 1.6866e-01, 1.1154e-01,\n",
      "           2.4698e-04],\n",
      "          [6.4882e-03, 1.2730e-03, 2.3356e-03, 8.1064e-03, 1.5827e-01,\n",
      "           5.3585e-01, 1.5541e-01, 9.6808e-02, 1.9414e-02, 9.1355e-03,\n",
      "           6.9080e-03],\n",
      "          [1.8458e-04, 1.6526e-05, 2.7456e-05, 2.0490e-04, 2.7310e-02,\n",
      "           9.6750e-01, 3.5618e-03, 7.7272e-04, 1.5029e-04, 7.4872e-05,\n",
      "           1.9256e-04],\n",
      "          [1.9754e-02, 2.8845e-03, 5.2545e-03, 1.0331e-02, 2.6157e-01,\n",
      "           2.2916e-01, 2.0804e-01, 1.2392e-01, 5.4515e-02, 6.5191e-02,\n",
      "           1.9383e-02],\n",
      "          [1.0859e-01, 6.6936e-01, 3.8471e-02, 8.2930e-02, 1.0743e-03,\n",
      "           4.8902e-04, 3.0292e-04, 1.4678e-04, 9.6933e-05, 1.9486e-04,\n",
      "           9.8344e-02],\n",
      "          [1.1221e-01, 9.0406e-02, 2.0647e-01, 4.6566e-01, 6.3398e-05,\n",
      "           1.2465e-04, 1.9616e-05, 4.4517e-06, 8.1204e-06, 1.3798e-05,\n",
      "           1.2501e-01]],\n",
      "\n",
      "         [[4.5568e-03, 3.0560e-03, 1.9296e-03, 1.4549e-03, 5.0402e-02,\n",
      "           1.7042e-02, 1.5789e-01, 4.3275e-01, 1.6861e-01, 1.5809e-01,\n",
      "           4.2139e-03],\n",
      "          [9.0610e-02, 4.7629e-02, 6.7512e-01, 9.9980e-02, 1.7882e-03,\n",
      "           5.7073e-05, 6.5269e-04, 5.3802e-04, 9.5373e-04, 4.7758e-03,\n",
      "           7.7896e-02],\n",
      "          [1.6019e-04, 3.0937e-04, 4.9784e-05, 8.5614e-05, 4.1716e-01,\n",
      "           1.4661e-01, 3.3530e-01, 7.7166e-02, 1.4857e-02, 8.1553e-03,\n",
      "           1.4486e-04],\n",
      "          [6.5427e-04, 5.2038e-04, 3.6886e-04, 7.4865e-04, 2.9515e-01,\n",
      "           6.8199e-01, 1.6670e-02, 2.1794e-03, 7.8078e-04, 1.8449e-04,\n",
      "           7.5471e-04],\n",
      "          [6.6102e-04, 1.9571e-04, 5.3970e-04, 3.3842e-04, 5.8702e-01,\n",
      "           1.7200e-02, 3.2729e-01, 3.4570e-02, 2.0435e-02, 1.1193e-02,\n",
      "           5.5140e-04],\n",
      "          [7.0721e-03, 7.3487e-03, 6.9010e-03, 3.2509e-03, 1.8809e-01,\n",
      "           1.5186e-02, 4.9561e-01, 1.1271e-01, 1.0342e-01, 5.4925e-02,\n",
      "           5.5004e-03],\n",
      "          [8.6250e-02, 9.5966e-02, 9.5807e-02, 6.0269e-01, 1.5305e-04,\n",
      "           9.0781e-04, 1.4941e-04, 6.4116e-05, 1.0319e-04, 4.7075e-05,\n",
      "           1.1786e-01]],\n",
      "\n",
      "         [[1.3674e-03, 7.5639e-04, 7.1731e-04, 7.4899e-04, 1.3694e-02,\n",
      "           1.4394e-02, 1.0560e-01, 2.7270e-01, 1.7882e-01, 4.0958e-01,\n",
      "           1.6248e-03],\n",
      "          [2.4658e-02, 9.9393e-03, 1.2389e-02, 1.0344e-02, 3.6215e-01,\n",
      "           4.2989e-02, 1.5635e-01, 1.1539e-01, 7.0509e-02, 1.7084e-01,\n",
      "           2.4451e-02],\n",
      "          [2.1598e-04, 1.1942e-04, 1.4052e-04, 1.4711e-04, 3.5829e-01,\n",
      "           4.7412e-01, 1.3840e-01, 2.1115e-02, 5.5942e-03, 1.5877e-03,\n",
      "           2.6569e-04],\n",
      "          [3.0929e-02, 1.0578e-02, 8.2094e-03, 3.6704e-02, 7.0874e-01,\n",
      "           7.7011e-02, 2.5327e-02, 2.3929e-02, 2.1494e-02, 2.3347e-02,\n",
      "           3.3727e-02],\n",
      "          [1.2620e-02, 4.1768e-03, 1.2820e-02, 1.4687e-02, 6.4679e-01,\n",
      "           2.4881e-02, 8.2604e-02, 4.1242e-02, 5.5090e-02, 9.4099e-02,\n",
      "           1.0988e-02],\n",
      "          [7.5406e-02, 7.4420e-01, 1.8405e-02, 4.2707e-02, 4.0861e-03,\n",
      "           2.6068e-03, 5.3768e-03, 1.0639e-02, 1.1984e-02, 1.4652e-02,\n",
      "           6.9939e-02],\n",
      "          [6.0392e-02, 3.7005e-01, 6.6748e-02, 3.9587e-01, 7.1779e-03,\n",
      "           3.0849e-02, 3.5323e-03, 2.1509e-03, 3.1119e-03, 1.5847e-03,\n",
      "           5.8526e-02]],\n",
      "\n",
      "         [[6.1914e-04, 5.1572e-04, 1.0208e-04, 3.6718e-04, 4.2726e-02,\n",
      "           1.7168e-02, 3.4199e-01, 3.7539e-01, 1.4622e-01, 7.4273e-02,\n",
      "           6.3357e-04],\n",
      "          [5.7161e-05, 6.6234e-06, 3.5118e-05, 1.7652e-05, 1.9989e-02,\n",
      "           3.8852e-04, 6.6034e-01, 1.4828e-01, 1.2213e-01, 4.8704e-02,\n",
      "           4.7172e-05],\n",
      "          [7.1264e-04, 7.5033e-05, 2.7719e-04, 4.9727e-04, 4.2960e-01,\n",
      "           1.1244e-01, 3.5773e-01, 6.1942e-02, 3.0815e-02, 5.1873e-03,\n",
      "           7.1023e-04],\n",
      "          [8.2999e-03, 4.4688e-04, 2.7274e-03, 1.0476e-02, 4.0112e-01,\n",
      "           5.3557e-01, 2.2495e-02, 3.7412e-03, 4.9873e-03, 1.2114e-03,\n",
      "           8.9297e-03],\n",
      "          [1.2386e-01, 3.3863e-02, 9.0434e-02, 5.7255e-02, 3.7584e-01,\n",
      "           1.2757e-01, 4.8062e-02, 1.2595e-02, 1.4940e-02, 9.6308e-03,\n",
      "           1.0595e-01],\n",
      "          [1.6127e-01, 1.7385e-01, 1.0082e-01, 1.4378e-01, 4.0105e-02,\n",
      "           2.2487e-02, 9.3175e-02, 4.0765e-02, 4.2548e-02, 1.7513e-02,\n",
      "           1.6368e-01],\n",
      "          [1.0911e-01, 2.3120e-01, 4.1133e-02, 4.8528e-01, 1.9285e-03,\n",
      "           3.7287e-03, 1.0958e-03, 5.8007e-04, 2.8229e-04, 2.0184e-04,\n",
      "           1.2546e-01]],\n",
      "\n",
      "         [[8.7465e-04, 5.5213e-04, 5.3893e-04, 8.7702e-04, 1.4588e-01,\n",
      "           9.7495e-02, 2.3745e-01, 2.2946e-01, 1.9801e-01, 8.8074e-02,\n",
      "           7.8902e-04],\n",
      "          [2.0608e-04, 1.5240e-04, 1.6504e-04, 8.6065e-05, 2.2966e-02,\n",
      "           1.2485e-02, 2.4784e-01, 5.4725e-01, 1.0169e-01, 6.6983e-02,\n",
      "           1.8612e-04],\n",
      "          [1.4811e-03, 3.9096e-04, 8.8826e-04, 1.9774e-03, 5.8172e-01,\n",
      "           1.6528e-01, 1.8980e-01, 3.7363e-02, 1.3966e-02, 5.4836e-03,\n",
      "           1.6541e-03],\n",
      "          [9.7496e-04, 7.2677e-04, 2.2738e-04, 2.2672e-03, 2.3556e-01,\n",
      "           6.0748e-02, 5.3263e-01, 1.0118e-01, 5.4796e-02, 9.7754e-03,\n",
      "           1.1149e-03],\n",
      "          [9.1177e-03, 2.1350e-03, 1.3462e-02, 1.6876e-02, 5.3900e-01,\n",
      "           2.7096e-02, 3.2797e-01, 3.3092e-02, 1.5970e-02, 8.2831e-03,\n",
      "           6.9980e-03],\n",
      "          [2.2400e-01, 1.2511e-01, 1.7143e-01, 2.7496e-01, 6.1444e-03,\n",
      "           5.1560e-04, 5.6612e-03, 9.9144e-04, 9.4555e-04, 7.0092e-04,\n",
      "           1.8954e-01],\n",
      "          [1.1820e-01, 1.4658e-01, 1.7896e-01, 4.2000e-01, 2.2668e-04,\n",
      "           7.1108e-04, 1.6066e-04, 7.2808e-05, 1.2280e-04, 1.0791e-04,\n",
      "           1.3485e-01]]]]), tensor([[[[3.1463e-03, 4.8807e-03, 2.8232e-03, 1.9911e-03, 6.3559e-02,\n",
      "           2.8466e-02, 2.5192e-01, 3.6398e-01, 1.2386e-01, 1.5234e-01,\n",
      "           3.0337e-03],\n",
      "          [8.2186e-04, 1.5400e-03, 1.0818e-03, 4.8190e-04, 2.0015e-02,\n",
      "           2.5287e-03, 3.3684e-01, 3.3960e-01, 1.7474e-01, 1.2155e-01,\n",
      "           8.0376e-04],\n",
      "          [5.7737e-06, 1.1360e-06, 2.3544e-06, 8.1774e-06, 7.0152e-03,\n",
      "           9.8961e-01, 2.5704e-03, 5.8056e-04, 1.6876e-04, 3.3153e-05,\n",
      "           7.7870e-06],\n",
      "          [1.0475e-03, 1.3335e-04, 5.5654e-04, 7.9319e-03, 6.4271e-02,\n",
      "           8.9064e-01, 2.3618e-02, 7.4127e-03, 2.4690e-03, 7.2102e-04,\n",
      "           1.1976e-03],\n",
      "          [5.7931e-03, 2.6612e-03, 7.9289e-03, 5.4315e-03, 7.0144e-01,\n",
      "           1.0099e-01, 9.9837e-02, 4.2141e-02, 1.6560e-02, 1.1802e-02,\n",
      "           5.4134e-03],\n",
      "          [1.1752e-01, 5.0375e-02, 7.9916e-02, 4.9886e-02, 5.6788e-02,\n",
      "           5.4993e-02, 1.3001e-01, 1.9941e-01, 1.2893e-01, 2.9106e-02,\n",
      "           1.0306e-01],\n",
      "          [7.2511e-02, 5.3683e-02, 8.0276e-02, 7.0218e-01, 1.9445e-04,\n",
      "           2.5987e-03, 1.3162e-04, 1.0059e-04, 2.1158e-04, 1.4226e-04,\n",
      "           8.7970e-02],\n",
      "          [6.6297e-02, 2.0991e-02, 1.3751e-01, 6.3443e-02, 2.0937e-01,\n",
      "           5.1978e-04, 5.5869e-02, 2.7919e-02, 7.7906e-02, 2.9626e-01,\n",
      "           4.3916e-02]],\n",
      "\n",
      "         [[2.2069e-02, 3.4022e-02, 1.1153e-02, 1.0452e-02, 7.9929e-02,\n",
      "           1.4591e-02, 2.2788e-01, 2.8653e-01, 1.8589e-01, 1.0547e-01,\n",
      "           2.2008e-02],\n",
      "          [1.1993e-01, 4.0426e-02, 2.6992e-01, 9.1956e-02, 1.7506e-01,\n",
      "           2.6440e-02, 8.5125e-02, 2.1970e-02, 2.5174e-02, 2.5401e-02,\n",
      "           1.1860e-01],\n",
      "          [4.8049e-03, 2.6281e-03, 3.4883e-03, 4.2358e-03, 4.3830e-01,\n",
      "           3.5349e-01, 1.2749e-01, 3.3562e-02, 2.1178e-02, 5.5271e-03,\n",
      "           5.2930e-03],\n",
      "          [1.3612e-04, 7.5279e-05, 4.5362e-05, 5.3250e-04, 7.1381e-02,\n",
      "           9.1831e-01, 5.5835e-03, 2.4914e-03, 1.1060e-03, 2.0686e-04,\n",
      "           1.3436e-04],\n",
      "          [2.6580e-04, 2.9633e-04, 4.1325e-04, 5.8770e-04, 6.6235e-01,\n",
      "           3.2131e-01, 9.3847e-03, 2.7951e-03, 1.5609e-03, 7.9497e-04,\n",
      "           2.3878e-04],\n",
      "          [1.7867e-01, 1.4918e-01, 1.9889e-01, 2.7258e-01, 8.4932e-03,\n",
      "           6.3507e-04, 5.9682e-03, 5.7982e-03, 6.1746e-03, 4.5077e-03,\n",
      "           1.6912e-01],\n",
      "          [1.7155e-01, 1.0497e-01, 9.0988e-02, 4.6727e-01, 5.4778e-04,\n",
      "           3.5050e-04, 2.2927e-04, 1.6535e-04, 4.4670e-04, 4.2240e-04,\n",
      "           1.6305e-01],\n",
      "          [3.5663e-02, 6.3531e-02, 5.5634e-02, 2.4517e-02, 6.2214e-01,\n",
      "           5.8929e-02, 4.3428e-02, 1.3069e-02, 1.8218e-02, 3.7177e-02,\n",
      "           2.7694e-02]],\n",
      "\n",
      "         [[1.6908e-03, 1.4467e-03, 6.9412e-04, 1.5117e-03, 1.9361e-02,\n",
      "           9.4148e-03, 1.4902e-01, 2.9468e-01, 2.6430e-01, 2.5609e-01,\n",
      "           1.7935e-03],\n",
      "          [6.5195e-03, 1.3313e-03, 5.5494e-03, 2.5668e-03, 1.5586e-01,\n",
      "           6.4921e-02, 4.8035e-01, 8.8519e-02, 5.3265e-02, 1.3614e-01,\n",
      "           4.9750e-03],\n",
      "          [6.8641e-04, 5.2134e-04, 3.6230e-04, 3.6309e-04, 5.6362e-01,\n",
      "           3.4869e-01, 5.9199e-02, 1.9372e-02, 4.2511e-03, 2.1957e-03,\n",
      "           7.3896e-04],\n",
      "          [7.5856e-03, 1.2385e-03, 4.0042e-03, 4.1666e-02, 6.9289e-01,\n",
      "           2.3641e-01, 3.5231e-03, 2.4355e-03, 8.3233e-04, 4.9467e-04,\n",
      "           8.9219e-03],\n",
      "          [1.9306e-03, 1.4239e-03, 5.5764e-03, 1.3963e-03, 9.0617e-01,\n",
      "           5.8418e-03, 2.6882e-02, 2.2972e-02, 1.6731e-02, 9.4478e-03,\n",
      "           1.6314e-03],\n",
      "          [6.9263e-02, 2.6118e-02, 2.0953e-01, 1.7045e-02, 4.7654e-01,\n",
      "           1.0154e-02, 4.2040e-02, 2.2766e-02, 4.2650e-02, 2.0826e-02,\n",
      "           6.3066e-02],\n",
      "          [6.4414e-02, 1.3122e-02, 1.9929e-01, 6.4859e-01, 3.5370e-04,\n",
      "           1.3373e-03, 8.9793e-05, 2.8804e-05, 7.4523e-05, 9.7373e-05,\n",
      "           7.2608e-02],\n",
      "          [1.0802e-01, 1.4047e-02, 2.6477e-01, 3.7681e-02, 2.7722e-01,\n",
      "           9.8086e-03, 5.5314e-02, 2.7502e-02, 6.3341e-02, 6.3649e-02,\n",
      "           7.8652e-02]],\n",
      "\n",
      "         [[1.0087e-03, 1.0757e-03, 2.8140e-04, 6.5788e-04, 5.8029e-02,\n",
      "           4.1349e-02, 3.6735e-01, 3.1825e-01, 1.2605e-01, 8.4957e-02,\n",
      "           9.9056e-04],\n",
      "          [2.8110e-04, 8.4849e-05, 1.3130e-04, 6.6385e-05, 1.3857e-02,\n",
      "           5.0771e-03, 3.4643e-01, 3.5363e-01, 1.6866e-01, 1.1154e-01,\n",
      "           2.4698e-04],\n",
      "          [6.4882e-03, 1.2730e-03, 2.3356e-03, 8.1064e-03, 1.5827e-01,\n",
      "           5.3585e-01, 1.5541e-01, 9.6808e-02, 1.9414e-02, 9.1355e-03,\n",
      "           6.9080e-03],\n",
      "          [1.8458e-04, 1.6526e-05, 2.7456e-05, 2.0490e-04, 2.7310e-02,\n",
      "           9.6750e-01, 3.5618e-03, 7.7272e-04, 1.5029e-04, 7.4872e-05,\n",
      "           1.9256e-04],\n",
      "          [1.9754e-02, 2.8845e-03, 5.2545e-03, 1.0331e-02, 2.6157e-01,\n",
      "           2.2916e-01, 2.0804e-01, 1.2392e-01, 5.4515e-02, 6.5191e-02,\n",
      "           1.9383e-02],\n",
      "          [1.0859e-01, 6.6936e-01, 3.8471e-02, 8.2930e-02, 1.0743e-03,\n",
      "           4.8902e-04, 3.0292e-04, 1.4678e-04, 9.6933e-05, 1.9486e-04,\n",
      "           9.8344e-02],\n",
      "          [1.1221e-01, 9.0406e-02, 2.0647e-01, 4.6566e-01, 6.3398e-05,\n",
      "           1.2465e-04, 1.9616e-05, 4.4517e-06, 8.1204e-06, 1.3798e-05,\n",
      "           1.2501e-01],\n",
      "          [1.4553e-03, 6.1252e-04, 6.6977e-04, 5.1395e-04, 1.9645e-02,\n",
      "           6.3985e-04, 1.3459e-01, 1.6571e-01, 2.8663e-01, 3.8839e-01,\n",
      "           1.1487e-03]],\n",
      "\n",
      "         [[4.5568e-03, 3.0560e-03, 1.9296e-03, 1.4549e-03, 5.0402e-02,\n",
      "           1.7042e-02, 1.5789e-01, 4.3275e-01, 1.6861e-01, 1.5809e-01,\n",
      "           4.2139e-03],\n",
      "          [9.0610e-02, 4.7629e-02, 6.7512e-01, 9.9980e-02, 1.7882e-03,\n",
      "           5.7073e-05, 6.5269e-04, 5.3802e-04, 9.5373e-04, 4.7758e-03,\n",
      "           7.7896e-02],\n",
      "          [1.6019e-04, 3.0937e-04, 4.9784e-05, 8.5614e-05, 4.1716e-01,\n",
      "           1.4661e-01, 3.3530e-01, 7.7166e-02, 1.4857e-02, 8.1553e-03,\n",
      "           1.4486e-04],\n",
      "          [6.5427e-04, 5.2038e-04, 3.6886e-04, 7.4865e-04, 2.9515e-01,\n",
      "           6.8199e-01, 1.6670e-02, 2.1794e-03, 7.8078e-04, 1.8449e-04,\n",
      "           7.5471e-04],\n",
      "          [6.6102e-04, 1.9571e-04, 5.3970e-04, 3.3842e-04, 5.8702e-01,\n",
      "           1.7200e-02, 3.2729e-01, 3.4570e-02, 2.0435e-02, 1.1193e-02,\n",
      "           5.5140e-04],\n",
      "          [7.0721e-03, 7.3487e-03, 6.9010e-03, 3.2509e-03, 1.8809e-01,\n",
      "           1.5186e-02, 4.9561e-01, 1.1271e-01, 1.0342e-01, 5.4925e-02,\n",
      "           5.5004e-03],\n",
      "          [8.6250e-02, 9.5966e-02, 9.5807e-02, 6.0269e-01, 1.5305e-04,\n",
      "           9.0781e-04, 1.4941e-04, 6.4116e-05, 1.0319e-04, 4.7075e-05,\n",
      "           1.1786e-01],\n",
      "          [3.7081e-02, 3.1006e-02, 8.6804e-02, 1.8811e-02, 1.3799e-01,\n",
      "           3.6791e-03, 1.2894e-01, 1.2121e-01, 1.1868e-01, 2.9048e-01,\n",
      "           2.5325e-02]],\n",
      "\n",
      "         [[1.3674e-03, 7.5639e-04, 7.1731e-04, 7.4899e-04, 1.3694e-02,\n",
      "           1.4394e-02, 1.0560e-01, 2.7270e-01, 1.7882e-01, 4.0958e-01,\n",
      "           1.6248e-03],\n",
      "          [2.4658e-02, 9.9393e-03, 1.2389e-02, 1.0344e-02, 3.6215e-01,\n",
      "           4.2989e-02, 1.5635e-01, 1.1539e-01, 7.0509e-02, 1.7084e-01,\n",
      "           2.4451e-02],\n",
      "          [2.1598e-04, 1.1942e-04, 1.4052e-04, 1.4711e-04, 3.5829e-01,\n",
      "           4.7412e-01, 1.3840e-01, 2.1115e-02, 5.5942e-03, 1.5877e-03,\n",
      "           2.6569e-04],\n",
      "          [3.0929e-02, 1.0578e-02, 8.2094e-03, 3.6704e-02, 7.0874e-01,\n",
      "           7.7011e-02, 2.5327e-02, 2.3929e-02, 2.1494e-02, 2.3347e-02,\n",
      "           3.3727e-02],\n",
      "          [1.2620e-02, 4.1768e-03, 1.2820e-02, 1.4687e-02, 6.4679e-01,\n",
      "           2.4881e-02, 8.2604e-02, 4.1242e-02, 5.5090e-02, 9.4099e-02,\n",
      "           1.0988e-02],\n",
      "          [7.5406e-02, 7.4420e-01, 1.8405e-02, 4.2707e-02, 4.0861e-03,\n",
      "           2.6068e-03, 5.3768e-03, 1.0639e-02, 1.1984e-02, 1.4652e-02,\n",
      "           6.9939e-02],\n",
      "          [6.0392e-02, 3.7005e-01, 6.6748e-02, 3.9587e-01, 7.1779e-03,\n",
      "           3.0849e-02, 3.5323e-03, 2.1509e-03, 3.1119e-03, 1.5847e-03,\n",
      "           5.8526e-02],\n",
      "          [1.2642e-01, 3.7359e-02, 3.0708e-01, 1.7994e-01, 8.6817e-02,\n",
      "           1.5429e-02, 3.7564e-02, 1.6565e-02, 3.2463e-02, 6.3272e-02,\n",
      "           9.7092e-02]],\n",
      "\n",
      "         [[6.1914e-04, 5.1572e-04, 1.0208e-04, 3.6718e-04, 4.2726e-02,\n",
      "           1.7168e-02, 3.4199e-01, 3.7539e-01, 1.4622e-01, 7.4273e-02,\n",
      "           6.3357e-04],\n",
      "          [5.7161e-05, 6.6234e-06, 3.5118e-05, 1.7652e-05, 1.9989e-02,\n",
      "           3.8852e-04, 6.6034e-01, 1.4828e-01, 1.2213e-01, 4.8704e-02,\n",
      "           4.7172e-05],\n",
      "          [7.1264e-04, 7.5033e-05, 2.7719e-04, 4.9727e-04, 4.2960e-01,\n",
      "           1.1244e-01, 3.5773e-01, 6.1942e-02, 3.0815e-02, 5.1873e-03,\n",
      "           7.1023e-04],\n",
      "          [8.2999e-03, 4.4688e-04, 2.7274e-03, 1.0476e-02, 4.0112e-01,\n",
      "           5.3557e-01, 2.2495e-02, 3.7412e-03, 4.9873e-03, 1.2114e-03,\n",
      "           8.9297e-03],\n",
      "          [1.2386e-01, 3.3863e-02, 9.0434e-02, 5.7255e-02, 3.7584e-01,\n",
      "           1.2757e-01, 4.8062e-02, 1.2595e-02, 1.4940e-02, 9.6308e-03,\n",
      "           1.0595e-01],\n",
      "          [1.6127e-01, 1.7385e-01, 1.0082e-01, 1.4378e-01, 4.0105e-02,\n",
      "           2.2487e-02, 9.3175e-02, 4.0765e-02, 4.2548e-02, 1.7513e-02,\n",
      "           1.6368e-01],\n",
      "          [1.0911e-01, 2.3120e-01, 4.1133e-02, 4.8528e-01, 1.9285e-03,\n",
      "           3.7287e-03, 1.0958e-03, 5.8007e-04, 2.8229e-04, 2.0184e-04,\n",
      "           1.2546e-01],\n",
      "          [3.8329e-02, 1.5435e-02, 5.2211e-02, 3.3439e-02, 6.5929e-01,\n",
      "           1.7042e-02, 7.9577e-02, 3.5777e-02, 1.1620e-02, 3.0323e-02,\n",
      "           2.6957e-02]],\n",
      "\n",
      "         [[8.7465e-04, 5.5213e-04, 5.3893e-04, 8.7702e-04, 1.4588e-01,\n",
      "           9.7495e-02, 2.3745e-01, 2.2946e-01, 1.9801e-01, 8.8074e-02,\n",
      "           7.8902e-04],\n",
      "          [2.0608e-04, 1.5240e-04, 1.6504e-04, 8.6065e-05, 2.2966e-02,\n",
      "           1.2485e-02, 2.4784e-01, 5.4725e-01, 1.0169e-01, 6.6983e-02,\n",
      "           1.8612e-04],\n",
      "          [1.4811e-03, 3.9096e-04, 8.8826e-04, 1.9774e-03, 5.8172e-01,\n",
      "           1.6528e-01, 1.8980e-01, 3.7363e-02, 1.3966e-02, 5.4836e-03,\n",
      "           1.6541e-03],\n",
      "          [9.7496e-04, 7.2677e-04, 2.2738e-04, 2.2672e-03, 2.3556e-01,\n",
      "           6.0748e-02, 5.3263e-01, 1.0118e-01, 5.4796e-02, 9.7754e-03,\n",
      "           1.1149e-03],\n",
      "          [9.1177e-03, 2.1350e-03, 1.3462e-02, 1.6876e-02, 5.3900e-01,\n",
      "           2.7096e-02, 3.2797e-01, 3.3092e-02, 1.5970e-02, 8.2831e-03,\n",
      "           6.9980e-03],\n",
      "          [2.2400e-01, 1.2511e-01, 1.7143e-01, 2.7496e-01, 6.1444e-03,\n",
      "           5.1560e-04, 5.6612e-03, 9.9144e-04, 9.4555e-04, 7.0092e-04,\n",
      "           1.8954e-01],\n",
      "          [1.1820e-01, 1.4658e-01, 1.7896e-01, 4.2000e-01, 2.2668e-04,\n",
      "           7.1108e-04, 1.6066e-04, 7.2808e-05, 1.2280e-04, 1.0791e-04,\n",
      "           1.3485e-01],\n",
      "          [2.5305e-03, 2.3044e-03, 7.6127e-03, 1.2404e-03, 1.5244e-01,\n",
      "           2.9261e-03, 8.6077e-02, 2.4420e-01, 1.4468e-01, 3.5414e-01,\n",
      "           1.8488e-03]]]]), tensor([[[[3.1463e-03, 4.8807e-03, 2.8232e-03, 1.9911e-03, 6.3559e-02,\n",
      "           2.8466e-02, 2.5192e-01, 3.6398e-01, 1.2386e-01, 1.5234e-01,\n",
      "           3.0337e-03],\n",
      "          [8.2186e-04, 1.5400e-03, 1.0818e-03, 4.8190e-04, 2.0015e-02,\n",
      "           2.5287e-03, 3.3684e-01, 3.3960e-01, 1.7474e-01, 1.2155e-01,\n",
      "           8.0376e-04],\n",
      "          [5.7737e-06, 1.1360e-06, 2.3544e-06, 8.1774e-06, 7.0152e-03,\n",
      "           9.8961e-01, 2.5704e-03, 5.8056e-04, 1.6876e-04, 3.3153e-05,\n",
      "           7.7870e-06],\n",
      "          [1.0475e-03, 1.3335e-04, 5.5654e-04, 7.9319e-03, 6.4271e-02,\n",
      "           8.9064e-01, 2.3618e-02, 7.4127e-03, 2.4690e-03, 7.2102e-04,\n",
      "           1.1976e-03],\n",
      "          [5.7931e-03, 2.6612e-03, 7.9289e-03, 5.4315e-03, 7.0144e-01,\n",
      "           1.0099e-01, 9.9837e-02, 4.2141e-02, 1.6560e-02, 1.1802e-02,\n",
      "           5.4134e-03],\n",
      "          [1.1752e-01, 5.0375e-02, 7.9916e-02, 4.9886e-02, 5.6788e-02,\n",
      "           5.4993e-02, 1.3001e-01, 1.9941e-01, 1.2893e-01, 2.9106e-02,\n",
      "           1.0306e-01],\n",
      "          [7.2511e-02, 5.3683e-02, 8.0276e-02, 7.0218e-01, 1.9445e-04,\n",
      "           2.5987e-03, 1.3162e-04, 1.0059e-04, 2.1158e-04, 1.4226e-04,\n",
      "           8.7970e-02],\n",
      "          [6.6297e-02, 2.0991e-02, 1.3751e-01, 6.3443e-02, 2.0937e-01,\n",
      "           5.1978e-04, 5.5869e-02, 2.7919e-02, 7.7906e-02, 2.9626e-01,\n",
      "           4.3916e-02],\n",
      "          [1.5486e-02, 7.8300e-03, 1.0002e-02, 9.1872e-03, 5.6243e-01,\n",
      "           3.6388e-02, 1.2224e-01, 3.9217e-02, 4.8265e-02, 1.3394e-01,\n",
      "           1.5007e-02]],\n",
      "\n",
      "         [[2.2069e-02, 3.4022e-02, 1.1153e-02, 1.0452e-02, 7.9929e-02,\n",
      "           1.4591e-02, 2.2788e-01, 2.8653e-01, 1.8589e-01, 1.0547e-01,\n",
      "           2.2008e-02],\n",
      "          [1.1993e-01, 4.0426e-02, 2.6992e-01, 9.1956e-02, 1.7506e-01,\n",
      "           2.6440e-02, 8.5125e-02, 2.1970e-02, 2.5174e-02, 2.5401e-02,\n",
      "           1.1860e-01],\n",
      "          [4.8049e-03, 2.6281e-03, 3.4883e-03, 4.2358e-03, 4.3830e-01,\n",
      "           3.5349e-01, 1.2749e-01, 3.3562e-02, 2.1178e-02, 5.5271e-03,\n",
      "           5.2930e-03],\n",
      "          [1.3612e-04, 7.5279e-05, 4.5362e-05, 5.3250e-04, 7.1381e-02,\n",
      "           9.1831e-01, 5.5835e-03, 2.4914e-03, 1.1060e-03, 2.0686e-04,\n",
      "           1.3436e-04],\n",
      "          [2.6580e-04, 2.9633e-04, 4.1325e-04, 5.8770e-04, 6.6235e-01,\n",
      "           3.2131e-01, 9.3847e-03, 2.7951e-03, 1.5609e-03, 7.9497e-04,\n",
      "           2.3878e-04],\n",
      "          [1.7867e-01, 1.4918e-01, 1.9889e-01, 2.7258e-01, 8.4932e-03,\n",
      "           6.3507e-04, 5.9682e-03, 5.7982e-03, 6.1746e-03, 4.5077e-03,\n",
      "           1.6912e-01],\n",
      "          [1.7155e-01, 1.0497e-01, 9.0988e-02, 4.6727e-01, 5.4777e-04,\n",
      "           3.5049e-04, 2.2927e-04, 1.6535e-04, 4.4670e-04, 4.2240e-04,\n",
      "           1.6305e-01],\n",
      "          [3.5663e-02, 6.3531e-02, 5.5634e-02, 2.4517e-02, 6.2214e-01,\n",
      "           5.8929e-02, 4.3428e-02, 1.3069e-02, 1.8218e-02, 3.7177e-02,\n",
      "           2.7694e-02],\n",
      "          [1.7836e-01, 1.2007e-01, 2.9690e-01, 1.7050e-01, 3.0041e-02,\n",
      "           2.7006e-02, 3.5990e-03, 1.7455e-03, 4.9633e-03, 1.3780e-02,\n",
      "           1.5303e-01]],\n",
      "\n",
      "         [[1.6908e-03, 1.4467e-03, 6.9412e-04, 1.5117e-03, 1.9361e-02,\n",
      "           9.4148e-03, 1.4902e-01, 2.9468e-01, 2.6430e-01, 2.5609e-01,\n",
      "           1.7935e-03],\n",
      "          [6.5195e-03, 1.3313e-03, 5.5494e-03, 2.5668e-03, 1.5586e-01,\n",
      "           6.4921e-02, 4.8035e-01, 8.8519e-02, 5.3265e-02, 1.3614e-01,\n",
      "           4.9750e-03],\n",
      "          [6.8641e-04, 5.2134e-04, 3.6230e-04, 3.6309e-04, 5.6362e-01,\n",
      "           3.4869e-01, 5.9199e-02, 1.9372e-02, 4.2511e-03, 2.1957e-03,\n",
      "           7.3896e-04],\n",
      "          [7.5856e-03, 1.2385e-03, 4.0042e-03, 4.1666e-02, 6.9289e-01,\n",
      "           2.3641e-01, 3.5231e-03, 2.4355e-03, 8.3233e-04, 4.9467e-04,\n",
      "           8.9219e-03],\n",
      "          [1.9306e-03, 1.4239e-03, 5.5764e-03, 1.3963e-03, 9.0617e-01,\n",
      "           5.8418e-03, 2.6882e-02, 2.2972e-02, 1.6731e-02, 9.4478e-03,\n",
      "           1.6314e-03],\n",
      "          [6.9263e-02, 2.6118e-02, 2.0953e-01, 1.7045e-02, 4.7654e-01,\n",
      "           1.0154e-02, 4.2040e-02, 2.2766e-02, 4.2650e-02, 2.0826e-02,\n",
      "           6.3066e-02],\n",
      "          [6.4414e-02, 1.3122e-02, 1.9929e-01, 6.4859e-01, 3.5370e-04,\n",
      "           1.3373e-03, 8.9793e-05, 2.8804e-05, 7.4523e-05, 9.7373e-05,\n",
      "           7.2608e-02],\n",
      "          [1.0802e-01, 1.4047e-02, 2.6476e-01, 3.7681e-02, 2.7722e-01,\n",
      "           9.8086e-03, 5.5314e-02, 2.7502e-02, 6.3341e-02, 6.3649e-02,\n",
      "           7.8652e-02],\n",
      "          [1.9455e-01, 2.4499e-01, 1.0271e-01, 1.1086e-01, 5.5137e-02,\n",
      "           8.7965e-02, 1.3079e-02, 4.6430e-03, 4.8357e-03, 4.6516e-03,\n",
      "           1.7658e-01]],\n",
      "\n",
      "         [[1.0087e-03, 1.0757e-03, 2.8140e-04, 6.5788e-04, 5.8029e-02,\n",
      "           4.1349e-02, 3.6735e-01, 3.1825e-01, 1.2605e-01, 8.4957e-02,\n",
      "           9.9056e-04],\n",
      "          [2.8110e-04, 8.4849e-05, 1.3130e-04, 6.6385e-05, 1.3857e-02,\n",
      "           5.0771e-03, 3.4643e-01, 3.5363e-01, 1.6866e-01, 1.1154e-01,\n",
      "           2.4698e-04],\n",
      "          [6.4882e-03, 1.2730e-03, 2.3356e-03, 8.1065e-03, 1.5827e-01,\n",
      "           5.3585e-01, 1.5541e-01, 9.6808e-02, 1.9414e-02, 9.1355e-03,\n",
      "           6.9080e-03],\n",
      "          [1.8458e-04, 1.6526e-05, 2.7456e-05, 2.0490e-04, 2.7310e-02,\n",
      "           9.6750e-01, 3.5618e-03, 7.7272e-04, 1.5029e-04, 7.4872e-05,\n",
      "           1.9256e-04],\n",
      "          [1.9754e-02, 2.8845e-03, 5.2545e-03, 1.0331e-02, 2.6157e-01,\n",
      "           2.2916e-01, 2.0804e-01, 1.2392e-01, 5.4515e-02, 6.5191e-02,\n",
      "           1.9383e-02],\n",
      "          [1.0859e-01, 6.6936e-01, 3.8471e-02, 8.2930e-02, 1.0743e-03,\n",
      "           4.8902e-04, 3.0292e-04, 1.4678e-04, 9.6933e-05, 1.9486e-04,\n",
      "           9.8344e-02],\n",
      "          [1.1221e-01, 9.0406e-02, 2.0647e-01, 4.6566e-01, 6.3398e-05,\n",
      "           1.2465e-04, 1.9616e-05, 4.4517e-06, 8.1204e-06, 1.3797e-05,\n",
      "           1.2501e-01],\n",
      "          [1.4553e-03, 6.1252e-04, 6.6976e-04, 5.1395e-04, 1.9645e-02,\n",
      "           6.3985e-04, 1.3459e-01, 1.6571e-01, 2.8663e-01, 3.8839e-01,\n",
      "           1.1487e-03],\n",
      "          [1.6881e-01, 2.2187e-02, 2.3702e-01, 8.0390e-02, 8.3711e-02,\n",
      "           1.8378e-01, 1.8165e-02, 8.9001e-03, 1.8277e-02, 3.2749e-02,\n",
      "           1.4601e-01]],\n",
      "\n",
      "         [[4.5568e-03, 3.0560e-03, 1.9296e-03, 1.4549e-03, 5.0402e-02,\n",
      "           1.7042e-02, 1.5789e-01, 4.3275e-01, 1.6861e-01, 1.5809e-01,\n",
      "           4.2139e-03],\n",
      "          [9.0610e-02, 4.7629e-02, 6.7512e-01, 9.9980e-02, 1.7882e-03,\n",
      "           5.7073e-05, 6.5269e-04, 5.3802e-04, 9.5373e-04, 4.7758e-03,\n",
      "           7.7896e-02],\n",
      "          [1.6019e-04, 3.0937e-04, 4.9784e-05, 8.5614e-05, 4.1716e-01,\n",
      "           1.4661e-01, 3.3530e-01, 7.7165e-02, 1.4857e-02, 8.1552e-03,\n",
      "           1.4486e-04],\n",
      "          [6.5427e-04, 5.2038e-04, 3.6886e-04, 7.4865e-04, 2.9515e-01,\n",
      "           6.8199e-01, 1.6670e-02, 2.1794e-03, 7.8078e-04, 1.8449e-04,\n",
      "           7.5471e-04],\n",
      "          [6.6102e-04, 1.9571e-04, 5.3970e-04, 3.3842e-04, 5.8702e-01,\n",
      "           1.7200e-02, 3.2729e-01, 3.4570e-02, 2.0435e-02, 1.1193e-02,\n",
      "           5.5140e-04],\n",
      "          [7.0721e-03, 7.3487e-03, 6.9010e-03, 3.2509e-03, 1.8809e-01,\n",
      "           1.5186e-02, 4.9561e-01, 1.1271e-01, 1.0342e-01, 5.4925e-02,\n",
      "           5.5004e-03],\n",
      "          [8.6250e-02, 9.5966e-02, 9.5807e-02, 6.0269e-01, 1.5305e-04,\n",
      "           9.0781e-04, 1.4941e-04, 6.4116e-05, 1.0319e-04, 4.7075e-05,\n",
      "           1.1786e-01],\n",
      "          [3.7081e-02, 3.1006e-02, 8.6804e-02, 1.8811e-02, 1.3799e-01,\n",
      "           3.6791e-03, 1.2894e-01, 1.2121e-01, 1.1868e-01, 2.9048e-01,\n",
      "           2.5325e-02],\n",
      "          [1.5333e-01, 6.0883e-02, 1.9886e-01, 6.2940e-02, 2.0146e-01,\n",
      "           5.8266e-02, 4.8638e-02, 1.5784e-02, 1.8753e-02, 4.0946e-02,\n",
      "           1.4014e-01]],\n",
      "\n",
      "         [[1.3674e-03, 7.5639e-04, 7.1731e-04, 7.4899e-04, 1.3694e-02,\n",
      "           1.4394e-02, 1.0560e-01, 2.7270e-01, 1.7882e-01, 4.0958e-01,\n",
      "           1.6248e-03],\n",
      "          [2.4658e-02, 9.9393e-03, 1.2389e-02, 1.0344e-02, 3.6215e-01,\n",
      "           4.2989e-02, 1.5635e-01, 1.1539e-01, 7.0509e-02, 1.7084e-01,\n",
      "           2.4451e-02],\n",
      "          [2.1598e-04, 1.1942e-04, 1.4052e-04, 1.4711e-04, 3.5829e-01,\n",
      "           4.7412e-01, 1.3840e-01, 2.1115e-02, 5.5942e-03, 1.5877e-03,\n",
      "           2.6569e-04],\n",
      "          [3.0929e-02, 1.0578e-02, 8.2094e-03, 3.6704e-02, 7.0874e-01,\n",
      "           7.7011e-02, 2.5327e-02, 2.3929e-02, 2.1494e-02, 2.3347e-02,\n",
      "           3.3727e-02],\n",
      "          [1.2620e-02, 4.1768e-03, 1.2820e-02, 1.4687e-02, 6.4679e-01,\n",
      "           2.4881e-02, 8.2604e-02, 4.1242e-02, 5.5090e-02, 9.4099e-02,\n",
      "           1.0988e-02],\n",
      "          [7.5406e-02, 7.4420e-01, 1.8405e-02, 4.2707e-02, 4.0861e-03,\n",
      "           2.6068e-03, 5.3768e-03, 1.0639e-02, 1.1984e-02, 1.4652e-02,\n",
      "           6.9939e-02],\n",
      "          [6.0392e-02, 3.7005e-01, 6.6748e-02, 3.9587e-01, 7.1779e-03,\n",
      "           3.0849e-02, 3.5323e-03, 2.1509e-03, 3.1119e-03, 1.5847e-03,\n",
      "           5.8526e-02],\n",
      "          [1.2642e-01, 3.7359e-02, 3.0708e-01, 1.7994e-01, 8.6817e-02,\n",
      "           1.5429e-02, 3.7564e-02, 1.6565e-02, 3.2463e-02, 6.3272e-02,\n",
      "           9.7092e-02],\n",
      "          [9.6826e-02, 3.7251e-02, 1.5127e-01, 8.6791e-02, 2.8930e-01,\n",
      "           1.4442e-01, 5.7215e-02, 1.8889e-02, 1.2859e-02, 1.3751e-02,\n",
      "           9.1429e-02]],\n",
      "\n",
      "         [[6.1914e-04, 5.1572e-04, 1.0208e-04, 3.6718e-04, 4.2726e-02,\n",
      "           1.7168e-02, 3.4199e-01, 3.7539e-01, 1.4622e-01, 7.4273e-02,\n",
      "           6.3357e-04],\n",
      "          [5.7161e-05, 6.6234e-06, 3.5118e-05, 1.7652e-05, 1.9989e-02,\n",
      "           3.8852e-04, 6.6034e-01, 1.4828e-01, 1.2213e-01, 4.8704e-02,\n",
      "           4.7172e-05],\n",
      "          [7.1264e-04, 7.5033e-05, 2.7719e-04, 4.9727e-04, 4.2960e-01,\n",
      "           1.1244e-01, 3.5773e-01, 6.1942e-02, 3.0815e-02, 5.1873e-03,\n",
      "           7.1023e-04],\n",
      "          [8.2999e-03, 4.4688e-04, 2.7274e-03, 1.0476e-02, 4.0112e-01,\n",
      "           5.3557e-01, 2.2495e-02, 3.7412e-03, 4.9873e-03, 1.2114e-03,\n",
      "           8.9297e-03],\n",
      "          [1.2386e-01, 3.3863e-02, 9.0434e-02, 5.7255e-02, 3.7584e-01,\n",
      "           1.2757e-01, 4.8062e-02, 1.2595e-02, 1.4940e-02, 9.6308e-03,\n",
      "           1.0595e-01],\n",
      "          [1.6127e-01, 1.7385e-01, 1.0082e-01, 1.4378e-01, 4.0105e-02,\n",
      "           2.2487e-02, 9.3175e-02, 4.0765e-02, 4.2548e-02, 1.7513e-02,\n",
      "           1.6368e-01],\n",
      "          [1.0911e-01, 2.3120e-01, 4.1133e-02, 4.8528e-01, 1.9285e-03,\n",
      "           3.7287e-03, 1.0958e-03, 5.8007e-04, 2.8229e-04, 2.0184e-04,\n",
      "           1.2546e-01],\n",
      "          [3.8329e-02, 1.5435e-02, 5.2211e-02, 3.3439e-02, 6.5929e-01,\n",
      "           1.7042e-02, 7.9577e-02, 3.5777e-02, 1.1620e-02, 3.0323e-02,\n",
      "           2.6957e-02],\n",
      "          [1.3472e-01, 2.2199e-02, 1.5019e-01, 3.7326e-02, 3.7377e-01,\n",
      "           9.1122e-02, 2.1180e-02, 1.0075e-02, 1.1341e-02, 2.5766e-02,\n",
      "           1.2231e-01]],\n",
      "\n",
      "         [[8.7465e-04, 5.5213e-04, 5.3893e-04, 8.7702e-04, 1.4588e-01,\n",
      "           9.7495e-02, 2.3745e-01, 2.2946e-01, 1.9801e-01, 8.8074e-02,\n",
      "           7.8902e-04],\n",
      "          [2.0608e-04, 1.5240e-04, 1.6504e-04, 8.6065e-05, 2.2966e-02,\n",
      "           1.2485e-02, 2.4784e-01, 5.4725e-01, 1.0169e-01, 6.6983e-02,\n",
      "           1.8612e-04],\n",
      "          [1.4811e-03, 3.9096e-04, 8.8826e-04, 1.9774e-03, 5.8172e-01,\n",
      "           1.6528e-01, 1.8980e-01, 3.7363e-02, 1.3966e-02, 5.4836e-03,\n",
      "           1.6541e-03],\n",
      "          [9.7496e-04, 7.2677e-04, 2.2738e-04, 2.2672e-03, 2.3556e-01,\n",
      "           6.0748e-02, 5.3263e-01, 1.0118e-01, 5.4796e-02, 9.7754e-03,\n",
      "           1.1149e-03],\n",
      "          [9.1177e-03, 2.1350e-03, 1.3462e-02, 1.6876e-02, 5.3900e-01,\n",
      "           2.7096e-02, 3.2797e-01, 3.3092e-02, 1.5970e-02, 8.2831e-03,\n",
      "           6.9980e-03],\n",
      "          [2.2400e-01, 1.2511e-01, 1.7143e-01, 2.7496e-01, 6.1444e-03,\n",
      "           5.1560e-04, 5.6612e-03, 9.9144e-04, 9.4555e-04, 7.0092e-04,\n",
      "           1.8954e-01],\n",
      "          [1.1820e-01, 1.4658e-01, 1.7896e-01, 4.2000e-01, 2.2668e-04,\n",
      "           7.1108e-04, 1.6066e-04, 7.2808e-05, 1.2280e-04, 1.0791e-04,\n",
      "           1.3485e-01],\n",
      "          [2.5305e-03, 2.3044e-03, 7.6127e-03, 1.2404e-03, 1.5244e-01,\n",
      "           2.9261e-03, 8.6077e-02, 2.4420e-01, 1.4468e-01, 3.5414e-01,\n",
      "           1.8488e-03],\n",
      "          [3.9342e-02, 2.5185e-02, 4.2794e-02, 3.2839e-02, 3.1945e-01,\n",
      "           6.9342e-02, 1.3539e-01, 9.5106e-02, 8.7208e-02, 1.1718e-01,\n",
      "           3.6166e-02]]]])]), (['<sos>', 'i', 'got', 'here', 'this', 'morning', '.', '<eos>'], [tensor([[[[1.7242e-01, 1.9567e-01, 1.3118e-01, 5.5230e-02, 2.1469e-01,\n",
      "           1.7080e-02, 8.6986e-03, 1.3592e-02, 1.5871e-02, 1.8958e-02,\n",
      "           1.5661e-01]],\n",
      "\n",
      "         [[2.8579e-03, 9.4333e-01, 3.4118e-02, 1.5241e-03, 1.7884e-03,\n",
      "           4.2228e-03, 4.2758e-04, 1.5526e-03, 3.1248e-03, 4.3409e-03,\n",
      "           2.7127e-03]],\n",
      "\n",
      "         [[5.2820e-03, 4.0367e-01, 3.9031e-01, 7.5593e-04, 8.2816e-04,\n",
      "           5.4032e-03, 1.1681e-02, 2.7376e-02, 4.6632e-02, 1.0285e-01,\n",
      "           5.2103e-03]],\n",
      "\n",
      "         [[2.0870e-02, 7.0276e-01, 1.1731e-01, 2.2768e-03, 5.0965e-03,\n",
      "           6.8304e-03, 1.4886e-02, 3.0109e-02, 2.4989e-02, 5.4441e-02,\n",
      "           2.0433e-02]],\n",
      "\n",
      "         [[1.6681e-02, 8.8849e-01, 4.6502e-02, 3.8100e-03, 5.1033e-03,\n",
      "           2.0054e-03, 1.5315e-03, 4.3113e-03, 4.4986e-03, 1.1215e-02,\n",
      "           1.5850e-02]],\n",
      "\n",
      "         [[6.3214e-02, 2.1686e-01, 1.8060e-01, 4.5005e-03, 7.2806e-03,\n",
      "           7.9482e-02, 1.1348e-01, 4.9919e-02, 8.6092e-02, 1.3650e-01,\n",
      "           6.2076e-02]],\n",
      "\n",
      "         [[5.0119e-03, 9.5917e-01, 2.0540e-02, 2.8189e-04, 1.5470e-03,\n",
      "           5.6593e-04, 4.3391e-04, 1.8978e-03, 2.6560e-03, 3.0168e-03,\n",
      "           4.8779e-03]],\n",
      "\n",
      "         [[2.3258e-02, 4.8514e-01, 1.6443e-01, 7.9946e-03, 8.8730e-03,\n",
      "           3.5271e-02, 1.7335e-02, 5.8945e-02, 6.6072e-02, 1.1069e-01,\n",
      "           2.1991e-02]]]]), tensor([[[[1.7242e-01, 1.9567e-01, 1.3118e-01, 5.5230e-02, 2.1469e-01,\n",
      "           1.7079e-02, 8.6986e-03, 1.3592e-02, 1.5871e-02, 1.8958e-02,\n",
      "           1.5661e-01],\n",
      "          [2.8835e-02, 6.9989e-03, 1.8119e-02, 4.2894e-03, 3.0078e-03,\n",
      "           1.0883e-01, 3.4729e-01, 2.8702e-01, 1.1803e-01, 4.3203e-02,\n",
      "           3.4375e-02]],\n",
      "\n",
      "         [[2.8579e-03, 9.4333e-01, 3.4118e-02, 1.5241e-03, 1.7884e-03,\n",
      "           4.2228e-03, 4.2758e-04, 1.5526e-03, 3.1248e-03, 4.3408e-03,\n",
      "           2.7127e-03],\n",
      "          [5.1802e-02, 6.6448e-03, 1.8516e-02, 7.3295e-03, 3.5997e-03,\n",
      "           1.8824e-02, 7.0132e-01, 1.0653e-01, 1.4497e-02, 1.0371e-02,\n",
      "           6.0571e-02]],\n",
      "\n",
      "         [[5.2820e-03, 4.0367e-01, 3.9031e-01, 7.5593e-04, 8.2816e-04,\n",
      "           5.4032e-03, 1.1681e-02, 2.7376e-02, 4.6632e-02, 1.0285e-01,\n",
      "           5.2103e-03],\n",
      "          [3.9056e-02, 4.4310e-03, 3.5978e-02, 7.3027e-03, 1.3327e-03,\n",
      "           1.2512e-01, 4.7356e-01, 1.6985e-01, 7.0551e-02, 2.8253e-02,\n",
      "           4.4556e-02]],\n",
      "\n",
      "         [[2.0870e-02, 7.0276e-01, 1.1731e-01, 2.2768e-03, 5.0965e-03,\n",
      "           6.8304e-03, 1.4886e-02, 3.0109e-02, 2.4989e-02, 5.4441e-02,\n",
      "           2.0433e-02],\n",
      "          [6.2041e-02, 1.2634e-02, 4.3304e-02, 1.1755e-02, 8.8600e-03,\n",
      "           8.4407e-02, 4.1227e-01, 2.1542e-01, 4.9598e-02, 2.9193e-02,\n",
      "           7.0522e-02]],\n",
      "\n",
      "         [[1.6681e-02, 8.8849e-01, 4.6502e-02, 3.8100e-03, 5.1033e-03,\n",
      "           2.0054e-03, 1.5315e-03, 4.3113e-03, 4.4986e-03, 1.1215e-02,\n",
      "           1.5850e-02],\n",
      "          [7.1942e-02, 7.6960e-03, 7.7154e-02, 1.3839e-02, 8.5830e-03,\n",
      "           7.6123e-02, 1.6676e-01, 2.3273e-01, 1.3135e-01, 1.3761e-01,\n",
      "           7.6219e-02]],\n",
      "\n",
      "         [[6.3214e-02, 2.1686e-01, 1.8060e-01, 4.5005e-03, 7.2806e-03,\n",
      "           7.9482e-02, 1.1348e-01, 4.9919e-02, 8.6092e-02, 1.3650e-01,\n",
      "           6.2076e-02],\n",
      "          [9.3040e-02, 9.9356e-03, 3.3335e-02, 3.1220e-02, 9.7237e-03,\n",
      "           2.7374e-02, 3.3986e-01, 2.5254e-01, 6.5222e-02, 3.1532e-02,\n",
      "           1.0621e-01]],\n",
      "\n",
      "         [[5.0119e-03, 9.5917e-01, 2.0540e-02, 2.8189e-04, 1.5470e-03,\n",
      "           5.6593e-04, 4.3391e-04, 1.8978e-03, 2.6560e-03, 3.0168e-03,\n",
      "           4.8779e-03],\n",
      "          [1.3247e-01, 6.6434e-03, 2.6867e-02, 5.9136e-02, 1.1065e-01,\n",
      "           1.3204e-02, 2.0134e-01, 1.4610e-01, 1.1655e-01, 3.7957e-02,\n",
      "           1.4908e-01]],\n",
      "\n",
      "         [[2.3258e-02, 4.8514e-01, 1.6443e-01, 7.9946e-03, 8.8730e-03,\n",
      "           3.5271e-02, 1.7335e-02, 5.8945e-02, 6.6072e-02, 1.1069e-01,\n",
      "           2.1991e-02],\n",
      "          [3.3121e-02, 1.6552e-02, 2.6644e-02, 7.2257e-03, 8.3610e-03,\n",
      "           1.9312e-02, 3.4206e-02, 1.0823e-01, 4.8304e-01, 2.3048e-01,\n",
      "           3.2830e-02]]]]), tensor([[[[1.7242e-01, 1.9567e-01, 1.3118e-01, 5.5230e-02, 2.1469e-01,\n",
      "           1.7079e-02, 8.6986e-03, 1.3592e-02, 1.5871e-02, 1.8958e-02,\n",
      "           1.5661e-01],\n",
      "          [2.8835e-02, 6.9989e-03, 1.8119e-02, 4.2894e-03, 3.0078e-03,\n",
      "           1.0883e-01, 3.4729e-01, 2.8702e-01, 1.1803e-01, 4.3203e-02,\n",
      "           3.4375e-02],\n",
      "          [2.4693e-01, 2.4307e-02, 2.9293e-02, 5.5631e-03, 2.8714e-03,\n",
      "           1.0900e-01, 2.4826e-01, 5.3490e-02, 9.9743e-03, 5.9263e-03,\n",
      "           2.6438e-01]],\n",
      "\n",
      "         [[2.8579e-03, 9.4333e-01, 3.4118e-02, 1.5241e-03, 1.7884e-03,\n",
      "           4.2228e-03, 4.2758e-04, 1.5526e-03, 3.1248e-03, 4.3408e-03,\n",
      "           2.7127e-03],\n",
      "          [5.1802e-02, 6.6448e-03, 1.8516e-02, 7.3295e-03, 3.5997e-03,\n",
      "           1.8824e-02, 7.0132e-01, 1.0653e-01, 1.4497e-02, 1.0371e-02,\n",
      "           6.0571e-02],\n",
      "          [7.0664e-03, 1.9997e-04, 2.1259e-03, 5.1804e-05, 8.7346e-05,\n",
      "           5.5633e-02, 9.1258e-01, 1.3420e-02, 4.9063e-04, 3.7645e-04,\n",
      "           7.9697e-03]],\n",
      "\n",
      "         [[5.2820e-03, 4.0367e-01, 3.9031e-01, 7.5593e-04, 8.2816e-04,\n",
      "           5.4032e-03, 1.1681e-02, 2.7376e-02, 4.6632e-02, 1.0285e-01,\n",
      "           5.2103e-03],\n",
      "          [3.9056e-02, 4.4310e-03, 3.5978e-02, 7.3027e-03, 1.3327e-03,\n",
      "           1.2512e-01, 4.7356e-01, 1.6985e-01, 7.0551e-02, 2.8253e-02,\n",
      "           4.4556e-02],\n",
      "          [3.7468e-02, 7.1511e-04, 2.6335e-02, 3.9433e-05, 2.6683e-05,\n",
      "           3.3958e-01, 5.2016e-01, 1.8939e-02, 9.0240e-03, 3.2108e-03,\n",
      "           4.4508e-02]],\n",
      "\n",
      "         [[2.0870e-02, 7.0276e-01, 1.1731e-01, 2.2768e-03, 5.0965e-03,\n",
      "           6.8304e-03, 1.4886e-02, 3.0109e-02, 2.4989e-02, 5.4441e-02,\n",
      "           2.0433e-02],\n",
      "          [6.2041e-02, 1.2634e-02, 4.3304e-02, 1.1755e-02, 8.8600e-03,\n",
      "           8.4407e-02, 4.1227e-01, 2.1542e-01, 4.9598e-02, 2.9193e-02,\n",
      "           7.0522e-02],\n",
      "          [3.8990e-02, 1.5276e-03, 4.4898e-03, 1.0018e-04, 4.2800e-04,\n",
      "           1.2708e-02, 8.7458e-01, 1.6834e-02, 2.4099e-03, 1.4087e-03,\n",
      "           4.6519e-02]],\n",
      "\n",
      "         [[1.6681e-02, 8.8849e-01, 4.6502e-02, 3.8100e-03, 5.1033e-03,\n",
      "           2.0054e-03, 1.5315e-03, 4.3113e-03, 4.4986e-03, 1.1215e-02,\n",
      "           1.5850e-02],\n",
      "          [7.1942e-02, 7.6960e-03, 7.7154e-02, 1.3839e-02, 8.5830e-03,\n",
      "           7.6123e-02, 1.6676e-01, 2.3273e-01, 1.3135e-01, 1.3761e-01,\n",
      "           7.6219e-02],\n",
      "          [3.8325e-02, 3.1838e-04, 7.7578e-03, 1.7997e-03, 2.4943e-03,\n",
      "           3.7688e-02, 8.0633e-01, 3.2812e-02, 1.7695e-02, 1.0966e-02,\n",
      "           4.3818e-02]],\n",
      "\n",
      "         [[6.3214e-02, 2.1686e-01, 1.8060e-01, 4.5005e-03, 7.2806e-03,\n",
      "           7.9482e-02, 1.1348e-01, 4.9919e-02, 8.6092e-02, 1.3650e-01,\n",
      "           6.2076e-02],\n",
      "          [9.3040e-02, 9.9356e-03, 3.3335e-02, 3.1220e-02, 9.7237e-03,\n",
      "           2.7374e-02, 3.3986e-01, 2.5254e-01, 6.5222e-02, 3.1532e-02,\n",
      "           1.0621e-01],\n",
      "          [2.0371e-01, 5.1896e-02, 8.2733e-02, 6.9654e-03, 7.0161e-03,\n",
      "           1.7022e-01, 2.3300e-01, 2.3797e-02, 1.0281e-02, 5.3649e-03,\n",
      "           2.0501e-01]],\n",
      "\n",
      "         [[5.0119e-03, 9.5917e-01, 2.0540e-02, 2.8189e-04, 1.5470e-03,\n",
      "           5.6593e-04, 4.3391e-04, 1.8978e-03, 2.6560e-03, 3.0168e-03,\n",
      "           4.8779e-03],\n",
      "          [1.3247e-01, 6.6434e-03, 2.6867e-02, 5.9136e-02, 1.1065e-01,\n",
      "           1.3204e-02, 2.0134e-01, 1.4610e-01, 1.1655e-01, 3.7957e-02,\n",
      "           1.4908e-01],\n",
      "          [1.4170e-01, 4.6652e-03, 8.3903e-03, 1.1260e-03, 2.8754e-03,\n",
      "           7.0632e-02, 5.3013e-01, 2.2610e-02, 3.6907e-02, 9.9697e-03,\n",
      "           1.7099e-01]],\n",
      "\n",
      "         [[2.3258e-02, 4.8514e-01, 1.6443e-01, 7.9946e-03, 8.8730e-03,\n",
      "           3.5271e-02, 1.7335e-02, 5.8945e-02, 6.6072e-02, 1.1069e-01,\n",
      "           2.1991e-02],\n",
      "          [3.3121e-02, 1.6552e-02, 2.6644e-02, 7.2257e-03, 8.3610e-03,\n",
      "           1.9312e-02, 3.4206e-02, 1.0823e-01, 4.8304e-01, 2.3048e-01,\n",
      "           3.2830e-02],\n",
      "          [1.6714e-01, 2.0627e-02, 6.2583e-02, 8.0828e-03, 8.3410e-03,\n",
      "           1.0731e-02, 4.2340e-01, 8.3584e-02, 1.8385e-02, 1.2374e-02,\n",
      "           1.8475e-01]]]]), tensor([[[[1.7242e-01, 1.9567e-01, 1.3118e-01, 5.5230e-02, 2.1469e-01,\n",
      "           1.7079e-02, 8.6986e-03, 1.3592e-02, 1.5871e-02, 1.8958e-02,\n",
      "           1.5661e-01],\n",
      "          [2.8835e-02, 6.9989e-03, 1.8119e-02, 4.2894e-03, 3.0078e-03,\n",
      "           1.0883e-01, 3.4729e-01, 2.8702e-01, 1.1803e-01, 4.3203e-02,\n",
      "           3.4375e-02],\n",
      "          [2.4693e-01, 2.4307e-02, 2.9293e-02, 5.5631e-03, 2.8714e-03,\n",
      "           1.0900e-01, 2.4826e-01, 5.3490e-02, 9.9743e-03, 5.9263e-03,\n",
      "           2.6438e-01],\n",
      "          [2.9509e-01, 4.9674e-03, 3.6487e-02, 1.1734e-01, 4.2774e-02,\n",
      "           4.3460e-02, 2.7867e-02, 3.3891e-02, 3.9468e-02, 5.7073e-02,\n",
      "           3.0159e-01]],\n",
      "\n",
      "         [[2.8579e-03, 9.4333e-01, 3.4118e-02, 1.5241e-03, 1.7884e-03,\n",
      "           4.2228e-03, 4.2758e-04, 1.5526e-03, 3.1248e-03, 4.3408e-03,\n",
      "           2.7127e-03],\n",
      "          [5.1802e-02, 6.6448e-03, 1.8516e-02, 7.3295e-03, 3.5997e-03,\n",
      "           1.8824e-02, 7.0132e-01, 1.0653e-01, 1.4497e-02, 1.0371e-02,\n",
      "           6.0571e-02],\n",
      "          [7.0664e-03, 1.9997e-04, 2.1259e-03, 5.1804e-05, 8.7346e-05,\n",
      "           5.5633e-02, 9.1258e-01, 1.3420e-02, 4.9063e-04, 3.7645e-04,\n",
      "           7.9697e-03],\n",
      "          [8.1891e-02, 2.2255e-03, 1.3640e-02, 4.6881e-01, 2.4067e-01,\n",
      "           1.9127e-02, 4.9961e-02, 1.7320e-02, 1.4401e-02, 1.2703e-02,\n",
      "           7.9257e-02]],\n",
      "\n",
      "         [[5.2820e-03, 4.0367e-01, 3.9031e-01, 7.5593e-04, 8.2816e-04,\n",
      "           5.4032e-03, 1.1681e-02, 2.7376e-02, 4.6632e-02, 1.0285e-01,\n",
      "           5.2103e-03],\n",
      "          [3.9056e-02, 4.4310e-03, 3.5978e-02, 7.3027e-03, 1.3327e-03,\n",
      "           1.2512e-01, 4.7356e-01, 1.6985e-01, 7.0551e-02, 2.8253e-02,\n",
      "           4.4556e-02],\n",
      "          [3.7468e-02, 7.1511e-04, 2.6335e-02, 3.9433e-05, 2.6683e-05,\n",
      "           3.3958e-01, 5.2016e-01, 1.8939e-02, 9.0240e-03, 3.2108e-03,\n",
      "           4.4508e-02],\n",
      "          [1.6314e-02, 3.8131e-05, 2.6269e-04, 6.2023e-01, 3.4444e-01,\n",
      "           1.6164e-03, 7.2689e-04, 3.1281e-04, 5.1772e-04, 5.7908e-04,\n",
      "           1.4968e-02]],\n",
      "\n",
      "         [[2.0870e-02, 7.0276e-01, 1.1731e-01, 2.2768e-03, 5.0965e-03,\n",
      "           6.8304e-03, 1.4886e-02, 3.0109e-02, 2.4989e-02, 5.4441e-02,\n",
      "           2.0433e-02],\n",
      "          [6.2041e-02, 1.2634e-02, 4.3304e-02, 1.1755e-02, 8.8600e-03,\n",
      "           8.4407e-02, 4.1227e-01, 2.1542e-01, 4.9598e-02, 2.9193e-02,\n",
      "           7.0522e-02],\n",
      "          [3.8990e-02, 1.5276e-03, 4.4898e-03, 1.0018e-04, 4.2800e-04,\n",
      "           1.2708e-02, 8.7458e-01, 1.6834e-02, 2.4099e-03, 1.4087e-03,\n",
      "           4.6519e-02],\n",
      "          [1.3887e-01, 1.0266e-02, 1.7622e-02, 2.0905e-02, 2.4949e-02,\n",
      "           8.2691e-02, 4.3314e-01, 1.0434e-01, 7.9365e-03, 1.5640e-02,\n",
      "           1.4364e-01]],\n",
      "\n",
      "         [[1.6681e-02, 8.8849e-01, 4.6502e-02, 3.8100e-03, 5.1033e-03,\n",
      "           2.0054e-03, 1.5315e-03, 4.3113e-03, 4.4986e-03, 1.1215e-02,\n",
      "           1.5850e-02],\n",
      "          [7.1942e-02, 7.6960e-03, 7.7154e-02, 1.3839e-02, 8.5830e-03,\n",
      "           7.6123e-02, 1.6676e-01, 2.3273e-01, 1.3135e-01, 1.3761e-01,\n",
      "           7.6219e-02],\n",
      "          [3.8325e-02, 3.1838e-04, 7.7578e-03, 1.7997e-03, 2.4943e-03,\n",
      "           3.7688e-02, 8.0633e-01, 3.2812e-02, 1.7695e-02, 1.0966e-02,\n",
      "           4.3818e-02],\n",
      "          [1.9367e-01, 2.1959e-03, 5.2514e-02, 5.3651e-03, 8.1064e-03,\n",
      "           3.2023e-02, 8.4082e-02, 9.1725e-02, 1.3981e-01, 1.9418e-01,\n",
      "           1.9633e-01]],\n",
      "\n",
      "         [[6.3214e-02, 2.1686e-01, 1.8060e-01, 4.5005e-03, 7.2806e-03,\n",
      "           7.9482e-02, 1.1348e-01, 4.9919e-02, 8.6092e-02, 1.3650e-01,\n",
      "           6.2076e-02],\n",
      "          [9.3040e-02, 9.9356e-03, 3.3335e-02, 3.1220e-02, 9.7237e-03,\n",
      "           2.7374e-02, 3.3986e-01, 2.5254e-01, 6.5222e-02, 3.1532e-02,\n",
      "           1.0621e-01],\n",
      "          [2.0371e-01, 5.1896e-02, 8.2733e-02, 6.9654e-03, 7.0161e-03,\n",
      "           1.7022e-01, 2.3300e-01, 2.3797e-02, 1.0281e-02, 5.3649e-03,\n",
      "           2.0501e-01],\n",
      "          [1.0268e-01, 3.4422e-03, 4.4656e-02, 2.2533e-01, 1.1146e-01,\n",
      "           9.6363e-03, 2.5701e-01, 5.6115e-02, 6.2997e-02, 2.6682e-02,\n",
      "           9.9983e-02]],\n",
      "\n",
      "         [[5.0119e-03, 9.5917e-01, 2.0540e-02, 2.8189e-04, 1.5470e-03,\n",
      "           5.6593e-04, 4.3391e-04, 1.8978e-03, 2.6560e-03, 3.0168e-03,\n",
      "           4.8779e-03],\n",
      "          [1.3247e-01, 6.6434e-03, 2.6867e-02, 5.9136e-02, 1.1065e-01,\n",
      "           1.3204e-02, 2.0134e-01, 1.4610e-01, 1.1655e-01, 3.7957e-02,\n",
      "           1.4908e-01],\n",
      "          [1.4170e-01, 4.6652e-03, 8.3903e-03, 1.1260e-03, 2.8754e-03,\n",
      "           7.0632e-02, 5.3013e-01, 2.2610e-02, 3.6907e-02, 9.9697e-03,\n",
      "           1.7099e-01],\n",
      "          [1.5746e-01, 6.3153e-04, 9.6277e-03, 2.2090e-01, 1.5854e-01,\n",
      "           8.9497e-02, 7.0673e-02, 4.3049e-02, 4.4827e-02, 5.1824e-02,\n",
      "           1.5297e-01]],\n",
      "\n",
      "         [[2.3258e-02, 4.8514e-01, 1.6443e-01, 7.9946e-03, 8.8730e-03,\n",
      "           3.5271e-02, 1.7335e-02, 5.8945e-02, 6.6072e-02, 1.1069e-01,\n",
      "           2.1991e-02],\n",
      "          [3.3121e-02, 1.6552e-02, 2.6644e-02, 7.2257e-03, 8.3610e-03,\n",
      "           1.9312e-02, 3.4206e-02, 1.0823e-01, 4.8304e-01, 2.3048e-01,\n",
      "           3.2830e-02],\n",
      "          [1.6714e-01, 2.0627e-02, 6.2583e-02, 8.0828e-03, 8.3410e-03,\n",
      "           1.0731e-02, 4.2340e-01, 8.3584e-02, 1.8385e-02, 1.2374e-02,\n",
      "           1.8475e-01],\n",
      "          [2.6070e-01, 3.0148e-02, 8.9910e-02, 2.1849e-02, 4.0606e-02,\n",
      "           3.1084e-02, 1.3487e-01, 5.3162e-02, 2.4145e-02, 5.3876e-02,\n",
      "           2.5965e-01]]]]), tensor([[[[1.7242e-01, 1.9567e-01, 1.3118e-01, 5.5230e-02, 2.1469e-01,\n",
      "           1.7079e-02, 8.6986e-03, 1.3592e-02, 1.5871e-02, 1.8958e-02,\n",
      "           1.5661e-01],\n",
      "          [2.8835e-02, 6.9989e-03, 1.8119e-02, 4.2894e-03, 3.0078e-03,\n",
      "           1.0883e-01, 3.4729e-01, 2.8702e-01, 1.1803e-01, 4.3203e-02,\n",
      "           3.4375e-02],\n",
      "          [2.4693e-01, 2.4307e-02, 2.9293e-02, 5.5631e-03, 2.8714e-03,\n",
      "           1.0900e-01, 2.4826e-01, 5.3490e-02, 9.9743e-03, 5.9263e-03,\n",
      "           2.6438e-01],\n",
      "          [2.9509e-01, 4.9674e-03, 3.6487e-02, 1.1734e-01, 4.2774e-02,\n",
      "           4.3460e-02, 2.7867e-02, 3.3891e-02, 3.9468e-02, 5.7073e-02,\n",
      "           3.0159e-01],\n",
      "          [4.8230e-02, 8.9105e-04, 4.8106e-03, 1.1575e-01, 7.6860e-01,\n",
      "           2.4220e-03, 3.4549e-03, 1.9041e-03, 5.8466e-03, 3.0062e-03,\n",
      "           4.5088e-02]],\n",
      "\n",
      "         [[2.8579e-03, 9.4333e-01, 3.4118e-02, 1.5241e-03, 1.7884e-03,\n",
      "           4.2228e-03, 4.2758e-04, 1.5526e-03, 3.1248e-03, 4.3408e-03,\n",
      "           2.7127e-03],\n",
      "          [5.1802e-02, 6.6448e-03, 1.8516e-02, 7.3295e-03, 3.5997e-03,\n",
      "           1.8824e-02, 7.0132e-01, 1.0653e-01, 1.4497e-02, 1.0371e-02,\n",
      "           6.0571e-02],\n",
      "          [7.0664e-03, 1.9997e-04, 2.1259e-03, 5.1804e-05, 8.7346e-05,\n",
      "           5.5633e-02, 9.1258e-01, 1.3420e-02, 4.9063e-04, 3.7645e-04,\n",
      "           7.9697e-03],\n",
      "          [8.1891e-02, 2.2255e-03, 1.3640e-02, 4.6881e-01, 2.4067e-01,\n",
      "           1.9127e-02, 4.9961e-02, 1.7320e-02, 1.4401e-02, 1.2703e-02,\n",
      "           7.9257e-02],\n",
      "          [1.3299e-01, 1.6256e-03, 8.4214e-03, 8.3458e-02, 5.4657e-01,\n",
      "           1.9091e-04, 8.5047e-03, 1.3114e-02, 5.3694e-02, 2.5695e-02,\n",
      "           1.2573e-01]],\n",
      "\n",
      "         [[5.2820e-03, 4.0367e-01, 3.9031e-01, 7.5593e-04, 8.2816e-04,\n",
      "           5.4032e-03, 1.1681e-02, 2.7376e-02, 4.6632e-02, 1.0285e-01,\n",
      "           5.2103e-03],\n",
      "          [3.9056e-02, 4.4310e-03, 3.5978e-02, 7.3027e-03, 1.3327e-03,\n",
      "           1.2512e-01, 4.7356e-01, 1.6985e-01, 7.0551e-02, 2.8253e-02,\n",
      "           4.4556e-02],\n",
      "          [3.7468e-02, 7.1511e-04, 2.6335e-02, 3.9433e-05, 2.6683e-05,\n",
      "           3.3958e-01, 5.2016e-01, 1.8939e-02, 9.0240e-03, 3.2108e-03,\n",
      "           4.4508e-02],\n",
      "          [1.6314e-02, 3.8131e-05, 2.6269e-04, 6.2023e-01, 3.4444e-01,\n",
      "           1.6164e-03, 7.2689e-04, 3.1281e-04, 5.1772e-04, 5.7908e-04,\n",
      "           1.4968e-02],\n",
      "          [2.6793e-02, 9.6198e-05, 1.6435e-04, 2.5742e-01, 6.8424e-01,\n",
      "           2.4367e-04, 1.7110e-04, 8.2143e-04, 4.0889e-03, 1.0345e-03,\n",
      "           2.4930e-02]],\n",
      "\n",
      "         [[2.0870e-02, 7.0276e-01, 1.1731e-01, 2.2768e-03, 5.0965e-03,\n",
      "           6.8304e-03, 1.4886e-02, 3.0109e-02, 2.4989e-02, 5.4441e-02,\n",
      "           2.0433e-02],\n",
      "          [6.2041e-02, 1.2634e-02, 4.3304e-02, 1.1755e-02, 8.8600e-03,\n",
      "           8.4407e-02, 4.1227e-01, 2.1542e-01, 4.9598e-02, 2.9193e-02,\n",
      "           7.0522e-02],\n",
      "          [3.8990e-02, 1.5276e-03, 4.4898e-03, 1.0018e-04, 4.2800e-04,\n",
      "           1.2708e-02, 8.7458e-01, 1.6834e-02, 2.4099e-03, 1.4087e-03,\n",
      "           4.6519e-02],\n",
      "          [1.3887e-01, 1.0266e-02, 1.7622e-02, 2.0905e-02, 2.4949e-02,\n",
      "           8.2691e-02, 4.3314e-01, 1.0434e-01, 7.9365e-03, 1.5640e-02,\n",
      "           1.4364e-01],\n",
      "          [1.1581e-02, 2.4888e-03, 2.0943e-03, 6.9409e-02, 8.6371e-01,\n",
      "           1.7197e-03, 8.8146e-04, 2.9937e-03, 2.3478e-02, 1.0917e-02,\n",
      "           1.0723e-02]],\n",
      "\n",
      "         [[1.6681e-02, 8.8849e-01, 4.6502e-02, 3.8100e-03, 5.1033e-03,\n",
      "           2.0054e-03, 1.5315e-03, 4.3113e-03, 4.4986e-03, 1.1215e-02,\n",
      "           1.5850e-02],\n",
      "          [7.1942e-02, 7.6960e-03, 7.7154e-02, 1.3839e-02, 8.5830e-03,\n",
      "           7.6124e-02, 1.6676e-01, 2.3273e-01, 1.3135e-01, 1.3761e-01,\n",
      "           7.6219e-02],\n",
      "          [3.8325e-02, 3.1838e-04, 7.7578e-03, 1.7997e-03, 2.4943e-03,\n",
      "           3.7688e-02, 8.0633e-01, 3.2812e-02, 1.7695e-02, 1.0966e-02,\n",
      "           4.3818e-02],\n",
      "          [1.9367e-01, 2.1959e-03, 5.2514e-02, 5.3651e-03, 8.1064e-03,\n",
      "           3.2023e-02, 8.4082e-02, 9.1725e-02, 1.3981e-01, 1.9418e-01,\n",
      "           1.9633e-01],\n",
      "          [1.3171e-02, 8.9593e-03, 2.9208e-03, 1.8979e-01, 7.6628e-01,\n",
      "           1.5727e-03, 3.7113e-04, 7.6298e-04, 2.7059e-03, 1.6656e-03,\n",
      "           1.1803e-02]],\n",
      "\n",
      "         [[6.3214e-02, 2.1686e-01, 1.8060e-01, 4.5005e-03, 7.2806e-03,\n",
      "           7.9482e-02, 1.1348e-01, 4.9919e-02, 8.6092e-02, 1.3650e-01,\n",
      "           6.2076e-02],\n",
      "          [9.3040e-02, 9.9356e-03, 3.3335e-02, 3.1220e-02, 9.7237e-03,\n",
      "           2.7374e-02, 3.3986e-01, 2.5254e-01, 6.5222e-02, 3.1532e-02,\n",
      "           1.0621e-01],\n",
      "          [2.0371e-01, 5.1896e-02, 8.2733e-02, 6.9654e-03, 7.0161e-03,\n",
      "           1.7022e-01, 2.3300e-01, 2.3797e-02, 1.0281e-02, 5.3649e-03,\n",
      "           2.0501e-01],\n",
      "          [1.0268e-01, 3.4422e-03, 4.4656e-02, 2.2533e-01, 1.1146e-01,\n",
      "           9.6363e-03, 2.5701e-01, 5.6115e-02, 6.2997e-02, 2.6682e-02,\n",
      "           9.9983e-02],\n",
      "          [1.5074e-02, 1.4399e-04, 1.0789e-03, 1.1024e-01, 8.5600e-01,\n",
      "           4.2773e-04, 4.1467e-04, 7.9635e-04, 1.7288e-03, 7.6096e-04,\n",
      "           1.3338e-02]],\n",
      "\n",
      "         [[5.0119e-03, 9.5917e-01, 2.0540e-02, 2.8189e-04, 1.5470e-03,\n",
      "           5.6593e-04, 4.3391e-04, 1.8978e-03, 2.6560e-03, 3.0168e-03,\n",
      "           4.8779e-03],\n",
      "          [1.3247e-01, 6.6434e-03, 2.6867e-02, 5.9136e-02, 1.1065e-01,\n",
      "           1.3204e-02, 2.0134e-01, 1.4610e-01, 1.1655e-01, 3.7957e-02,\n",
      "           1.4908e-01],\n",
      "          [1.4170e-01, 4.6652e-03, 8.3903e-03, 1.1260e-03, 2.8754e-03,\n",
      "           7.0632e-02, 5.3013e-01, 2.2610e-02, 3.6907e-02, 9.9697e-03,\n",
      "           1.7099e-01],\n",
      "          [1.5746e-01, 6.3153e-04, 9.6277e-03, 2.2090e-01, 1.5854e-01,\n",
      "           8.9497e-02, 7.0673e-02, 4.3049e-02, 4.4827e-02, 5.1824e-02,\n",
      "           1.5297e-01],\n",
      "          [3.9868e-02, 5.5407e-04, 1.8463e-03, 1.2309e-01, 7.6958e-01,\n",
      "           4.7162e-04, 2.1869e-03, 1.0701e-02, 8.1410e-03, 5.0304e-03,\n",
      "           3.8534e-02]],\n",
      "\n",
      "         [[2.3258e-02, 4.8514e-01, 1.6443e-01, 7.9946e-03, 8.8730e-03,\n",
      "           3.5271e-02, 1.7335e-02, 5.8945e-02, 6.6072e-02, 1.1069e-01,\n",
      "           2.1991e-02],\n",
      "          [3.3121e-02, 1.6552e-02, 2.6644e-02, 7.2257e-03, 8.3610e-03,\n",
      "           1.9312e-02, 3.4206e-02, 1.0823e-01, 4.8304e-01, 2.3048e-01,\n",
      "           3.2830e-02],\n",
      "          [1.6714e-01, 2.0627e-02, 6.2583e-02, 8.0828e-03, 8.3410e-03,\n",
      "           1.0731e-02, 4.2340e-01, 8.3584e-02, 1.8385e-02, 1.2374e-02,\n",
      "           1.8475e-01],\n",
      "          [2.6070e-01, 3.0148e-02, 8.9910e-02, 2.1849e-02, 4.0606e-02,\n",
      "           3.1084e-02, 1.3487e-01, 5.3162e-02, 2.4145e-02, 5.3876e-02,\n",
      "           2.5965e-01],\n",
      "          [2.9190e-03, 1.3947e-03, 6.3498e-04, 2.9099e-01, 6.8080e-01,\n",
      "           1.2985e-02, 2.4220e-04, 5.8332e-04, 3.3339e-03, 3.4644e-03,\n",
      "           2.6480e-03]]]]), tensor([[[[1.7242e-01, 1.9567e-01, 1.3118e-01, 5.5230e-02, 2.1469e-01,\n",
      "           1.7079e-02, 8.6986e-03, 1.3592e-02, 1.5871e-02, 1.8958e-02,\n",
      "           1.5661e-01],\n",
      "          [2.8835e-02, 6.9989e-03, 1.8119e-02, 4.2894e-03, 3.0078e-03,\n",
      "           1.0883e-01, 3.4729e-01, 2.8702e-01, 1.1803e-01, 4.3203e-02,\n",
      "           3.4375e-02],\n",
      "          [2.4693e-01, 2.4307e-02, 2.9293e-02, 5.5631e-03, 2.8714e-03,\n",
      "           1.0900e-01, 2.4826e-01, 5.3490e-02, 9.9743e-03, 5.9263e-03,\n",
      "           2.6438e-01],\n",
      "          [2.9509e-01, 4.9674e-03, 3.6487e-02, 1.1734e-01, 4.2774e-02,\n",
      "           4.3460e-02, 2.7867e-02, 3.3891e-02, 3.9468e-02, 5.7073e-02,\n",
      "           3.0159e-01],\n",
      "          [4.8230e-02, 8.9105e-04, 4.8106e-03, 1.1575e-01, 7.6860e-01,\n",
      "           2.4220e-03, 3.4549e-03, 1.9041e-03, 5.8466e-03, 3.0062e-03,\n",
      "           4.5088e-02],\n",
      "          [5.2177e-02, 1.5835e-03, 2.9348e-02, 2.9040e-02, 5.4353e-02,\n",
      "           1.5728e-02, 2.0592e-02, 6.1287e-02, 2.9135e-01, 3.9298e-01,\n",
      "           5.1566e-02]],\n",
      "\n",
      "         [[2.8579e-03, 9.4333e-01, 3.4118e-02, 1.5241e-03, 1.7884e-03,\n",
      "           4.2228e-03, 4.2758e-04, 1.5526e-03, 3.1248e-03, 4.3408e-03,\n",
      "           2.7127e-03],\n",
      "          [5.1802e-02, 6.6448e-03, 1.8516e-02, 7.3295e-03, 3.5997e-03,\n",
      "           1.8824e-02, 7.0132e-01, 1.0653e-01, 1.4497e-02, 1.0371e-02,\n",
      "           6.0571e-02],\n",
      "          [7.0664e-03, 1.9997e-04, 2.1259e-03, 5.1804e-05, 8.7346e-05,\n",
      "           5.5633e-02, 9.1258e-01, 1.3420e-02, 4.9063e-04, 3.7645e-04,\n",
      "           7.9697e-03],\n",
      "          [8.1891e-02, 2.2255e-03, 1.3640e-02, 4.6881e-01, 2.4067e-01,\n",
      "           1.9127e-02, 4.9961e-02, 1.7320e-02, 1.4401e-02, 1.2703e-02,\n",
      "           7.9257e-02],\n",
      "          [1.3299e-01, 1.6256e-03, 8.4214e-03, 8.3458e-02, 5.4657e-01,\n",
      "           1.9091e-04, 8.5047e-03, 1.3114e-02, 5.3694e-02, 2.5695e-02,\n",
      "           1.2573e-01],\n",
      "          [1.4577e-02, 3.6709e-04, 2.2491e-03, 7.0270e-01, 2.1262e-01,\n",
      "           8.8768e-03, 4.6607e-03, 1.0859e-02, 1.7590e-02, 1.1296e-02,\n",
      "           1.4196e-02]],\n",
      "\n",
      "         [[5.2820e-03, 4.0367e-01, 3.9031e-01, 7.5593e-04, 8.2816e-04,\n",
      "           5.4032e-03, 1.1681e-02, 2.7376e-02, 4.6632e-02, 1.0285e-01,\n",
      "           5.2103e-03],\n",
      "          [3.9056e-02, 4.4310e-03, 3.5978e-02, 7.3027e-03, 1.3327e-03,\n",
      "           1.2512e-01, 4.7356e-01, 1.6985e-01, 7.0551e-02, 2.8253e-02,\n",
      "           4.4556e-02],\n",
      "          [3.7468e-02, 7.1511e-04, 2.6335e-02, 3.9433e-05, 2.6683e-05,\n",
      "           3.3958e-01, 5.2016e-01, 1.8939e-02, 9.0240e-03, 3.2108e-03,\n",
      "           4.4508e-02],\n",
      "          [1.6314e-02, 3.8131e-05, 2.6269e-04, 6.2023e-01, 3.4444e-01,\n",
      "           1.6164e-03, 7.2689e-04, 3.1281e-04, 5.1772e-04, 5.7908e-04,\n",
      "           1.4968e-02],\n",
      "          [2.6793e-02, 9.6198e-05, 1.6435e-04, 2.5742e-01, 6.8424e-01,\n",
      "           2.4367e-04, 1.7110e-04, 8.2143e-04, 4.0889e-03, 1.0345e-03,\n",
      "           2.4930e-02],\n",
      "          [4.2336e-02, 1.3368e-03, 1.8138e-03, 5.1239e-01, 3.9168e-01,\n",
      "           5.5079e-03, 9.8635e-04, 1.0502e-03, 1.4630e-03, 1.7983e-03,\n",
      "           3.9645e-02]],\n",
      "\n",
      "         [[2.0870e-02, 7.0276e-01, 1.1731e-01, 2.2768e-03, 5.0965e-03,\n",
      "           6.8304e-03, 1.4886e-02, 3.0109e-02, 2.4989e-02, 5.4441e-02,\n",
      "           2.0433e-02],\n",
      "          [6.2041e-02, 1.2634e-02, 4.3304e-02, 1.1755e-02, 8.8600e-03,\n",
      "           8.4407e-02, 4.1227e-01, 2.1542e-01, 4.9598e-02, 2.9193e-02,\n",
      "           7.0522e-02],\n",
      "          [3.8990e-02, 1.5276e-03, 4.4898e-03, 1.0018e-04, 4.2800e-04,\n",
      "           1.2708e-02, 8.7458e-01, 1.6834e-02, 2.4099e-03, 1.4087e-03,\n",
      "           4.6519e-02],\n",
      "          [1.3887e-01, 1.0266e-02, 1.7622e-02, 2.0905e-02, 2.4949e-02,\n",
      "           8.2691e-02, 4.3314e-01, 1.0434e-01, 7.9365e-03, 1.5640e-02,\n",
      "           1.4364e-01],\n",
      "          [1.1581e-02, 2.4888e-03, 2.0943e-03, 6.9409e-02, 8.6371e-01,\n",
      "           1.7197e-03, 8.8146e-04, 2.9937e-03, 2.3478e-02, 1.0917e-02,\n",
      "           1.0723e-02],\n",
      "          [1.9555e-01, 6.8090e-03, 4.4984e-02, 6.5062e-02, 1.9336e-01,\n",
      "           1.6684e-02, 4.9973e-03, 2.5874e-02, 1.6021e-01, 1.0260e-01,\n",
      "           1.8387e-01]],\n",
      "\n",
      "         [[1.6681e-02, 8.8849e-01, 4.6502e-02, 3.8100e-03, 5.1033e-03,\n",
      "           2.0054e-03, 1.5315e-03, 4.3113e-03, 4.4986e-03, 1.1215e-02,\n",
      "           1.5850e-02],\n",
      "          [7.1942e-02, 7.6960e-03, 7.7154e-02, 1.3839e-02, 8.5830e-03,\n",
      "           7.6124e-02, 1.6676e-01, 2.3273e-01, 1.3135e-01, 1.3761e-01,\n",
      "           7.6219e-02],\n",
      "          [3.8325e-02, 3.1838e-04, 7.7578e-03, 1.7997e-03, 2.4943e-03,\n",
      "           3.7688e-02, 8.0633e-01, 3.2812e-02, 1.7695e-02, 1.0966e-02,\n",
      "           4.3818e-02],\n",
      "          [1.9367e-01, 2.1959e-03, 5.2514e-02, 5.3651e-03, 8.1064e-03,\n",
      "           3.2023e-02, 8.4082e-02, 9.1725e-02, 1.3981e-01, 1.9418e-01,\n",
      "           1.9633e-01],\n",
      "          [1.3171e-02, 8.9593e-03, 2.9208e-03, 1.8979e-01, 7.6628e-01,\n",
      "           1.5727e-03, 3.7113e-04, 7.6298e-04, 2.7059e-03, 1.6656e-03,\n",
      "           1.1803e-02],\n",
      "          [7.8879e-02, 1.9940e-01, 1.5149e-01, 1.4016e-02, 2.5302e-02,\n",
      "           3.4797e-02, 8.7304e-03, 8.3292e-02, 1.0276e-01, 2.2845e-01,\n",
      "           7.2877e-02]],\n",
      "\n",
      "         [[6.3214e-02, 2.1686e-01, 1.8060e-01, 4.5005e-03, 7.2806e-03,\n",
      "           7.9482e-02, 1.1348e-01, 4.9919e-02, 8.6092e-02, 1.3650e-01,\n",
      "           6.2076e-02],\n",
      "          [9.3040e-02, 9.9356e-03, 3.3335e-02, 3.1220e-02, 9.7237e-03,\n",
      "           2.7374e-02, 3.3986e-01, 2.5254e-01, 6.5222e-02, 3.1532e-02,\n",
      "           1.0621e-01],\n",
      "          [2.0371e-01, 5.1896e-02, 8.2733e-02, 6.9654e-03, 7.0161e-03,\n",
      "           1.7022e-01, 2.3300e-01, 2.3797e-02, 1.0281e-02, 5.3649e-03,\n",
      "           2.0501e-01],\n",
      "          [1.0268e-01, 3.4422e-03, 4.4656e-02, 2.2533e-01, 1.1146e-01,\n",
      "           9.6363e-03, 2.5701e-01, 5.6115e-02, 6.2997e-02, 2.6682e-02,\n",
      "           9.9983e-02],\n",
      "          [1.5074e-02, 1.4399e-04, 1.0789e-03, 1.1024e-01, 8.5600e-01,\n",
      "           4.2773e-04, 4.1467e-04, 7.9635e-04, 1.7288e-03, 7.6096e-04,\n",
      "           1.3338e-02],\n",
      "          [1.1986e-01, 3.7870e-02, 3.6543e-02, 4.3157e-02, 1.2324e-01,\n",
      "           4.9529e-02, 2.1636e-02, 6.9773e-02, 1.8876e-01, 1.8833e-01,\n",
      "           1.2131e-01]],\n",
      "\n",
      "         [[5.0119e-03, 9.5917e-01, 2.0540e-02, 2.8189e-04, 1.5470e-03,\n",
      "           5.6593e-04, 4.3391e-04, 1.8978e-03, 2.6560e-03, 3.0168e-03,\n",
      "           4.8779e-03],\n",
      "          [1.3247e-01, 6.6434e-03, 2.6867e-02, 5.9136e-02, 1.1065e-01,\n",
      "           1.3204e-02, 2.0134e-01, 1.4610e-01, 1.1655e-01, 3.7957e-02,\n",
      "           1.4908e-01],\n",
      "          [1.4170e-01, 4.6652e-03, 8.3903e-03, 1.1260e-03, 2.8754e-03,\n",
      "           7.0632e-02, 5.3013e-01, 2.2610e-02, 3.6907e-02, 9.9697e-03,\n",
      "           1.7099e-01],\n",
      "          [1.5746e-01, 6.3153e-04, 9.6277e-03, 2.2090e-01, 1.5854e-01,\n",
      "           8.9497e-02, 7.0673e-02, 4.3049e-02, 4.4827e-02, 5.1824e-02,\n",
      "           1.5297e-01],\n",
      "          [3.9868e-02, 5.5407e-04, 1.8463e-03, 1.2309e-01, 7.6958e-01,\n",
      "           4.7162e-04, 2.1869e-03, 1.0701e-02, 8.1410e-03, 5.0304e-03,\n",
      "           3.8534e-02],\n",
      "          [1.1646e-01, 6.5902e-03, 3.1488e-02, 1.1700e-01, 1.0342e-01,\n",
      "           2.7549e-02, 1.0330e-01, 1.6704e-01, 1.2053e-01, 8.6014e-02,\n",
      "           1.2060e-01]],\n",
      "\n",
      "         [[2.3258e-02, 4.8514e-01, 1.6443e-01, 7.9946e-03, 8.8730e-03,\n",
      "           3.5271e-02, 1.7335e-02, 5.8945e-02, 6.6072e-02, 1.1069e-01,\n",
      "           2.1991e-02],\n",
      "          [3.3121e-02, 1.6552e-02, 2.6644e-02, 7.2257e-03, 8.3610e-03,\n",
      "           1.9312e-02, 3.4206e-02, 1.0823e-01, 4.8304e-01, 2.3048e-01,\n",
      "           3.2830e-02],\n",
      "          [1.6714e-01, 2.0627e-02, 6.2583e-02, 8.0828e-03, 8.3410e-03,\n",
      "           1.0731e-02, 4.2340e-01, 8.3584e-02, 1.8385e-02, 1.2374e-02,\n",
      "           1.8475e-01],\n",
      "          [2.6070e-01, 3.0148e-02, 8.9910e-02, 2.1849e-02, 4.0606e-02,\n",
      "           3.1084e-02, 1.3487e-01, 5.3162e-02, 2.4145e-02, 5.3876e-02,\n",
      "           2.5965e-01],\n",
      "          [2.9190e-03, 1.3947e-03, 6.3498e-04, 2.9099e-01, 6.8080e-01,\n",
      "           1.2985e-02, 2.4220e-04, 5.8332e-04, 3.3339e-03, 3.4644e-03,\n",
      "           2.6480e-03],\n",
      "          [3.0424e-02, 3.5954e-01, 1.9234e-01, 8.6364e-03, 4.7840e-03,\n",
      "           7.3614e-02, 2.9028e-02, 6.2032e-02, 5.7644e-02, 1.5321e-01,\n",
      "           2.8747e-02]]]]), tensor([[[[1.7242e-01, 1.9567e-01, 1.3118e-01, 5.5230e-02, 2.1469e-01,\n",
      "           1.7079e-02, 8.6986e-03, 1.3592e-02, 1.5871e-02, 1.8958e-02,\n",
      "           1.5661e-01],\n",
      "          [2.8835e-02, 6.9989e-03, 1.8119e-02, 4.2894e-03, 3.0078e-03,\n",
      "           1.0883e-01, 3.4729e-01, 2.8702e-01, 1.1803e-01, 4.3203e-02,\n",
      "           3.4375e-02],\n",
      "          [2.4693e-01, 2.4307e-02, 2.9293e-02, 5.5631e-03, 2.8714e-03,\n",
      "           1.0900e-01, 2.4826e-01, 5.3490e-02, 9.9743e-03, 5.9263e-03,\n",
      "           2.6438e-01],\n",
      "          [2.9509e-01, 4.9674e-03, 3.6487e-02, 1.1734e-01, 4.2774e-02,\n",
      "           4.3460e-02, 2.7867e-02, 3.3891e-02, 3.9468e-02, 5.7073e-02,\n",
      "           3.0159e-01],\n",
      "          [4.8230e-02, 8.9105e-04, 4.8106e-03, 1.1575e-01, 7.6860e-01,\n",
      "           2.4220e-03, 3.4549e-03, 1.9041e-03, 5.8466e-03, 3.0062e-03,\n",
      "           4.5088e-02],\n",
      "          [5.2177e-02, 1.5835e-03, 2.9348e-02, 2.9040e-02, 5.4353e-02,\n",
      "           1.5728e-02, 2.0592e-02, 6.1287e-02, 2.9135e-01, 3.9298e-01,\n",
      "           5.1566e-02],\n",
      "          [2.2413e-01, 8.6840e-03, 3.2829e-02, 2.0267e-02, 3.2428e-02,\n",
      "           1.5690e-01, 1.7058e-02, 2.7992e-02, 1.0542e-01, 1.2805e-01,\n",
      "           2.4624e-01]],\n",
      "\n",
      "         [[2.8579e-03, 9.4333e-01, 3.4118e-02, 1.5241e-03, 1.7884e-03,\n",
      "           4.2228e-03, 4.2758e-04, 1.5526e-03, 3.1248e-03, 4.3408e-03,\n",
      "           2.7127e-03],\n",
      "          [5.1802e-02, 6.6448e-03, 1.8516e-02, 7.3295e-03, 3.5997e-03,\n",
      "           1.8824e-02, 7.0132e-01, 1.0653e-01, 1.4497e-02, 1.0371e-02,\n",
      "           6.0571e-02],\n",
      "          [7.0664e-03, 1.9997e-04, 2.1259e-03, 5.1804e-05, 8.7346e-05,\n",
      "           5.5633e-02, 9.1258e-01, 1.3420e-02, 4.9063e-04, 3.7645e-04,\n",
      "           7.9697e-03],\n",
      "          [8.1891e-02, 2.2255e-03, 1.3640e-02, 4.6881e-01, 2.4067e-01,\n",
      "           1.9127e-02, 4.9961e-02, 1.7320e-02, 1.4401e-02, 1.2703e-02,\n",
      "           7.9257e-02],\n",
      "          [1.3299e-01, 1.6256e-03, 8.4214e-03, 8.3458e-02, 5.4657e-01,\n",
      "           1.9091e-04, 8.5047e-03, 1.3114e-02, 5.3694e-02, 2.5695e-02,\n",
      "           1.2573e-01],\n",
      "          [1.4577e-02, 3.6709e-04, 2.2491e-03, 7.0270e-01, 2.1262e-01,\n",
      "           8.8768e-03, 4.6607e-03, 1.0859e-02, 1.7590e-02, 1.1296e-02,\n",
      "           1.4196e-02],\n",
      "          [9.4797e-02, 4.4151e-04, 5.5221e-03, 1.1565e-01, 6.4740e-02,\n",
      "           4.2928e-01, 3.6357e-03, 1.5940e-02, 8.4031e-02, 9.4978e-02,\n",
      "           9.0988e-02]],\n",
      "\n",
      "         [[5.2820e-03, 4.0367e-01, 3.9031e-01, 7.5593e-04, 8.2816e-04,\n",
      "           5.4032e-03, 1.1681e-02, 2.7376e-02, 4.6632e-02, 1.0285e-01,\n",
      "           5.2103e-03],\n",
      "          [3.9056e-02, 4.4310e-03, 3.5978e-02, 7.3027e-03, 1.3327e-03,\n",
      "           1.2512e-01, 4.7356e-01, 1.6985e-01, 7.0551e-02, 2.8253e-02,\n",
      "           4.4556e-02],\n",
      "          [3.7468e-02, 7.1511e-04, 2.6335e-02, 3.9433e-05, 2.6683e-05,\n",
      "           3.3958e-01, 5.2016e-01, 1.8939e-02, 9.0240e-03, 3.2108e-03,\n",
      "           4.4508e-02],\n",
      "          [1.6314e-02, 3.8131e-05, 2.6269e-04, 6.2023e-01, 3.4444e-01,\n",
      "           1.6164e-03, 7.2689e-04, 3.1281e-04, 5.1772e-04, 5.7908e-04,\n",
      "           1.4968e-02],\n",
      "          [2.6793e-02, 9.6198e-05, 1.6435e-04, 2.5742e-01, 6.8424e-01,\n",
      "           2.4367e-04, 1.7110e-04, 8.2143e-04, 4.0889e-03, 1.0345e-03,\n",
      "           2.4930e-02],\n",
      "          [4.2336e-02, 1.3368e-03, 1.8138e-03, 5.1239e-01, 3.9168e-01,\n",
      "           5.5079e-03, 9.8635e-04, 1.0502e-03, 1.4630e-03, 1.7983e-03,\n",
      "           3.9645e-02],\n",
      "          [9.5054e-02, 9.7146e-03, 4.8364e-03, 3.8031e-01, 2.5659e-01,\n",
      "           3.4245e-02, 2.1550e-02, 2.4298e-02, 4.8450e-02, 2.4672e-02,\n",
      "           1.0028e-01]],\n",
      "\n",
      "         [[2.0870e-02, 7.0276e-01, 1.1731e-01, 2.2768e-03, 5.0965e-03,\n",
      "           6.8304e-03, 1.4886e-02, 3.0109e-02, 2.4989e-02, 5.4441e-02,\n",
      "           2.0433e-02],\n",
      "          [6.2041e-02, 1.2634e-02, 4.3304e-02, 1.1755e-02, 8.8600e-03,\n",
      "           8.4407e-02, 4.1227e-01, 2.1542e-01, 4.9598e-02, 2.9193e-02,\n",
      "           7.0522e-02],\n",
      "          [3.8990e-02, 1.5276e-03, 4.4898e-03, 1.0018e-04, 4.2800e-04,\n",
      "           1.2708e-02, 8.7458e-01, 1.6834e-02, 2.4099e-03, 1.4087e-03,\n",
      "           4.6519e-02],\n",
      "          [1.3887e-01, 1.0266e-02, 1.7622e-02, 2.0905e-02, 2.4949e-02,\n",
      "           8.2691e-02, 4.3314e-01, 1.0434e-01, 7.9365e-03, 1.5640e-02,\n",
      "           1.4364e-01],\n",
      "          [1.1581e-02, 2.4888e-03, 2.0943e-03, 6.9409e-02, 8.6371e-01,\n",
      "           1.7197e-03, 8.8146e-04, 2.9937e-03, 2.3478e-02, 1.0917e-02,\n",
      "           1.0723e-02],\n",
      "          [1.9555e-01, 6.8090e-03, 4.4984e-02, 6.5062e-02, 1.9336e-01,\n",
      "           1.6684e-02, 4.9973e-03, 2.5874e-02, 1.6021e-01, 1.0260e-01,\n",
      "           1.8387e-01],\n",
      "          [2.4109e-01, 1.1361e-02, 2.2192e-02, 9.5981e-03, 1.8044e-02,\n",
      "           2.3615e-01, 8.0589e-02, 4.0597e-02, 3.7843e-02, 4.1380e-02,\n",
      "           2.6116e-01]],\n",
      "\n",
      "         [[1.6681e-02, 8.8849e-01, 4.6502e-02, 3.8100e-03, 5.1033e-03,\n",
      "           2.0054e-03, 1.5315e-03, 4.3113e-03, 4.4986e-03, 1.1215e-02,\n",
      "           1.5850e-02],\n",
      "          [7.1942e-02, 7.6960e-03, 7.7154e-02, 1.3839e-02, 8.5830e-03,\n",
      "           7.6124e-02, 1.6676e-01, 2.3273e-01, 1.3135e-01, 1.3761e-01,\n",
      "           7.6219e-02],\n",
      "          [3.8325e-02, 3.1838e-04, 7.7578e-03, 1.7997e-03, 2.4943e-03,\n",
      "           3.7688e-02, 8.0633e-01, 3.2812e-02, 1.7695e-02, 1.0966e-02,\n",
      "           4.3818e-02],\n",
      "          [1.9367e-01, 2.1959e-03, 5.2514e-02, 5.3651e-03, 8.1064e-03,\n",
      "           3.2023e-02, 8.4082e-02, 9.1725e-02, 1.3981e-01, 1.9418e-01,\n",
      "           1.9633e-01],\n",
      "          [1.3171e-02, 8.9593e-03, 2.9208e-03, 1.8979e-01, 7.6628e-01,\n",
      "           1.5727e-03, 3.7113e-04, 7.6298e-04, 2.7059e-03, 1.6656e-03,\n",
      "           1.1803e-02],\n",
      "          [7.8879e-02, 1.9940e-01, 1.5149e-01, 1.4016e-02, 2.5302e-02,\n",
      "           3.4797e-02, 8.7304e-03, 8.3292e-02, 1.0276e-01, 2.2845e-01,\n",
      "           7.2877e-02],\n",
      "          [9.6300e-02, 3.5826e-01, 7.6831e-02, 8.8099e-03, 8.5766e-03,\n",
      "           5.8274e-02, 1.2762e-02, 9.0703e-02, 5.9722e-02, 1.3557e-01,\n",
      "           9.4182e-02]],\n",
      "\n",
      "         [[6.3214e-02, 2.1686e-01, 1.8060e-01, 4.5005e-03, 7.2806e-03,\n",
      "           7.9482e-02, 1.1348e-01, 4.9919e-02, 8.6092e-02, 1.3650e-01,\n",
      "           6.2076e-02],\n",
      "          [9.3040e-02, 9.9356e-03, 3.3335e-02, 3.1220e-02, 9.7237e-03,\n",
      "           2.7374e-02, 3.3986e-01, 2.5254e-01, 6.5222e-02, 3.1532e-02,\n",
      "           1.0621e-01],\n",
      "          [2.0371e-01, 5.1896e-02, 8.2733e-02, 6.9654e-03, 7.0161e-03,\n",
      "           1.7022e-01, 2.3300e-01, 2.3797e-02, 1.0281e-02, 5.3649e-03,\n",
      "           2.0501e-01],\n",
      "          [1.0268e-01, 3.4422e-03, 4.4656e-02, 2.2533e-01, 1.1146e-01,\n",
      "           9.6363e-03, 2.5701e-01, 5.6115e-02, 6.2997e-02, 2.6682e-02,\n",
      "           9.9983e-02],\n",
      "          [1.5074e-02, 1.4399e-04, 1.0789e-03, 1.1024e-01, 8.5600e-01,\n",
      "           4.2773e-04, 4.1467e-04, 7.9635e-04, 1.7288e-03, 7.6096e-04,\n",
      "           1.3338e-02],\n",
      "          [1.1986e-01, 3.7870e-02, 3.6543e-02, 4.3157e-02, 1.2324e-01,\n",
      "           4.9529e-02, 2.1636e-02, 6.9773e-02, 1.8876e-01, 1.8833e-01,\n",
      "           1.2131e-01],\n",
      "          [1.0279e-01, 1.6266e-02, 3.0006e-02, 8.5322e-02, 3.2652e-02,\n",
      "           3.1243e-01, 6.0434e-02, 9.7323e-02, 6.4912e-02, 8.4443e-02,\n",
      "           1.1343e-01]],\n",
      "\n",
      "         [[5.0119e-03, 9.5917e-01, 2.0540e-02, 2.8189e-04, 1.5470e-03,\n",
      "           5.6593e-04, 4.3391e-04, 1.8978e-03, 2.6560e-03, 3.0168e-03,\n",
      "           4.8779e-03],\n",
      "          [1.3247e-01, 6.6434e-03, 2.6867e-02, 5.9136e-02, 1.1065e-01,\n",
      "           1.3204e-02, 2.0134e-01, 1.4610e-01, 1.1655e-01, 3.7957e-02,\n",
      "           1.4908e-01],\n",
      "          [1.4170e-01, 4.6652e-03, 8.3903e-03, 1.1260e-03, 2.8754e-03,\n",
      "           7.0632e-02, 5.3013e-01, 2.2610e-02, 3.6907e-02, 9.9697e-03,\n",
      "           1.7099e-01],\n",
      "          [1.5746e-01, 6.3153e-04, 9.6277e-03, 2.2090e-01, 1.5854e-01,\n",
      "           8.9497e-02, 7.0673e-02, 4.3049e-02, 4.4827e-02, 5.1824e-02,\n",
      "           1.5297e-01],\n",
      "          [3.9868e-02, 5.5407e-04, 1.8463e-03, 1.2309e-01, 7.6958e-01,\n",
      "           4.7162e-04, 2.1869e-03, 1.0701e-02, 8.1410e-03, 5.0304e-03,\n",
      "           3.8534e-02],\n",
      "          [1.1646e-01, 6.5902e-03, 3.1488e-02, 1.1700e-01, 1.0342e-01,\n",
      "           2.7549e-02, 1.0330e-01, 1.6704e-01, 1.2053e-01, 8.6014e-02,\n",
      "           1.2060e-01],\n",
      "          [1.3090e-01, 1.6674e-02, 2.7525e-02, 1.5547e-01, 1.4981e-01,\n",
      "           1.3233e-01, 3.3566e-02, 8.5944e-02, 6.0217e-02, 7.0573e-02,\n",
      "           1.3699e-01]],\n",
      "\n",
      "         [[2.3258e-02, 4.8514e-01, 1.6443e-01, 7.9946e-03, 8.8730e-03,\n",
      "           3.5271e-02, 1.7335e-02, 5.8945e-02, 6.6072e-02, 1.1069e-01,\n",
      "           2.1991e-02],\n",
      "          [3.3121e-02, 1.6552e-02, 2.6644e-02, 7.2257e-03, 8.3610e-03,\n",
      "           1.9312e-02, 3.4206e-02, 1.0823e-01, 4.8304e-01, 2.3048e-01,\n",
      "           3.2830e-02],\n",
      "          [1.6714e-01, 2.0627e-02, 6.2583e-02, 8.0828e-03, 8.3410e-03,\n",
      "           1.0731e-02, 4.2340e-01, 8.3584e-02, 1.8385e-02, 1.2374e-02,\n",
      "           1.8475e-01],\n",
      "          [2.6070e-01, 3.0148e-02, 8.9910e-02, 2.1849e-02, 4.0606e-02,\n",
      "           3.1084e-02, 1.3487e-01, 5.3162e-02, 2.4145e-02, 5.3876e-02,\n",
      "           2.5965e-01],\n",
      "          [2.9190e-03, 1.3947e-03, 6.3498e-04, 2.9099e-01, 6.8080e-01,\n",
      "           1.2985e-02, 2.4220e-04, 5.8332e-04, 3.3339e-03, 3.4644e-03,\n",
      "           2.6480e-03],\n",
      "          [3.0424e-02, 3.5954e-01, 1.9234e-01, 8.6364e-03, 4.7840e-03,\n",
      "           7.3614e-02, 2.9028e-02, 6.2032e-02, 5.7644e-02, 1.5321e-01,\n",
      "           2.8747e-02],\n",
      "          [7.6933e-02, 4.2549e-02, 4.5490e-02, 6.3308e-02, 5.9556e-02,\n",
      "           6.7260e-02, 3.9533e-02, 8.7595e-02, 1.6123e-01, 2.7855e-01,\n",
      "           7.7996e-02]]]])]), (['<sos>', 'may', 'i', 'help', 'you', '?', '<eos>'], [tensor([[[[0.1596, 0.1640, 0.0957, 0.1473, 0.1538, 0.0520, 0.0310, 0.0401,\n",
      "           0.1567]],\n",
      "\n",
      "         [[0.2290, 0.2902, 0.0634, 0.0745, 0.0784, 0.0092, 0.0200, 0.0096,\n",
      "           0.2257]],\n",
      "\n",
      "         [[0.0737, 0.0588, 0.0839, 0.0994, 0.0829, 0.1358, 0.2153, 0.1758,\n",
      "           0.0743]],\n",
      "\n",
      "         [[0.0646, 0.1251, 0.0982, 0.0903, 0.0896, 0.0857, 0.2604, 0.1214,\n",
      "           0.0648]],\n",
      "\n",
      "         [[0.2828, 0.0960, 0.0592, 0.0913, 0.0585, 0.0447, 0.0473, 0.0399,\n",
      "           0.2802]],\n",
      "\n",
      "         [[0.0320, 0.0165, 0.0500, 0.0543, 0.0448, 0.1904, 0.2393, 0.3412,\n",
      "           0.0315]],\n",
      "\n",
      "         [[0.0527, 0.0710, 0.0749, 0.1141, 0.0893, 0.1458, 0.2303, 0.1694,\n",
      "           0.0524]],\n",
      "\n",
      "         [[0.2165, 0.1344, 0.0748, 0.0738, 0.0891, 0.0463, 0.0881, 0.0625,\n",
      "           0.2145]]]]), tensor([[[[0.1596, 0.1640, 0.0957, 0.1473, 0.1538, 0.0520, 0.0310, 0.0401,\n",
      "           0.1567],\n",
      "          [0.0850, 0.1180, 0.1448, 0.0843, 0.1919, 0.1156, 0.0869, 0.0890,\n",
      "           0.0845]],\n",
      "\n",
      "         [[0.2290, 0.2902, 0.0634, 0.0745, 0.0784, 0.0092, 0.0200, 0.0096,\n",
      "           0.2257],\n",
      "          [0.0619, 0.1451, 0.2010, 0.1237, 0.1960, 0.1075, 0.0411, 0.0603,\n",
      "           0.0634]],\n",
      "\n",
      "         [[0.0737, 0.0588, 0.0839, 0.0994, 0.0829, 0.1358, 0.2153, 0.1758,\n",
      "           0.0743],\n",
      "          [0.0813, 0.0403, 0.1113, 0.0813, 0.1035, 0.2724, 0.0827, 0.1452,\n",
      "           0.0819]],\n",
      "\n",
      "         [[0.0646, 0.1251, 0.0982, 0.0903, 0.0896, 0.0857, 0.2604, 0.1214,\n",
      "           0.0648],\n",
      "          [0.0556, 0.0245, 0.0881, 0.0437, 0.0690, 0.3208, 0.1739, 0.1689,\n",
      "           0.0554]],\n",
      "\n",
      "         [[0.2828, 0.0960, 0.0592, 0.0913, 0.0585, 0.0447, 0.0473, 0.0399,\n",
      "           0.2802],\n",
      "          [0.1987, 0.1273, 0.1073, 0.0895, 0.0684, 0.1010, 0.0428, 0.0648,\n",
      "           0.2001]],\n",
      "\n",
      "         [[0.0320, 0.0165, 0.0500, 0.0543, 0.0448, 0.1904, 0.2393, 0.3412,\n",
      "           0.0315],\n",
      "          [0.2359, 0.0980, 0.0848, 0.0736, 0.0907, 0.0733, 0.0643, 0.0443,\n",
      "           0.2352]],\n",
      "\n",
      "         [[0.0527, 0.0710, 0.0749, 0.1141, 0.0893, 0.1458, 0.2303, 0.1694,\n",
      "           0.0524],\n",
      "          [0.1661, 0.0445, 0.1763, 0.0453, 0.1248, 0.1148, 0.0974, 0.0631,\n",
      "           0.1677]],\n",
      "\n",
      "         [[0.2165, 0.1344, 0.0748, 0.0738, 0.0891, 0.0463, 0.0881, 0.0625,\n",
      "           0.2145],\n",
      "          [0.2067, 0.1771, 0.0977, 0.0766, 0.1034, 0.0447, 0.0522, 0.0340,\n",
      "           0.2075]]]]), tensor([[[[0.1596, 0.1640, 0.0957, 0.1473, 0.1538, 0.0520, 0.0310, 0.0401,\n",
      "           0.1567],\n",
      "          [0.0850, 0.1180, 0.1448, 0.0843, 0.1919, 0.1156, 0.0869, 0.0890,\n",
      "           0.0845],\n",
      "          [0.0678, 0.0597, 0.1533, 0.3598, 0.1880, 0.0459, 0.0262, 0.0262,\n",
      "           0.0731]],\n",
      "\n",
      "         [[0.2290, 0.2902, 0.0634, 0.0745, 0.0784, 0.0092, 0.0200, 0.0096,\n",
      "           0.2257],\n",
      "          [0.0619, 0.1451, 0.2010, 0.1237, 0.1960, 0.1075, 0.0411, 0.0603,\n",
      "           0.0634],\n",
      "          [0.0804, 0.0743, 0.1987, 0.1857, 0.2410, 0.0590, 0.0386, 0.0386,\n",
      "           0.0837]],\n",
      "\n",
      "         [[0.0737, 0.0588, 0.0839, 0.0994, 0.0829, 0.1358, 0.2153, 0.1758,\n",
      "           0.0743],\n",
      "          [0.0813, 0.0403, 0.1113, 0.0813, 0.1035, 0.2724, 0.0827, 0.1452,\n",
      "           0.0819],\n",
      "          [0.0515, 0.0519, 0.1302, 0.3762, 0.1994, 0.0505, 0.0428, 0.0447,\n",
      "           0.0528]],\n",
      "\n",
      "         [[0.0646, 0.1251, 0.0982, 0.0903, 0.0896, 0.0857, 0.2604, 0.1214,\n",
      "           0.0648],\n",
      "          [0.0556, 0.0245, 0.0881, 0.0437, 0.0690, 0.3208, 0.1739, 0.1689,\n",
      "           0.0554],\n",
      "          [0.1703, 0.0800, 0.0795, 0.2057, 0.1098, 0.0396, 0.0728, 0.0651,\n",
      "           0.1774]],\n",
      "\n",
      "         [[0.2828, 0.0960, 0.0592, 0.0913, 0.0585, 0.0447, 0.0473, 0.0399,\n",
      "           0.2802],\n",
      "          [0.1987, 0.1273, 0.1073, 0.0895, 0.0684, 0.1010, 0.0428, 0.0648,\n",
      "           0.2001],\n",
      "          [0.0886, 0.0204, 0.1427, 0.2533, 0.1540, 0.1151, 0.0513, 0.0833,\n",
      "           0.0912]],\n",
      "\n",
      "         [[0.0320, 0.0165, 0.0500, 0.0543, 0.0448, 0.1904, 0.2393, 0.3412,\n",
      "           0.0315],\n",
      "          [0.2359, 0.0980, 0.0848, 0.0736, 0.0907, 0.0733, 0.0643, 0.0443,\n",
      "           0.2352],\n",
      "          [0.1291, 0.0605, 0.2102, 0.1897, 0.2081, 0.0265, 0.0233, 0.0135,\n",
      "           0.1391]],\n",
      "\n",
      "         [[0.0527, 0.0710, 0.0749, 0.1141, 0.0893, 0.1458, 0.2303, 0.1694,\n",
      "           0.0524],\n",
      "          [0.1661, 0.0445, 0.1763, 0.0453, 0.1248, 0.1148, 0.0974, 0.0631,\n",
      "           0.1677],\n",
      "          [0.1060, 0.0593, 0.1471, 0.3203, 0.2286, 0.0100, 0.0083, 0.0055,\n",
      "           0.1150]],\n",
      "\n",
      "         [[0.2165, 0.1344, 0.0748, 0.0738, 0.0891, 0.0463, 0.0881, 0.0625,\n",
      "           0.2145],\n",
      "          [0.2067, 0.1771, 0.0977, 0.0766, 0.1034, 0.0447, 0.0522, 0.0340,\n",
      "           0.2075],\n",
      "          [0.1333, 0.0503, 0.1902, 0.1496, 0.2522, 0.0290, 0.0296, 0.0248,\n",
      "           0.1411]]]]), tensor([[[[0.1596, 0.1640, 0.0957, 0.1473, 0.1538, 0.0520, 0.0310, 0.0401,\n",
      "           0.1567],\n",
      "          [0.0850, 0.1180, 0.1448, 0.0843, 0.1919, 0.1156, 0.0869, 0.0890,\n",
      "           0.0845],\n",
      "          [0.0678, 0.0597, 0.1533, 0.3598, 0.1880, 0.0459, 0.0262, 0.0262,\n",
      "           0.0731],\n",
      "          [0.2302, 0.1425, 0.0711, 0.0908, 0.0613, 0.0616, 0.0566, 0.0511,\n",
      "           0.2348]],\n",
      "\n",
      "         [[0.2290, 0.2902, 0.0634, 0.0745, 0.0784, 0.0092, 0.0200, 0.0096,\n",
      "           0.2257],\n",
      "          [0.0619, 0.1451, 0.2010, 0.1237, 0.1960, 0.1075, 0.0411, 0.0603,\n",
      "           0.0634],\n",
      "          [0.0804, 0.0743, 0.1987, 0.1857, 0.2410, 0.0590, 0.0386, 0.0386,\n",
      "           0.0837],\n",
      "          [0.2162, 0.1611, 0.1045, 0.0827, 0.0916, 0.0596, 0.0278, 0.0382,\n",
      "           0.2184]],\n",
      "\n",
      "         [[0.0737, 0.0588, 0.0839, 0.0994, 0.0829, 0.1358, 0.2153, 0.1758,\n",
      "           0.0743],\n",
      "          [0.0813, 0.0403, 0.1113, 0.0813, 0.1035, 0.2724, 0.0827, 0.1452,\n",
      "           0.0819],\n",
      "          [0.0515, 0.0519, 0.1302, 0.3762, 0.1994, 0.0505, 0.0428, 0.0447,\n",
      "           0.0528],\n",
      "          [0.1861, 0.0360, 0.1261, 0.2092, 0.1635, 0.0476, 0.0203, 0.0238,\n",
      "           0.1875]],\n",
      "\n",
      "         [[0.0646, 0.1251, 0.0982, 0.0903, 0.0896, 0.0857, 0.2604, 0.1214,\n",
      "           0.0648],\n",
      "          [0.0556, 0.0245, 0.0881, 0.0437, 0.0690, 0.3208, 0.1739, 0.1689,\n",
      "           0.0554],\n",
      "          [0.1703, 0.0800, 0.0795, 0.2057, 0.1098, 0.0396, 0.0728, 0.0651,\n",
      "           0.1774],\n",
      "          [0.1954, 0.0452, 0.1149, 0.0644, 0.0783, 0.1323, 0.0835, 0.0913,\n",
      "           0.1947]],\n",
      "\n",
      "         [[0.2828, 0.0960, 0.0592, 0.0913, 0.0585, 0.0447, 0.0473, 0.0399,\n",
      "           0.2802],\n",
      "          [0.1987, 0.1273, 0.1073, 0.0895, 0.0684, 0.1010, 0.0428, 0.0648,\n",
      "           0.2001],\n",
      "          [0.0886, 0.0204, 0.1427, 0.2533, 0.1540, 0.1151, 0.0513, 0.0833,\n",
      "           0.0912],\n",
      "          [0.3257, 0.1291, 0.0795, 0.0595, 0.0423, 0.0196, 0.0084, 0.0102,\n",
      "           0.3257]],\n",
      "\n",
      "         [[0.0320, 0.0165, 0.0500, 0.0543, 0.0448, 0.1904, 0.2393, 0.3412,\n",
      "           0.0315],\n",
      "          [0.2359, 0.0980, 0.0848, 0.0736, 0.0907, 0.0733, 0.0643, 0.0443,\n",
      "           0.2352],\n",
      "          [0.1291, 0.0605, 0.2102, 0.1897, 0.2081, 0.0265, 0.0233, 0.0135,\n",
      "           0.1391],\n",
      "          [0.3096, 0.0305, 0.0673, 0.0488, 0.0604, 0.0827, 0.0508, 0.0451,\n",
      "           0.3049]],\n",
      "\n",
      "         [[0.0527, 0.0710, 0.0749, 0.1141, 0.0893, 0.1458, 0.2303, 0.1694,\n",
      "           0.0524],\n",
      "          [0.1661, 0.0445, 0.1763, 0.0453, 0.1248, 0.1148, 0.0974, 0.0631,\n",
      "           0.1677],\n",
      "          [0.1060, 0.0593, 0.1471, 0.3203, 0.2286, 0.0100, 0.0083, 0.0055,\n",
      "           0.1150],\n",
      "          [0.1646, 0.1856, 0.0931, 0.1796, 0.0791, 0.0538, 0.0429, 0.0326,\n",
      "           0.1688]],\n",
      "\n",
      "         [[0.2165, 0.1344, 0.0748, 0.0738, 0.0891, 0.0463, 0.0881, 0.0625,\n",
      "           0.2145],\n",
      "          [0.2067, 0.1771, 0.0977, 0.0766, 0.1034, 0.0447, 0.0522, 0.0340,\n",
      "           0.2075],\n",
      "          [0.1333, 0.0503, 0.1902, 0.1496, 0.2522, 0.0290, 0.0296, 0.0248,\n",
      "           0.1411],\n",
      "          [0.0910, 0.0888, 0.0651, 0.0764, 0.0472, 0.1592, 0.2144, 0.1670,\n",
      "           0.0909]]]]), tensor([[[[0.1596, 0.1640, 0.0957, 0.1473, 0.1538, 0.0520, 0.0310, 0.0401,\n",
      "           0.1567],\n",
      "          [0.0850, 0.1180, 0.1448, 0.0843, 0.1919, 0.1156, 0.0869, 0.0890,\n",
      "           0.0845],\n",
      "          [0.0678, 0.0597, 0.1533, 0.3598, 0.1880, 0.0459, 0.0262, 0.0262,\n",
      "           0.0731],\n",
      "          [0.2302, 0.1425, 0.0711, 0.0908, 0.0613, 0.0616, 0.0566, 0.0511,\n",
      "           0.2348],\n",
      "          [0.3038, 0.1278, 0.0754, 0.0723, 0.0574, 0.0245, 0.0192, 0.0121,\n",
      "           0.3074]],\n",
      "\n",
      "         [[0.2290, 0.2902, 0.0634, 0.0745, 0.0784, 0.0092, 0.0200, 0.0096,\n",
      "           0.2257],\n",
      "          [0.0619, 0.1451, 0.2010, 0.1237, 0.1960, 0.1075, 0.0411, 0.0603,\n",
      "           0.0634],\n",
      "          [0.0804, 0.0743, 0.1987, 0.1857, 0.2410, 0.0590, 0.0386, 0.0386,\n",
      "           0.0837],\n",
      "          [0.2162, 0.1611, 0.1045, 0.0827, 0.0916, 0.0596, 0.0278, 0.0382,\n",
      "           0.2184],\n",
      "          [0.1450, 0.0494, 0.2610, 0.1205, 0.1810, 0.0472, 0.0281, 0.0191,\n",
      "           0.1488]],\n",
      "\n",
      "         [[0.0737, 0.0588, 0.0839, 0.0994, 0.0829, 0.1358, 0.2153, 0.1758,\n",
      "           0.0743],\n",
      "          [0.0813, 0.0403, 0.1113, 0.0813, 0.1035, 0.2724, 0.0827, 0.1452,\n",
      "           0.0819],\n",
      "          [0.0515, 0.0519, 0.1302, 0.3762, 0.1994, 0.0505, 0.0428, 0.0447,\n",
      "           0.0528],\n",
      "          [0.1861, 0.0360, 0.1261, 0.2092, 0.1635, 0.0476, 0.0203, 0.0238,\n",
      "           0.1875],\n",
      "          [0.2316, 0.2207, 0.0779, 0.0954, 0.1236, 0.0079, 0.0054, 0.0063,\n",
      "           0.2313]],\n",
      "\n",
      "         [[0.0646, 0.1251, 0.0982, 0.0903, 0.0896, 0.0857, 0.2604, 0.1214,\n",
      "           0.0648],\n",
      "          [0.0556, 0.0245, 0.0881, 0.0437, 0.0690, 0.3208, 0.1739, 0.1689,\n",
      "           0.0554],\n",
      "          [0.1703, 0.0800, 0.0795, 0.2057, 0.1098, 0.0396, 0.0728, 0.0651,\n",
      "           0.1774],\n",
      "          [0.1954, 0.0452, 0.1149, 0.0644, 0.0783, 0.1323, 0.0835, 0.0913,\n",
      "           0.1947],\n",
      "          [0.2812, 0.0620, 0.0770, 0.0906, 0.1314, 0.0271, 0.0195, 0.0308,\n",
      "           0.2806]],\n",
      "\n",
      "         [[0.2828, 0.0960, 0.0592, 0.0913, 0.0585, 0.0447, 0.0473, 0.0399,\n",
      "           0.2802],\n",
      "          [0.1987, 0.1273, 0.1073, 0.0895, 0.0684, 0.1010, 0.0428, 0.0648,\n",
      "           0.2001],\n",
      "          [0.0886, 0.0204, 0.1427, 0.2533, 0.1540, 0.1151, 0.0513, 0.0833,\n",
      "           0.0912],\n",
      "          [0.3257, 0.1291, 0.0795, 0.0595, 0.0423, 0.0196, 0.0084, 0.0102,\n",
      "           0.3257],\n",
      "          [0.1108, 0.2654, 0.1495, 0.1515, 0.0991, 0.0473, 0.0276, 0.0378,\n",
      "           0.1110]],\n",
      "\n",
      "         [[0.0320, 0.0165, 0.0500, 0.0543, 0.0448, 0.1904, 0.2393, 0.3412,\n",
      "           0.0315],\n",
      "          [0.2359, 0.0980, 0.0848, 0.0736, 0.0907, 0.0733, 0.0643, 0.0443,\n",
      "           0.2352],\n",
      "          [0.1291, 0.0605, 0.2102, 0.1897, 0.2081, 0.0265, 0.0233, 0.0135,\n",
      "           0.1391],\n",
      "          [0.3096, 0.0305, 0.0673, 0.0488, 0.0604, 0.0827, 0.0508, 0.0451,\n",
      "           0.3049],\n",
      "          [0.1779, 0.1380, 0.1152, 0.1921, 0.1297, 0.0276, 0.0181, 0.0186,\n",
      "           0.1830]],\n",
      "\n",
      "         [[0.0527, 0.0710, 0.0749, 0.1141, 0.0893, 0.1458, 0.2303, 0.1694,\n",
      "           0.0524],\n",
      "          [0.1661, 0.0445, 0.1763, 0.0453, 0.1248, 0.1148, 0.0974, 0.0631,\n",
      "           0.1677],\n",
      "          [0.1060, 0.0593, 0.1471, 0.3203, 0.2286, 0.0100, 0.0083, 0.0055,\n",
      "           0.1150],\n",
      "          [0.1646, 0.1856, 0.0931, 0.1796, 0.0791, 0.0538, 0.0429, 0.0326,\n",
      "           0.1688],\n",
      "          [0.1180, 0.2486, 0.0920, 0.2246, 0.1583, 0.0143, 0.0121, 0.0110,\n",
      "           0.1210]],\n",
      "\n",
      "         [[0.2165, 0.1344, 0.0748, 0.0738, 0.0891, 0.0463, 0.0881, 0.0625,\n",
      "           0.2145],\n",
      "          [0.2067, 0.1771, 0.0977, 0.0766, 0.1034, 0.0447, 0.0522, 0.0340,\n",
      "           0.2075],\n",
      "          [0.1333, 0.0503, 0.1902, 0.1496, 0.2522, 0.0290, 0.0296, 0.0248,\n",
      "           0.1411],\n",
      "          [0.0910, 0.0888, 0.0651, 0.0764, 0.0472, 0.1592, 0.2144, 0.1670,\n",
      "           0.0909],\n",
      "          [0.0494, 0.1593, 0.1234, 0.2018, 0.1403, 0.0931, 0.1014, 0.0811,\n",
      "           0.0501]]]]), tensor([[[[0.1596, 0.1640, 0.0957, 0.1473, 0.1538, 0.0520, 0.0310, 0.0401,\n",
      "           0.1567],\n",
      "          [0.0850, 0.1180, 0.1448, 0.0843, 0.1919, 0.1156, 0.0869, 0.0890,\n",
      "           0.0845],\n",
      "          [0.0678, 0.0597, 0.1533, 0.3598, 0.1880, 0.0459, 0.0262, 0.0262,\n",
      "           0.0731],\n",
      "          [0.2302, 0.1425, 0.0711, 0.0908, 0.0613, 0.0616, 0.0566, 0.0511,\n",
      "           0.2348],\n",
      "          [0.3038, 0.1278, 0.0754, 0.0723, 0.0574, 0.0245, 0.0192, 0.0121,\n",
      "           0.3074],\n",
      "          [0.1896, 0.0408, 0.1228, 0.0848, 0.1092, 0.1057, 0.0728, 0.0879,\n",
      "           0.1865]],\n",
      "\n",
      "         [[0.2290, 0.2902, 0.0634, 0.0745, 0.0784, 0.0092, 0.0200, 0.0096,\n",
      "           0.2257],\n",
      "          [0.0619, 0.1451, 0.2010, 0.1237, 0.1960, 0.1075, 0.0411, 0.0603,\n",
      "           0.0634],\n",
      "          [0.0804, 0.0743, 0.1987, 0.1857, 0.2410, 0.0590, 0.0386, 0.0386,\n",
      "           0.0837],\n",
      "          [0.2162, 0.1611, 0.1045, 0.0827, 0.0916, 0.0596, 0.0278, 0.0382,\n",
      "           0.2184],\n",
      "          [0.1450, 0.0494, 0.2610, 0.1205, 0.1810, 0.0472, 0.0281, 0.0191,\n",
      "           0.1488],\n",
      "          [0.2105, 0.1102, 0.1055, 0.0574, 0.0849, 0.1204, 0.0414, 0.0638,\n",
      "           0.2058]],\n",
      "\n",
      "         [[0.0737, 0.0588, 0.0839, 0.0994, 0.0829, 0.1358, 0.2153, 0.1758,\n",
      "           0.0743],\n",
      "          [0.0813, 0.0403, 0.1113, 0.0813, 0.1035, 0.2724, 0.0827, 0.1452,\n",
      "           0.0819],\n",
      "          [0.0515, 0.0519, 0.1302, 0.3762, 0.1994, 0.0505, 0.0428, 0.0447,\n",
      "           0.0528],\n",
      "          [0.1861, 0.0360, 0.1261, 0.2092, 0.1635, 0.0476, 0.0203, 0.0238,\n",
      "           0.1875],\n",
      "          [0.2316, 0.2207, 0.0779, 0.0954, 0.1236, 0.0079, 0.0054, 0.0063,\n",
      "           0.2313],\n",
      "          [0.1933, 0.1269, 0.1366, 0.1484, 0.1044, 0.0405, 0.0299, 0.0294,\n",
      "           0.1905]],\n",
      "\n",
      "         [[0.0646, 0.1251, 0.0982, 0.0903, 0.0896, 0.0857, 0.2604, 0.1214,\n",
      "           0.0648],\n",
      "          [0.0556, 0.0245, 0.0881, 0.0437, 0.0690, 0.3208, 0.1739, 0.1689,\n",
      "           0.0554],\n",
      "          [0.1703, 0.0800, 0.0795, 0.2057, 0.1098, 0.0396, 0.0728, 0.0651,\n",
      "           0.1774],\n",
      "          [0.1954, 0.0452, 0.1149, 0.0644, 0.0783, 0.1323, 0.0835, 0.0913,\n",
      "           0.1947],\n",
      "          [0.2812, 0.0620, 0.0770, 0.0906, 0.1314, 0.0271, 0.0195, 0.0308,\n",
      "           0.2806],\n",
      "          [0.2116, 0.1424, 0.1126, 0.0624, 0.0836, 0.0745, 0.0327, 0.0677,\n",
      "           0.2124]],\n",
      "\n",
      "         [[0.2828, 0.0960, 0.0592, 0.0913, 0.0585, 0.0447, 0.0473, 0.0399,\n",
      "           0.2802],\n",
      "          [0.1987, 0.1273, 0.1073, 0.0895, 0.0684, 0.1010, 0.0428, 0.0648,\n",
      "           0.2001],\n",
      "          [0.0886, 0.0204, 0.1427, 0.2533, 0.1540, 0.1151, 0.0513, 0.0833,\n",
      "           0.0912],\n",
      "          [0.3257, 0.1291, 0.0795, 0.0595, 0.0423, 0.0196, 0.0084, 0.0102,\n",
      "           0.3257],\n",
      "          [0.1108, 0.2654, 0.1495, 0.1515, 0.0991, 0.0473, 0.0276, 0.0378,\n",
      "           0.1110],\n",
      "          [0.1048, 0.0662, 0.1681, 0.1532, 0.1219, 0.1396, 0.0545, 0.0877,\n",
      "           0.1040]],\n",
      "\n",
      "         [[0.0320, 0.0165, 0.0500, 0.0543, 0.0448, 0.1904, 0.2393, 0.3412,\n",
      "           0.0315],\n",
      "          [0.2359, 0.0980, 0.0848, 0.0736, 0.0907, 0.0733, 0.0643, 0.0443,\n",
      "           0.2352],\n",
      "          [0.1291, 0.0605, 0.2102, 0.1897, 0.2081, 0.0265, 0.0233, 0.0135,\n",
      "           0.1391],\n",
      "          [0.3096, 0.0305, 0.0673, 0.0488, 0.0604, 0.0827, 0.0508, 0.0451,\n",
      "           0.3049],\n",
      "          [0.1779, 0.1380, 0.1152, 0.1921, 0.1297, 0.0276, 0.0181, 0.0186,\n",
      "           0.1830],\n",
      "          [0.1890, 0.2102, 0.1030, 0.0877, 0.1159, 0.0411, 0.0364, 0.0295,\n",
      "           0.1872]],\n",
      "\n",
      "         [[0.0527, 0.0710, 0.0749, 0.1141, 0.0893, 0.1458, 0.2303, 0.1694,\n",
      "           0.0524],\n",
      "          [0.1661, 0.0445, 0.1763, 0.0453, 0.1248, 0.1148, 0.0974, 0.0631,\n",
      "           0.1677],\n",
      "          [0.1060, 0.0593, 0.1471, 0.3203, 0.2286, 0.0100, 0.0083, 0.0055,\n",
      "           0.1150],\n",
      "          [0.1646, 0.1856, 0.0931, 0.1796, 0.0791, 0.0538, 0.0429, 0.0326,\n",
      "           0.1688],\n",
      "          [0.1180, 0.2486, 0.0920, 0.2246, 0.1583, 0.0143, 0.0121, 0.0110,\n",
      "           0.1210],\n",
      "          [0.1029, 0.1049, 0.1121, 0.0699, 0.1062, 0.1651, 0.0902, 0.1477,\n",
      "           0.1010]],\n",
      "\n",
      "         [[0.2165, 0.1344, 0.0748, 0.0738, 0.0891, 0.0463, 0.0881, 0.0625,\n",
      "           0.2145],\n",
      "          [0.2067, 0.1771, 0.0977, 0.0766, 0.1034, 0.0447, 0.0522, 0.0340,\n",
      "           0.2075],\n",
      "          [0.1333, 0.0503, 0.1902, 0.1496, 0.2522, 0.0290, 0.0296, 0.0248,\n",
      "           0.1411],\n",
      "          [0.0910, 0.0888, 0.0651, 0.0764, 0.0472, 0.1592, 0.2144, 0.1670,\n",
      "           0.0909],\n",
      "          [0.0494, 0.1593, 0.1234, 0.2018, 0.1403, 0.0931, 0.1014, 0.0811,\n",
      "           0.0501],\n",
      "          [0.1087, 0.0270, 0.1174, 0.0600, 0.0755, 0.1934, 0.1066, 0.1990,\n",
      "           0.1125]]]])]), (['<sos>', 'there', \"'s\", 'a', 'police', 'station', 'across', 'the', 'street', '.', 'i', \"'m\", 'sure', 'we', \"'ll\", 'help', 'you', '.', '<eos>'], [tensor([[[[1.7743e-01, 3.7521e-01, 1.6678e-01, 2.5366e-02, 3.4719e-02,\n",
      "           5.5695e-02, 1.9681e-02, 2.7427e-03, 5.3430e-03, 2.6665e-04,\n",
      "           2.7988e-04, 2.0024e-03, 1.9536e-04, 1.6475e-04, 3.5695e-04,\n",
      "           1.0933e-03, 1.3268e-01]],\n",
      "\n",
      "         [[5.9442e-02, 1.7457e-01, 6.8187e-02, 6.6231e-02, 1.2160e-01,\n",
      "           3.4383e-01, 9.6388e-02, 1.5546e-03, 7.2361e-03, 3.6152e-04,\n",
      "           5.8413e-04, 5.4978e-03, 4.6751e-04, 6.1408e-04, 5.3136e-04,\n",
      "           7.8217e-03, 4.5081e-02]],\n",
      "\n",
      "         [[2.5901e-03, 4.0910e-03, 2.3251e-02, 2.0493e-03, 5.3184e-01,\n",
      "           3.5444e-01, 7.0159e-02, 2.1636e-03, 2.0102e-03, 8.7146e-05,\n",
      "           3.7551e-04, 1.1074e-03, 3.2351e-04, 1.2103e-03, 1.6823e-03,\n",
      "           8.8087e-04, 1.7392e-03]],\n",
      "\n",
      "         [[1.1537e-02, 4.0463e-02, 1.1963e-01, 8.5196e-03, 1.5613e-01,\n",
      "           4.7785e-01, 1.4848e-01, 4.7556e-03, 1.0242e-02, 1.3071e-03,\n",
      "           9.9085e-04, 2.5635e-03, 9.1511e-04, 3.5022e-03, 2.1266e-03,\n",
      "           2.3801e-03, 8.5981e-03]],\n",
      "\n",
      "         [[7.2577e-02, 1.5304e-01, 1.6273e-01, 3.2579e-02, 2.0103e-01,\n",
      "           1.4322e-01, 1.2201e-01, 4.2586e-03, 2.8589e-02, 3.4624e-03,\n",
      "           3.6977e-03, 2.8457e-03, 3.0219e-03, 1.1453e-03, 1.1842e-03,\n",
      "           8.1077e-03, 5.6500e-02]],\n",
      "\n",
      "         [[1.8500e-02, 4.6488e-03, 2.4297e-02, 1.5465e-02, 2.2031e-01,\n",
      "           4.1031e-01, 2.1691e-01, 3.1934e-02, 1.1519e-02, 4.8408e-03,\n",
      "           1.4349e-03, 6.2359e-03, 1.1308e-03, 3.9685e-03, 4.8328e-03,\n",
      "           6.7267e-03, 1.6938e-02]],\n",
      "\n",
      "         [[1.7600e-02, 8.5285e-03, 3.6417e-02, 1.0185e-02, 5.7025e-02,\n",
      "           4.7405e-01, 3.5295e-01, 1.3012e-03, 6.8646e-03, 2.4514e-03,\n",
      "           1.4334e-03, 7.7738e-03, 1.1087e-03, 8.8593e-04, 2.1551e-03,\n",
      "           3.8019e-03, 1.5472e-02]],\n",
      "\n",
      "         [[4.4535e-03, 1.5546e-02, 3.4853e-02, 2.8058e-03, 1.7927e-01,\n",
      "           4.7568e-01, 2.5066e-01, 6.8883e-03, 1.0078e-02, 5.0742e-05,\n",
      "           2.3165e-04, 8.1959e-04, 2.2286e-04, 8.3022e-03, 3.1336e-03,\n",
      "           4.2528e-03, 2.7499e-03]]]]), tensor([[[[1.7743e-01, 3.7521e-01, 1.6678e-01, 2.5366e-02, 3.4719e-02,\n",
      "           5.5695e-02, 1.9681e-02, 2.7427e-03, 5.3430e-03, 2.6665e-04,\n",
      "           2.7988e-04, 2.0024e-03, 1.9536e-04, 1.6475e-04, 3.5695e-04,\n",
      "           1.0933e-03, 1.3268e-01],\n",
      "          [4.3516e-02, 2.3388e-01, 9.6774e-02, 1.1312e-02, 7.5405e-02,\n",
      "           2.0868e-01, 2.4645e-01, 2.2417e-03, 8.4124e-03, 3.8403e-03,\n",
      "           6.8524e-03, 1.5869e-03, 7.1658e-03, 6.0570e-03, 1.9096e-03,\n",
      "           1.3840e-02, 3.2080e-02]],\n",
      "\n",
      "         [[5.9442e-02, 1.7457e-01, 6.8187e-02, 6.6231e-02, 1.2160e-01,\n",
      "           3.4383e-01, 9.6388e-02, 1.5546e-03, 7.2361e-03, 3.6152e-04,\n",
      "           5.8413e-04, 5.4978e-03, 4.6751e-04, 6.1408e-04, 5.3136e-04,\n",
      "           7.8217e-03, 4.5081e-02],\n",
      "          [1.1759e-01, 2.3108e-01, 4.9012e-02, 6.6589e-02, 5.7507e-02,\n",
      "           3.1980e-01, 5.6524e-02, 3.2067e-04, 1.6989e-03, 1.0950e-03,\n",
      "           1.4918e-03, 2.4627e-03, 1.3727e-03, 2.7629e-03, 4.0909e-03,\n",
      "           1.3290e-03, 8.5273e-02]],\n",
      "\n",
      "         [[2.5901e-03, 4.0910e-03, 2.3251e-02, 2.0493e-03, 5.3184e-01,\n",
      "           3.5444e-01, 7.0159e-02, 2.1636e-03, 2.0102e-03, 8.7146e-05,\n",
      "           3.7551e-04, 1.1074e-03, 3.2351e-04, 1.2103e-03, 1.6823e-03,\n",
      "           8.8087e-04, 1.7392e-03],\n",
      "          [3.6140e-02, 2.0164e-01, 9.2041e-02, 1.5718e-02, 3.6398e-02,\n",
      "           5.1119e-01, 5.0137e-02, 1.7705e-02, 6.8773e-03, 1.3557e-03,\n",
      "           1.0246e-03, 7.5426e-04, 1.0560e-03, 1.5902e-03, 2.1791e-03,\n",
      "           7.3264e-04, 2.3453e-02]],\n",
      "\n",
      "         [[1.1537e-02, 4.0463e-02, 1.1963e-01, 8.5196e-03, 1.5613e-01,\n",
      "           4.7785e-01, 1.4848e-01, 4.7556e-03, 1.0242e-02, 1.3071e-03,\n",
      "           9.9085e-04, 2.5635e-03, 9.1511e-04, 3.5022e-03, 2.1266e-03,\n",
      "           2.3801e-03, 8.5981e-03],\n",
      "          [1.7585e-02, 3.8539e-01, 1.1688e-01, 6.1168e-03, 4.6612e-02,\n",
      "           3.4324e-01, 5.6861e-02, 9.9924e-04, 1.3109e-03, 8.6840e-04,\n",
      "           1.9761e-03, 5.7103e-04, 2.4861e-03, 3.0448e-03, 2.3841e-03,\n",
      "           2.1779e-03, 1.1504e-02]],\n",
      "\n",
      "         [[7.2577e-02, 1.5304e-01, 1.6273e-01, 3.2579e-02, 2.0103e-01,\n",
      "           1.4322e-01, 1.2201e-01, 4.2586e-03, 2.8589e-02, 3.4624e-03,\n",
      "           3.6977e-03, 2.8457e-03, 3.0219e-03, 1.1453e-03, 1.1842e-03,\n",
      "           8.1077e-03, 5.6500e-02],\n",
      "          [7.4569e-02, 1.5840e-01, 6.9947e-02, 3.2184e-02, 1.3375e-01,\n",
      "           2.8473e-01, 1.5478e-01, 4.3325e-04, 4.6106e-03, 1.8679e-03,\n",
      "           6.9463e-03, 1.9899e-03, 6.2037e-03, 1.1151e-02, 1.1965e-02,\n",
      "           6.5998e-03, 3.9872e-02]],\n",
      "\n",
      "         [[1.8500e-02, 4.6488e-03, 2.4297e-02, 1.5465e-02, 2.2031e-01,\n",
      "           4.1031e-01, 2.1691e-01, 3.1934e-02, 1.1519e-02, 4.8408e-03,\n",
      "           1.4349e-03, 6.2359e-03, 1.1308e-03, 3.9685e-03, 4.8328e-03,\n",
      "           6.7266e-03, 1.6938e-02],\n",
      "          [6.4975e-02, 6.0509e-02, 4.2867e-02, 2.6802e-02, 2.3328e-01,\n",
      "           3.2681e-01, 1.9087e-01, 5.4084e-04, 2.0421e-03, 6.6373e-04,\n",
      "           5.4243e-04, 8.7638e-04, 4.5589e-04, 2.4238e-03, 3.2180e-03,\n",
      "           2.0516e-03, 4.1066e-02]],\n",
      "\n",
      "         [[1.7600e-02, 8.5285e-03, 3.6417e-02, 1.0185e-02, 5.7025e-02,\n",
      "           4.7405e-01, 3.5295e-01, 1.3012e-03, 6.8646e-03, 2.4514e-03,\n",
      "           1.4334e-03, 7.7738e-03, 1.1087e-03, 8.8593e-04, 2.1551e-03,\n",
      "           3.8019e-03, 1.5472e-02],\n",
      "          [4.8449e-02, 2.3196e-01, 1.8550e-01, 7.9776e-03, 6.1444e-02,\n",
      "           2.4574e-01, 1.8434e-01, 1.5650e-03, 3.5518e-03, 4.0135e-04,\n",
      "           3.4161e-04, 3.2155e-04, 3.3397e-04, 1.3332e-03, 6.8339e-04,\n",
      "           1.1787e-03, 2.4887e-02]],\n",
      "\n",
      "         [[4.4535e-03, 1.5546e-02, 3.4853e-02, 2.8058e-03, 1.7927e-01,\n",
      "           4.7568e-01, 2.5066e-01, 6.8883e-03, 1.0078e-02, 5.0742e-05,\n",
      "           2.3165e-04, 8.1959e-04, 2.2286e-04, 8.3023e-03, 3.1336e-03,\n",
      "           4.2528e-03, 2.7499e-03],\n",
      "          [7.6824e-02, 5.6918e-02, 3.7978e-02, 1.5925e-02, 2.7099e-01,\n",
      "           4.0040e-01, 8.1054e-02, 1.5507e-03, 7.2735e-03, 4.8642e-05,\n",
      "           7.2153e-04, 2.2128e-03, 5.3790e-04, 4.2269e-04, 5.4290e-03,\n",
      "           5.3130e-04, 4.1188e-02]]]]), tensor([[[[1.7743e-01, 3.7521e-01, 1.6678e-01, 2.5366e-02, 3.4719e-02,\n",
      "           5.5695e-02, 1.9681e-02, 2.7427e-03, 5.3430e-03, 2.6665e-04,\n",
      "           2.7988e-04, 2.0024e-03, 1.9536e-04, 1.6475e-04, 3.5695e-04,\n",
      "           1.0933e-03, 1.3268e-01],\n",
      "          [4.3516e-02, 2.3388e-01, 9.6774e-02, 1.1312e-02, 7.5405e-02,\n",
      "           2.0868e-01, 2.4645e-01, 2.2417e-03, 8.4124e-03, 3.8403e-03,\n",
      "           6.8524e-03, 1.5869e-03, 7.1658e-03, 6.0570e-03, 1.9096e-03,\n",
      "           1.3840e-02, 3.2080e-02],\n",
      "          [8.1063e-02, 1.4702e-01, 1.3583e-01, 1.6272e-02, 1.6078e-01,\n",
      "           3.4457e-02, 1.6977e-02, 3.1023e-02, 2.4909e-02, 1.6201e-01,\n",
      "           3.5713e-02, 6.8470e-03, 3.2916e-02, 3.0521e-02, 1.0057e-02,\n",
      "           1.6966e-02, 5.6646e-02]],\n",
      "\n",
      "         [[5.9442e-02, 1.7457e-01, 6.8187e-02, 6.6231e-02, 1.2160e-01,\n",
      "           3.4383e-01, 9.6388e-02, 1.5546e-03, 7.2361e-03, 3.6152e-04,\n",
      "           5.8413e-04, 5.4978e-03, 4.6751e-04, 6.1408e-04, 5.3136e-04,\n",
      "           7.8217e-03, 4.5081e-02],\n",
      "          [1.1759e-01, 2.3108e-01, 4.9012e-02, 6.6589e-02, 5.7507e-02,\n",
      "           3.1980e-01, 5.6524e-02, 3.2067e-04, 1.6989e-03, 1.0950e-03,\n",
      "           1.4918e-03, 2.4627e-03, 1.3727e-03, 2.7629e-03, 4.0909e-03,\n",
      "           1.3290e-03, 8.5273e-02],\n",
      "          [9.1519e-02, 2.5034e-01, 8.7355e-02, 4.7904e-02, 1.9848e-01,\n",
      "           1.6532e-01, 4.2233e-02, 2.3966e-03, 6.1855e-03, 1.5384e-02,\n",
      "           2.1763e-03, 1.1061e-02, 1.8585e-03, 3.1324e-03, 2.1897e-03,\n",
      "           4.2162e-03, 6.8249e-02]],\n",
      "\n",
      "         [[2.5901e-03, 4.0910e-03, 2.3251e-02, 2.0493e-03, 5.3184e-01,\n",
      "           3.5444e-01, 7.0159e-02, 2.1636e-03, 2.0102e-03, 8.7146e-05,\n",
      "           3.7551e-04, 1.1074e-03, 3.2351e-04, 1.2103e-03, 1.6823e-03,\n",
      "           8.8087e-04, 1.7392e-03],\n",
      "          [3.6140e-02, 2.0164e-01, 9.2041e-02, 1.5718e-02, 3.6398e-02,\n",
      "           5.1119e-01, 5.0137e-02, 1.7705e-02, 6.8773e-03, 1.3557e-03,\n",
      "           1.0246e-03, 7.5426e-04, 1.0560e-03, 1.5902e-03, 2.1791e-03,\n",
      "           7.3264e-04, 2.3453e-02],\n",
      "          [1.1522e-01, 2.9745e-01, 5.4066e-02, 5.6322e-02, 1.5310e-01,\n",
      "           1.3601e-01, 3.5955e-02, 5.2581e-03, 4.3369e-03, 3.0700e-02,\n",
      "           3.1786e-03, 9.7824e-03, 2.8809e-03, 2.9344e-03, 3.9768e-03,\n",
      "           3.9445e-03, 8.4887e-02]],\n",
      "\n",
      "         [[1.1537e-02, 4.0463e-02, 1.1963e-01, 8.5196e-03, 1.5613e-01,\n",
      "           4.7785e-01, 1.4848e-01, 4.7556e-03, 1.0242e-02, 1.3071e-03,\n",
      "           9.9085e-04, 2.5635e-03, 9.1511e-04, 3.5022e-03, 2.1266e-03,\n",
      "           2.3801e-03, 8.5981e-03],\n",
      "          [1.7585e-02, 3.8539e-01, 1.1688e-01, 6.1168e-03, 4.6612e-02,\n",
      "           3.4324e-01, 5.6861e-02, 9.9924e-04, 1.3109e-03, 8.6840e-04,\n",
      "           1.9761e-03, 5.7103e-04, 2.4861e-03, 3.0448e-03, 2.3841e-03,\n",
      "           2.1779e-03, 1.1504e-02],\n",
      "          [4.0584e-02, 1.0327e-01, 2.8698e-01, 5.4264e-03, 1.4224e-01,\n",
      "           2.9503e-01, 3.2236e-02, 3.1303e-02, 9.3257e-03, 3.7113e-03,\n",
      "           2.5519e-03, 1.9768e-03, 2.6039e-03, 7.2847e-03, 2.6060e-03,\n",
      "           2.8253e-03, 3.0044e-02]],\n",
      "\n",
      "         [[7.2577e-02, 1.5304e-01, 1.6273e-01, 3.2579e-02, 2.0103e-01,\n",
      "           1.4322e-01, 1.2201e-01, 4.2586e-03, 2.8589e-02, 3.4624e-03,\n",
      "           3.6977e-03, 2.8457e-03, 3.0219e-03, 1.1453e-03, 1.1842e-03,\n",
      "           8.1077e-03, 5.6500e-02],\n",
      "          [7.4569e-02, 1.5840e-01, 6.9947e-02, 3.2184e-02, 1.3375e-01,\n",
      "           2.8473e-01, 1.5478e-01, 4.3325e-04, 4.6106e-03, 1.8679e-03,\n",
      "           6.9463e-03, 1.9899e-03, 6.2037e-03, 1.1151e-02, 1.1965e-02,\n",
      "           6.5998e-03, 3.9872e-02],\n",
      "          [7.0524e-03, 4.8956e-02, 1.3307e-02, 6.4460e-03, 9.5386e-02,\n",
      "           7.1170e-01, 8.3515e-02, 2.6254e-03, 2.5613e-03, 4.5371e-03,\n",
      "           1.6703e-03, 4.5537e-03, 1.3544e-03, 4.7264e-03, 6.2111e-03,\n",
      "           9.0408e-04, 4.4957e-03]],\n",
      "\n",
      "         [[1.8500e-02, 4.6488e-03, 2.4297e-02, 1.5465e-02, 2.2031e-01,\n",
      "           4.1031e-01, 2.1691e-01, 3.1934e-02, 1.1519e-02, 4.8408e-03,\n",
      "           1.4349e-03, 6.2359e-03, 1.1308e-03, 3.9685e-03, 4.8328e-03,\n",
      "           6.7266e-03, 1.6938e-02],\n",
      "          [6.4975e-02, 6.0509e-02, 4.2867e-02, 2.6802e-02, 2.3328e-01,\n",
      "           3.2681e-01, 1.9087e-01, 5.4084e-04, 2.0421e-03, 6.6373e-04,\n",
      "           5.4243e-04, 8.7638e-04, 4.5589e-04, 2.4238e-03, 3.2180e-03,\n",
      "           2.0516e-03, 4.1066e-02],\n",
      "          [3.4049e-02, 1.9794e-02, 3.5795e-02, 1.5621e-02, 2.0767e-01,\n",
      "           3.3287e-01, 2.2698e-01, 1.9417e-02, 1.3882e-02, 4.0951e-02,\n",
      "           2.2765e-03, 3.3020e-03, 2.2202e-03, 8.6433e-03, 4.5617e-03,\n",
      "           7.8384e-03, 2.4137e-02]],\n",
      "\n",
      "         [[1.7600e-02, 8.5285e-03, 3.6417e-02, 1.0185e-02, 5.7025e-02,\n",
      "           4.7405e-01, 3.5295e-01, 1.3012e-03, 6.8646e-03, 2.4514e-03,\n",
      "           1.4334e-03, 7.7738e-03, 1.1087e-03, 8.8593e-04, 2.1551e-03,\n",
      "           3.8019e-03, 1.5472e-02],\n",
      "          [4.8449e-02, 2.3196e-01, 1.8550e-01, 7.9776e-03, 6.1444e-02,\n",
      "           2.4574e-01, 1.8434e-01, 1.5650e-03, 3.5518e-03, 4.0135e-04,\n",
      "           3.4161e-04, 3.2155e-04, 3.3397e-04, 1.3332e-03, 6.8339e-04,\n",
      "           1.1787e-03, 2.4887e-02],\n",
      "          [5.4983e-02, 1.4981e-01, 6.4043e-02, 8.1940e-03, 2.5492e-02,\n",
      "           3.2901e-01, 2.5257e-01, 1.6024e-02, 3.0384e-02, 1.3961e-02,\n",
      "           3.8257e-03, 3.2995e-03, 2.9166e-03, 6.7778e-03, 3.8303e-03,\n",
      "           1.0634e-03, 3.3814e-02]],\n",
      "\n",
      "         [[4.4535e-03, 1.5546e-02, 3.4853e-02, 2.8058e-03, 1.7927e-01,\n",
      "           4.7568e-01, 2.5066e-01, 6.8883e-03, 1.0078e-02, 5.0742e-05,\n",
      "           2.3165e-04, 8.1959e-04, 2.2286e-04, 8.3023e-03, 3.1336e-03,\n",
      "           4.2528e-03, 2.7499e-03],\n",
      "          [7.6824e-02, 5.6918e-02, 3.7978e-02, 1.5925e-02, 2.7099e-01,\n",
      "           4.0040e-01, 8.1054e-02, 1.5507e-03, 7.2735e-03, 4.8642e-05,\n",
      "           7.2153e-04, 2.2128e-03, 5.3790e-04, 4.2269e-04, 5.4290e-03,\n",
      "           5.3130e-04, 4.1188e-02],\n",
      "          [4.0531e-02, 2.4389e-02, 3.8391e-02, 1.9504e-02, 3.8249e-01,\n",
      "           1.9288e-01, 1.0416e-01, 1.2396e-02, 2.1664e-02, 9.9765e-03,\n",
      "           9.3922e-03, 1.8724e-02, 8.4772e-03, 4.1400e-02, 3.5819e-02,\n",
      "           1.3561e-02, 2.6241e-02]]]]), tensor([[[[1.7743e-01, 3.7521e-01, 1.6678e-01, 2.5366e-02, 3.4719e-02,\n",
      "           5.5695e-02, 1.9681e-02, 2.7427e-03, 5.3430e-03, 2.6665e-04,\n",
      "           2.7988e-04, 2.0024e-03, 1.9536e-04, 1.6475e-04, 3.5695e-04,\n",
      "           1.0933e-03, 1.3268e-01],\n",
      "          [4.3516e-02, 2.3388e-01, 9.6774e-02, 1.1312e-02, 7.5405e-02,\n",
      "           2.0868e-01, 2.4645e-01, 2.2417e-03, 8.4124e-03, 3.8403e-03,\n",
      "           6.8524e-03, 1.5869e-03, 7.1658e-03, 6.0570e-03, 1.9096e-03,\n",
      "           1.3840e-02, 3.2080e-02],\n",
      "          [8.1063e-02, 1.4702e-01, 1.3583e-01, 1.6272e-02, 1.6078e-01,\n",
      "           3.4457e-02, 1.6977e-02, 3.1023e-02, 2.4909e-02, 1.6201e-01,\n",
      "           3.5713e-02, 6.8470e-03, 3.2916e-02, 3.0521e-02, 1.0057e-02,\n",
      "           1.6966e-02, 5.6646e-02],\n",
      "          [1.5585e-01, 1.9927e-01, 1.7719e-02, 4.3789e-01, 7.2047e-03,\n",
      "           6.8037e-03, 1.2710e-03, 2.0167e-04, 4.0369e-04, 3.4111e-02,\n",
      "           1.2064e-03, 2.1071e-03, 9.2715e-04, 2.3399e-03, 1.7485e-03,\n",
      "           6.4412e-04, 1.3031e-01]],\n",
      "\n",
      "         [[5.9442e-02, 1.7457e-01, 6.8187e-02, 6.6231e-02, 1.2160e-01,\n",
      "           3.4383e-01, 9.6388e-02, 1.5546e-03, 7.2361e-03, 3.6152e-04,\n",
      "           5.8413e-04, 5.4978e-03, 4.6751e-04, 6.1408e-04, 5.3136e-04,\n",
      "           7.8217e-03, 4.5081e-02],\n",
      "          [1.1759e-01, 2.3108e-01, 4.9012e-02, 6.6589e-02, 5.7507e-02,\n",
      "           3.1980e-01, 5.6524e-02, 3.2067e-04, 1.6989e-03, 1.0950e-03,\n",
      "           1.4918e-03, 2.4627e-03, 1.3727e-03, 2.7629e-03, 4.0909e-03,\n",
      "           1.3290e-03, 8.5273e-02],\n",
      "          [9.1519e-02, 2.5034e-01, 8.7355e-02, 4.7904e-02, 1.9848e-01,\n",
      "           1.6532e-01, 4.2233e-02, 2.3966e-03, 6.1855e-03, 1.5384e-02,\n",
      "           2.1763e-03, 1.1061e-02, 1.8585e-03, 3.1324e-03, 2.1897e-03,\n",
      "           4.2162e-03, 6.8249e-02],\n",
      "          [6.9856e-02, 9.9510e-02, 9.7398e-03, 7.2912e-01, 1.2160e-02,\n",
      "           1.0836e-02, 2.9143e-03, 8.4413e-06, 1.1033e-04, 3.4721e-03,\n",
      "           2.0615e-04, 1.7303e-04, 1.8094e-04, 7.1524e-05, 3.1669e-04,\n",
      "           1.4845e-04, 6.1174e-02]],\n",
      "\n",
      "         [[2.5901e-03, 4.0910e-03, 2.3251e-02, 2.0493e-03, 5.3184e-01,\n",
      "           3.5444e-01, 7.0159e-02, 2.1636e-03, 2.0102e-03, 8.7146e-05,\n",
      "           3.7551e-04, 1.1074e-03, 3.2351e-04, 1.2103e-03, 1.6823e-03,\n",
      "           8.8087e-04, 1.7392e-03],\n",
      "          [3.6140e-02, 2.0164e-01, 9.2041e-02, 1.5718e-02, 3.6398e-02,\n",
      "           5.1119e-01, 5.0137e-02, 1.7705e-02, 6.8773e-03, 1.3557e-03,\n",
      "           1.0246e-03, 7.5426e-04, 1.0560e-03, 1.5902e-03, 2.1791e-03,\n",
      "           7.3264e-04, 2.3453e-02],\n",
      "          [1.1522e-01, 2.9745e-01, 5.4066e-02, 5.6322e-02, 1.5310e-01,\n",
      "           1.3601e-01, 3.5955e-02, 5.2581e-03, 4.3369e-03, 3.0700e-02,\n",
      "           3.1786e-03, 9.7824e-03, 2.8809e-03, 2.9344e-03, 3.9768e-03,\n",
      "           3.9445e-03, 8.4887e-02],\n",
      "          [2.3569e-01, 3.4942e-02, 3.7613e-03, 4.8740e-01, 4.6477e-03,\n",
      "           6.6741e-03, 4.0859e-03, 1.8617e-04, 2.0253e-04, 1.3619e-03,\n",
      "           1.1879e-04, 6.4143e-04, 1.0480e-04, 1.3035e-04, 3.2315e-04,\n",
      "           4.1631e-04, 2.1931e-01]],\n",
      "\n",
      "         [[1.1537e-02, 4.0463e-02, 1.1963e-01, 8.5196e-03, 1.5613e-01,\n",
      "           4.7785e-01, 1.4848e-01, 4.7556e-03, 1.0242e-02, 1.3071e-03,\n",
      "           9.9085e-04, 2.5635e-03, 9.1511e-04, 3.5022e-03, 2.1266e-03,\n",
      "           2.3801e-03, 8.5981e-03],\n",
      "          [1.7585e-02, 3.8539e-01, 1.1688e-01, 6.1168e-03, 4.6612e-02,\n",
      "           3.4324e-01, 5.6861e-02, 9.9924e-04, 1.3109e-03, 8.6840e-04,\n",
      "           1.9761e-03, 5.7103e-04, 2.4861e-03, 3.0448e-03, 2.3841e-03,\n",
      "           2.1779e-03, 1.1504e-02],\n",
      "          [4.0584e-02, 1.0327e-01, 2.8698e-01, 5.4264e-03, 1.4224e-01,\n",
      "           2.9503e-01, 3.2236e-02, 3.1303e-02, 9.3257e-03, 3.7113e-03,\n",
      "           2.5519e-03, 1.9768e-03, 2.6039e-03, 7.2847e-03, 2.6060e-03,\n",
      "           2.8253e-03, 3.0044e-02],\n",
      "          [1.4611e-01, 3.8618e-02, 1.3763e-02, 5.7042e-01, 6.0486e-02,\n",
      "           2.8917e-02, 3.0115e-03, 6.6923e-05, 4.9160e-04, 1.8771e-03,\n",
      "           2.7887e-04, 7.1538e-04, 2.5841e-04, 1.1463e-03, 1.2130e-03,\n",
      "           2.9912e-04, 1.3233e-01]],\n",
      "\n",
      "         [[7.2577e-02, 1.5304e-01, 1.6273e-01, 3.2579e-02, 2.0103e-01,\n",
      "           1.4322e-01, 1.2201e-01, 4.2586e-03, 2.8589e-02, 3.4624e-03,\n",
      "           3.6977e-03, 2.8457e-03, 3.0219e-03, 1.1453e-03, 1.1842e-03,\n",
      "           8.1077e-03, 5.6500e-02],\n",
      "          [7.4569e-02, 1.5840e-01, 6.9947e-02, 3.2184e-02, 1.3375e-01,\n",
      "           2.8473e-01, 1.5478e-01, 4.3325e-04, 4.6106e-03, 1.8679e-03,\n",
      "           6.9463e-03, 1.9899e-03, 6.2037e-03, 1.1151e-02, 1.1965e-02,\n",
      "           6.5998e-03, 3.9872e-02],\n",
      "          [7.0524e-03, 4.8956e-02, 1.3307e-02, 6.4460e-03, 9.5386e-02,\n",
      "           7.1170e-01, 8.3515e-02, 2.6254e-03, 2.5613e-03, 4.5371e-03,\n",
      "           1.6703e-03, 4.5537e-03, 1.3544e-03, 4.7264e-03, 6.2111e-03,\n",
      "           9.0408e-04, 4.4957e-03],\n",
      "          [1.6082e-01, 1.0973e-02, 6.1483e-03, 5.5964e-01, 3.4907e-02,\n",
      "           1.5120e-02, 1.0630e-03, 1.2701e-04, 2.8810e-04, 1.8789e-02,\n",
      "           1.0288e-03, 4.6292e-03, 1.0572e-03, 4.0566e-03, 7.3833e-03,\n",
      "           1.1459e-03, 1.7283e-01]],\n",
      "\n",
      "         [[1.8500e-02, 4.6488e-03, 2.4297e-02, 1.5465e-02, 2.2031e-01,\n",
      "           4.1031e-01, 2.1691e-01, 3.1934e-02, 1.1519e-02, 4.8408e-03,\n",
      "           1.4349e-03, 6.2359e-03, 1.1308e-03, 3.9685e-03, 4.8328e-03,\n",
      "           6.7266e-03, 1.6938e-02],\n",
      "          [6.4975e-02, 6.0509e-02, 4.2867e-02, 2.6802e-02, 2.3328e-01,\n",
      "           3.2681e-01, 1.9087e-01, 5.4084e-04, 2.0421e-03, 6.6373e-04,\n",
      "           5.4243e-04, 8.7638e-04, 4.5589e-04, 2.4238e-03, 3.2180e-03,\n",
      "           2.0516e-03, 4.1066e-02],\n",
      "          [3.4049e-02, 1.9794e-02, 3.5795e-02, 1.5621e-02, 2.0767e-01,\n",
      "           3.3287e-01, 2.2698e-01, 1.9417e-02, 1.3882e-02, 4.0951e-02,\n",
      "           2.2765e-03, 3.3020e-03, 2.2202e-03, 8.6433e-03, 4.5617e-03,\n",
      "           7.8384e-03, 2.4137e-02],\n",
      "          [9.2918e-02, 1.3326e-02, 3.2757e-03, 7.5830e-01, 1.6788e-02,\n",
      "           2.4435e-02, 2.7181e-03, 1.9268e-05, 2.3064e-04, 1.1414e-03,\n",
      "           6.3232e-05, 4.0612e-04, 4.8193e-05, 2.5352e-04, 9.1938e-04,\n",
      "           7.9316e-05, 8.5081e-02]],\n",
      "\n",
      "         [[1.7600e-02, 8.5285e-03, 3.6417e-02, 1.0185e-02, 5.7025e-02,\n",
      "           4.7405e-01, 3.5295e-01, 1.3012e-03, 6.8646e-03, 2.4514e-03,\n",
      "           1.4334e-03, 7.7738e-03, 1.1087e-03, 8.8593e-04, 2.1551e-03,\n",
      "           3.8019e-03, 1.5472e-02],\n",
      "          [4.8449e-02, 2.3196e-01, 1.8550e-01, 7.9776e-03, 6.1444e-02,\n",
      "           2.4574e-01, 1.8434e-01, 1.5650e-03, 3.5518e-03, 4.0135e-04,\n",
      "           3.4161e-04, 3.2155e-04, 3.3397e-04, 1.3332e-03, 6.8339e-04,\n",
      "           1.1787e-03, 2.4887e-02],\n",
      "          [5.4983e-02, 1.4981e-01, 6.4043e-02, 8.1940e-03, 2.5492e-02,\n",
      "           3.2901e-01, 2.5257e-01, 1.6024e-02, 3.0384e-02, 1.3961e-02,\n",
      "           3.8257e-03, 3.2995e-03, 2.9166e-03, 6.7778e-03, 3.8303e-03,\n",
      "           1.0634e-03, 3.3814e-02],\n",
      "          [1.1571e-01, 1.1377e-02, 1.0125e-02, 6.3387e-01, 9.6633e-03,\n",
      "           2.5855e-02, 1.4830e-02, 9.8082e-03, 6.4630e-03, 1.7517e-02,\n",
      "           2.0453e-03, 3.8089e-03, 1.3604e-03, 3.8810e-03, 7.1405e-03,\n",
      "           3.7154e-04, 1.2617e-01]],\n",
      "\n",
      "         [[4.4535e-03, 1.5546e-02, 3.4853e-02, 2.8058e-03, 1.7927e-01,\n",
      "           4.7568e-01, 2.5066e-01, 6.8883e-03, 1.0078e-02, 5.0742e-05,\n",
      "           2.3165e-04, 8.1959e-04, 2.2286e-04, 8.3023e-03, 3.1336e-03,\n",
      "           4.2528e-03, 2.7499e-03],\n",
      "          [7.6824e-02, 5.6918e-02, 3.7978e-02, 1.5925e-02, 2.7099e-01,\n",
      "           4.0040e-01, 8.1054e-02, 1.5507e-03, 7.2735e-03, 4.8642e-05,\n",
      "           7.2153e-04, 2.2128e-03, 5.3790e-04, 4.2269e-04, 5.4290e-03,\n",
      "           5.3130e-04, 4.1188e-02],\n",
      "          [4.0531e-02, 2.4389e-02, 3.8391e-02, 1.9504e-02, 3.8249e-01,\n",
      "           1.9288e-01, 1.0416e-01, 1.2396e-02, 2.1664e-02, 9.9765e-03,\n",
      "           9.3922e-03, 1.8724e-02, 8.4772e-03, 4.1400e-02, 3.5819e-02,\n",
      "           1.3561e-02, 2.6241e-02],\n",
      "          [7.8301e-02, 7.9292e-03, 2.1941e-03, 7.9581e-01, 1.4639e-02,\n",
      "           1.1975e-02, 2.4525e-03, 6.0641e-04, 9.8893e-04, 4.1403e-03,\n",
      "           3.4231e-04, 1.3430e-03, 2.8789e-04, 1.1620e-03, 1.7369e-03,\n",
      "           3.4606e-04, 7.5750e-02]]]]), tensor([[[[1.7743e-01, 3.7521e-01, 1.6678e-01, 2.5366e-02, 3.4719e-02,\n",
      "           5.5695e-02, 1.9681e-02, 2.7427e-03, 5.3430e-03, 2.6665e-04,\n",
      "           2.7988e-04, 2.0024e-03, 1.9536e-04, 1.6475e-04, 3.5695e-04,\n",
      "           1.0933e-03, 1.3268e-01],\n",
      "          [4.3516e-02, 2.3388e-01, 9.6774e-02, 1.1312e-02, 7.5405e-02,\n",
      "           2.0868e-01, 2.4645e-01, 2.2417e-03, 8.4124e-03, 3.8403e-03,\n",
      "           6.8524e-03, 1.5869e-03, 7.1658e-03, 6.0570e-03, 1.9097e-03,\n",
      "           1.3840e-02, 3.2080e-02],\n",
      "          [8.1063e-02, 1.4702e-01, 1.3583e-01, 1.6272e-02, 1.6078e-01,\n",
      "           3.4457e-02, 1.6977e-02, 3.1023e-02, 2.4909e-02, 1.6201e-01,\n",
      "           3.5713e-02, 6.8470e-03, 3.2916e-02, 3.0521e-02, 1.0057e-02,\n",
      "           1.6966e-02, 5.6646e-02],\n",
      "          [1.5585e-01, 1.9927e-01, 1.7719e-02, 4.3789e-01, 7.2047e-03,\n",
      "           6.8037e-03, 1.2710e-03, 2.0167e-04, 4.0369e-04, 3.4111e-02,\n",
      "           1.2064e-03, 2.1071e-03, 9.2715e-04, 2.3399e-03, 1.7485e-03,\n",
      "           6.4412e-04, 1.3031e-01],\n",
      "          [1.3060e-01, 1.8805e-01, 1.7981e-02, 4.5097e-01, 2.0331e-02,\n",
      "           4.7270e-02, 1.8210e-02, 2.6018e-04, 3.2665e-04, 1.0140e-04,\n",
      "           8.1919e-05, 2.5576e-04, 7.1219e-05, 2.5921e-04, 3.5456e-04,\n",
      "           1.3356e-04, 1.2474e-01]],\n",
      "\n",
      "         [[5.9442e-02, 1.7457e-01, 6.8187e-02, 6.6231e-02, 1.2160e-01,\n",
      "           3.4383e-01, 9.6388e-02, 1.5546e-03, 7.2361e-03, 3.6152e-04,\n",
      "           5.8413e-04, 5.4978e-03, 4.6751e-04, 6.1408e-04, 5.3136e-04,\n",
      "           7.8217e-03, 4.5081e-02],\n",
      "          [1.1759e-01, 2.3108e-01, 4.9012e-02, 6.6589e-02, 5.7507e-02,\n",
      "           3.1980e-01, 5.6524e-02, 3.2067e-04, 1.6989e-03, 1.0950e-03,\n",
      "           1.4918e-03, 2.4627e-03, 1.3727e-03, 2.7629e-03, 4.0909e-03,\n",
      "           1.3290e-03, 8.5273e-02],\n",
      "          [9.1519e-02, 2.5034e-01, 8.7355e-02, 4.7904e-02, 1.9848e-01,\n",
      "           1.6532e-01, 4.2233e-02, 2.3966e-03, 6.1855e-03, 1.5384e-02,\n",
      "           2.1763e-03, 1.1061e-02, 1.8585e-03, 3.1324e-03, 2.1897e-03,\n",
      "           4.2162e-03, 6.8249e-02],\n",
      "          [6.9856e-02, 9.9510e-02, 9.7398e-03, 7.2912e-01, 1.2160e-02,\n",
      "           1.0836e-02, 2.9143e-03, 8.4413e-06, 1.1033e-04, 3.4721e-03,\n",
      "           2.0615e-04, 1.7303e-04, 1.8094e-04, 7.1524e-05, 3.1669e-04,\n",
      "           1.4845e-04, 6.1174e-02],\n",
      "          [1.4469e-01, 1.5470e-01, 3.8286e-02, 3.3086e-01, 5.4361e-02,\n",
      "           1.0198e-01, 4.0514e-02, 4.9126e-03, 4.6209e-03, 2.5702e-04,\n",
      "           7.4973e-04, 6.8863e-04, 7.5471e-04, 1.0092e-03, 2.5488e-03,\n",
      "           2.4052e-03, 1.1666e-01]],\n",
      "\n",
      "         [[2.5901e-03, 4.0910e-03, 2.3251e-02, 2.0493e-03, 5.3184e-01,\n",
      "           3.5444e-01, 7.0159e-02, 2.1636e-03, 2.0102e-03, 8.7146e-05,\n",
      "           3.7551e-04, 1.1074e-03, 3.2351e-04, 1.2103e-03, 1.6823e-03,\n",
      "           8.8087e-04, 1.7392e-03],\n",
      "          [3.6140e-02, 2.0164e-01, 9.2041e-02, 1.5718e-02, 3.6398e-02,\n",
      "           5.1119e-01, 5.0137e-02, 1.7705e-02, 6.8773e-03, 1.3557e-03,\n",
      "           1.0246e-03, 7.5426e-04, 1.0560e-03, 1.5902e-03, 2.1791e-03,\n",
      "           7.3264e-04, 2.3453e-02],\n",
      "          [1.1522e-01, 2.9745e-01, 5.4066e-02, 5.6322e-02, 1.5310e-01,\n",
      "           1.3601e-01, 3.5955e-02, 5.2581e-03, 4.3369e-03, 3.0700e-02,\n",
      "           3.1786e-03, 9.7824e-03, 2.8809e-03, 2.9344e-03, 3.9768e-03,\n",
      "           3.9445e-03, 8.4887e-02],\n",
      "          [2.3569e-01, 3.4942e-02, 3.7613e-03, 4.8740e-01, 4.6477e-03,\n",
      "           6.6741e-03, 4.0859e-03, 1.8617e-04, 2.0253e-04, 1.3619e-03,\n",
      "           1.1879e-04, 6.4143e-04, 1.0480e-04, 1.3035e-04, 3.2315e-04,\n",
      "           4.1631e-04, 2.1931e-01],\n",
      "          [3.3563e-01, 1.0633e-02, 6.2996e-03, 2.6528e-01, 1.4737e-03,\n",
      "           3.1002e-03, 2.2025e-03, 4.2374e-03, 1.4868e-03, 2.4901e-04,\n",
      "           1.0706e-04, 1.3979e-04, 1.0223e-04, 1.8510e-04, 1.8866e-04,\n",
      "           6.6156e-04, 3.6802e-01]],\n",
      "\n",
      "         [[1.1537e-02, 4.0463e-02, 1.1963e-01, 8.5196e-03, 1.5613e-01,\n",
      "           4.7785e-01, 1.4848e-01, 4.7556e-03, 1.0242e-02, 1.3071e-03,\n",
      "           9.9085e-04, 2.5635e-03, 9.1511e-04, 3.5022e-03, 2.1266e-03,\n",
      "           2.3801e-03, 8.5981e-03],\n",
      "          [1.7585e-02, 3.8539e-01, 1.1688e-01, 6.1168e-03, 4.6612e-02,\n",
      "           3.4324e-01, 5.6861e-02, 9.9924e-04, 1.3109e-03, 8.6840e-04,\n",
      "           1.9761e-03, 5.7103e-04, 2.4861e-03, 3.0448e-03, 2.3841e-03,\n",
      "           2.1779e-03, 1.1504e-02],\n",
      "          [4.0584e-02, 1.0327e-01, 2.8698e-01, 5.4264e-03, 1.4224e-01,\n",
      "           2.9503e-01, 3.2236e-02, 3.1303e-02, 9.3257e-03, 3.7113e-03,\n",
      "           2.5519e-03, 1.9768e-03, 2.6039e-03, 7.2847e-03, 2.6060e-03,\n",
      "           2.8253e-03, 3.0044e-02],\n",
      "          [1.4611e-01, 3.8618e-02, 1.3763e-02, 5.7042e-01, 6.0486e-02,\n",
      "           2.8917e-02, 3.0115e-03, 6.6924e-05, 4.9160e-04, 1.8771e-03,\n",
      "           2.7887e-04, 7.1538e-04, 2.5841e-04, 1.1463e-03, 1.2130e-03,\n",
      "           2.9912e-04, 1.3233e-01],\n",
      "          [1.8096e-01, 1.3511e-01, 4.0123e-02, 3.8979e-01, 4.2671e-02,\n",
      "           5.3638e-02, 7.3994e-03, 3.6485e-04, 8.5969e-04, 5.3534e-04,\n",
      "           3.4825e-04, 1.0669e-03, 3.6083e-04, 2.0015e-03, 1.4886e-03,\n",
      "           6.3166e-04, 1.4266e-01]],\n",
      "\n",
      "         [[7.2577e-02, 1.5304e-01, 1.6273e-01, 3.2579e-02, 2.0103e-01,\n",
      "           1.4322e-01, 1.2201e-01, 4.2586e-03, 2.8589e-02, 3.4624e-03,\n",
      "           3.6977e-03, 2.8457e-03, 3.0219e-03, 1.1453e-03, 1.1842e-03,\n",
      "           8.1077e-03, 5.6500e-02],\n",
      "          [7.4569e-02, 1.5840e-01, 6.9947e-02, 3.2184e-02, 1.3375e-01,\n",
      "           2.8473e-01, 1.5478e-01, 4.3325e-04, 4.6106e-03, 1.8679e-03,\n",
      "           6.9463e-03, 1.9899e-03, 6.2037e-03, 1.1151e-02, 1.1965e-02,\n",
      "           6.5998e-03, 3.9872e-02],\n",
      "          [7.0524e-03, 4.8956e-02, 1.3307e-02, 6.4460e-03, 9.5386e-02,\n",
      "           7.1170e-01, 8.3515e-02, 2.6254e-03, 2.5613e-03, 4.5371e-03,\n",
      "           1.6703e-03, 4.5537e-03, 1.3544e-03, 4.7264e-03, 6.2111e-03,\n",
      "           9.0408e-04, 4.4957e-03],\n",
      "          [1.6082e-01, 1.0973e-02, 6.1483e-03, 5.5964e-01, 3.4907e-02,\n",
      "           1.5120e-02, 1.0630e-03, 1.2701e-04, 2.8810e-04, 1.8789e-02,\n",
      "           1.0288e-03, 4.6292e-03, 1.0572e-03, 4.0566e-03, 7.3833e-03,\n",
      "           1.1459e-03, 1.7283e-01],\n",
      "          [5.9382e-02, 1.3249e-02, 6.4481e-03, 8.3720e-01, 6.6907e-03,\n",
      "           8.3006e-03, 1.6924e-03, 2.5266e-05, 2.8911e-04, 2.2970e-05,\n",
      "           5.7880e-05, 6.0462e-05, 4.4967e-05, 6.8823e-05, 5.3506e-04,\n",
      "           5.9903e-05, 6.5873e-02]],\n",
      "\n",
      "         [[1.8500e-02, 4.6488e-03, 2.4297e-02, 1.5465e-02, 2.2031e-01,\n",
      "           4.1031e-01, 2.1691e-01, 3.1934e-02, 1.1519e-02, 4.8408e-03,\n",
      "           1.4349e-03, 6.2359e-03, 1.1308e-03, 3.9685e-03, 4.8328e-03,\n",
      "           6.7266e-03, 1.6938e-02],\n",
      "          [6.4975e-02, 6.0509e-02, 4.2867e-02, 2.6802e-02, 2.3328e-01,\n",
      "           3.2681e-01, 1.9087e-01, 5.4084e-04, 2.0421e-03, 6.6373e-04,\n",
      "           5.4243e-04, 8.7638e-04, 4.5589e-04, 2.4238e-03, 3.2180e-03,\n",
      "           2.0516e-03, 4.1066e-02],\n",
      "          [3.4049e-02, 1.9794e-02, 3.5795e-02, 1.5621e-02, 2.0767e-01,\n",
      "           3.3287e-01, 2.2698e-01, 1.9417e-02, 1.3882e-02, 4.0951e-02,\n",
      "           2.2765e-03, 3.3020e-03, 2.2202e-03, 8.6433e-03, 4.5617e-03,\n",
      "           7.8384e-03, 2.4137e-02],\n",
      "          [9.2918e-02, 1.3326e-02, 3.2757e-03, 7.5830e-01, 1.6788e-02,\n",
      "           2.4435e-02, 2.7181e-03, 1.9268e-05, 2.3064e-04, 1.1414e-03,\n",
      "           6.3232e-05, 4.0612e-04, 4.8193e-05, 2.5352e-04, 9.1938e-04,\n",
      "           7.9316e-05, 8.5081e-02],\n",
      "          [1.2464e-01, 1.2216e-02, 4.9200e-03, 7.1155e-01, 6.1603e-03,\n",
      "           1.1089e-02, 3.5330e-03, 1.4986e-05, 1.7792e-04, 2.4991e-05,\n",
      "           1.8962e-05, 7.6402e-05, 1.4610e-05, 1.1484e-05, 4.2298e-05,\n",
      "           3.5418e-05, 1.2547e-01]],\n",
      "\n",
      "         [[1.7600e-02, 8.5285e-03, 3.6417e-02, 1.0185e-02, 5.7025e-02,\n",
      "           4.7405e-01, 3.5295e-01, 1.3012e-03, 6.8646e-03, 2.4514e-03,\n",
      "           1.4334e-03, 7.7738e-03, 1.1087e-03, 8.8593e-04, 2.1551e-03,\n",
      "           3.8019e-03, 1.5472e-02],\n",
      "          [4.8449e-02, 2.3196e-01, 1.8550e-01, 7.9776e-03, 6.1444e-02,\n",
      "           2.4574e-01, 1.8434e-01, 1.5650e-03, 3.5518e-03, 4.0135e-04,\n",
      "           3.4161e-04, 3.2155e-04, 3.3397e-04, 1.3332e-03, 6.8339e-04,\n",
      "           1.1787e-03, 2.4887e-02],\n",
      "          [5.4983e-02, 1.4981e-01, 6.4043e-02, 8.1940e-03, 2.5492e-02,\n",
      "           3.2901e-01, 2.5257e-01, 1.6024e-02, 3.0384e-02, 1.3961e-02,\n",
      "           3.8257e-03, 3.2995e-03, 2.9166e-03, 6.7778e-03, 3.8303e-03,\n",
      "           1.0634e-03, 3.3814e-02],\n",
      "          [1.1571e-01, 1.1377e-02, 1.0125e-02, 6.3387e-01, 9.6633e-03,\n",
      "           2.5855e-02, 1.4830e-02, 9.8082e-03, 6.4630e-03, 1.7517e-02,\n",
      "           2.0453e-03, 3.8089e-03, 1.3604e-03, 3.8810e-03, 7.1405e-03,\n",
      "           3.7154e-04, 1.2617e-01],\n",
      "          [1.8162e-01, 1.5318e-02, 1.0776e-01, 3.0586e-01, 9.8343e-02,\n",
      "           4.6903e-02, 1.9474e-02, 1.1837e-02, 2.3956e-02, 5.9769e-04,\n",
      "           2.2599e-03, 7.4513e-03, 1.8609e-03, 3.5252e-03, 5.6119e-03,\n",
      "           2.3303e-03, 1.6529e-01]],\n",
      "\n",
      "         [[4.4535e-03, 1.5546e-02, 3.4853e-02, 2.8058e-03, 1.7927e-01,\n",
      "           4.7568e-01, 2.5066e-01, 6.8883e-03, 1.0078e-02, 5.0742e-05,\n",
      "           2.3165e-04, 8.1959e-04, 2.2286e-04, 8.3023e-03, 3.1336e-03,\n",
      "           4.2528e-03, 2.7499e-03],\n",
      "          [7.6824e-02, 5.6918e-02, 3.7978e-02, 1.5925e-02, 2.7099e-01,\n",
      "           4.0040e-01, 8.1054e-02, 1.5507e-03, 7.2735e-03, 4.8642e-05,\n",
      "           7.2153e-04, 2.2128e-03, 5.3790e-04, 4.2269e-04, 5.4290e-03,\n",
      "           5.3130e-04, 4.1188e-02],\n",
      "          [4.0531e-02, 2.4389e-02, 3.8391e-02, 1.9504e-02, 3.8249e-01,\n",
      "           1.9288e-01, 1.0416e-01, 1.2396e-02, 2.1664e-02, 9.9765e-03,\n",
      "           9.3922e-03, 1.8724e-02, 8.4772e-03, 4.1400e-02, 3.5819e-02,\n",
      "           1.3561e-02, 2.6241e-02],\n",
      "          [7.8301e-02, 7.9292e-03, 2.1941e-03, 7.9581e-01, 1.4639e-02,\n",
      "           1.1975e-02, 2.4525e-03, 6.0641e-04, 9.8893e-04, 4.1403e-03,\n",
      "           3.4231e-04, 1.3430e-03, 2.8789e-04, 1.1620e-03, 1.7369e-03,\n",
      "           3.4606e-04, 7.5749e-02],\n",
      "          [1.8876e-01, 6.2290e-02, 1.9610e-02, 4.1921e-01, 4.8494e-02,\n",
      "           6.5321e-02, 2.1007e-02, 2.1620e-03, 6.4221e-03, 4.8786e-04,\n",
      "           5.3908e-04, 8.6527e-04, 4.4358e-04, 3.9504e-04, 1.0972e-03,\n",
      "           1.1805e-03, 1.6172e-01]]]]), tensor([[[[1.7743e-01, 3.7521e-01, 1.6678e-01, 2.5366e-02, 3.4719e-02,\n",
      "           5.5695e-02, 1.9681e-02, 2.7427e-03, 5.3430e-03, 2.6665e-04,\n",
      "           2.7988e-04, 2.0024e-03, 1.9536e-04, 1.6475e-04, 3.5695e-04,\n",
      "           1.0933e-03, 1.3268e-01],\n",
      "          [4.3516e-02, 2.3388e-01, 9.6774e-02, 1.1312e-02, 7.5405e-02,\n",
      "           2.0868e-01, 2.4645e-01, 2.2417e-03, 8.4124e-03, 3.8403e-03,\n",
      "           6.8524e-03, 1.5869e-03, 7.1658e-03, 6.0570e-03, 1.9097e-03,\n",
      "           1.3840e-02, 3.2080e-02],\n",
      "          [8.1063e-02, 1.4702e-01, 1.3583e-01, 1.6272e-02, 1.6078e-01,\n",
      "           3.4457e-02, 1.6977e-02, 3.1023e-02, 2.4909e-02, 1.6201e-01,\n",
      "           3.5713e-02, 6.8470e-03, 3.2916e-02, 3.0521e-02, 1.0057e-02,\n",
      "           1.6966e-02, 5.6646e-02],\n",
      "          [1.5585e-01, 1.9927e-01, 1.7719e-02, 4.3789e-01, 7.2047e-03,\n",
      "           6.8037e-03, 1.2710e-03, 2.0167e-04, 4.0369e-04, 3.4111e-02,\n",
      "           1.2064e-03, 2.1071e-03, 9.2715e-04, 2.3399e-03, 1.7485e-03,\n",
      "           6.4412e-04, 1.3031e-01],\n",
      "          [1.3060e-01, 1.8805e-01, 1.7981e-02, 4.5097e-01, 2.0331e-02,\n",
      "           4.7270e-02, 1.8210e-02, 2.6018e-04, 3.2665e-04, 1.0140e-04,\n",
      "           8.1919e-05, 2.5576e-04, 7.1219e-05, 2.5921e-04, 3.5456e-04,\n",
      "           1.3356e-04, 1.2474e-01],\n",
      "          [1.6979e-01, 2.4596e-01, 3.0632e-01, 9.1252e-02, 3.6439e-02,\n",
      "           1.7458e-02, 1.3111e-02, 2.7164e-03, 1.2007e-02, 3.3953e-04,\n",
      "           4.5654e-04, 8.8566e-04, 3.5481e-04, 7.3110e-04, 6.1786e-04,\n",
      "           5.6720e-04, 1.0099e-01]],\n",
      "\n",
      "         [[5.9442e-02, 1.7457e-01, 6.8187e-02, 6.6231e-02, 1.2160e-01,\n",
      "           3.4383e-01, 9.6388e-02, 1.5546e-03, 7.2361e-03, 3.6152e-04,\n",
      "           5.8413e-04, 5.4978e-03, 4.6751e-04, 6.1408e-04, 5.3136e-04,\n",
      "           7.8217e-03, 4.5081e-02],\n",
      "          [1.1759e-01, 2.3108e-01, 4.9012e-02, 6.6589e-02, 5.7507e-02,\n",
      "           3.1980e-01, 5.6524e-02, 3.2067e-04, 1.6989e-03, 1.0950e-03,\n",
      "           1.4918e-03, 2.4627e-03, 1.3727e-03, 2.7629e-03, 4.0909e-03,\n",
      "           1.3290e-03, 8.5273e-02],\n",
      "          [9.1519e-02, 2.5034e-01, 8.7355e-02, 4.7904e-02, 1.9848e-01,\n",
      "           1.6532e-01, 4.2233e-02, 2.3966e-03, 6.1855e-03, 1.5384e-02,\n",
      "           2.1763e-03, 1.1061e-02, 1.8585e-03, 3.1324e-03, 2.1897e-03,\n",
      "           4.2162e-03, 6.8249e-02],\n",
      "          [6.9856e-02, 9.9510e-02, 9.7398e-03, 7.2912e-01, 1.2160e-02,\n",
      "           1.0836e-02, 2.9143e-03, 8.4413e-06, 1.1033e-04, 3.4721e-03,\n",
      "           2.0615e-04, 1.7303e-04, 1.8094e-04, 7.1524e-05, 3.1669e-04,\n",
      "           1.4845e-04, 6.1174e-02],\n",
      "          [1.4469e-01, 1.5470e-01, 3.8286e-02, 3.3086e-01, 5.4361e-02,\n",
      "           1.0198e-01, 4.0514e-02, 4.9126e-03, 4.6209e-03, 2.5702e-04,\n",
      "           7.4973e-04, 6.8863e-04, 7.5471e-04, 1.0092e-03, 2.5488e-03,\n",
      "           2.4052e-03, 1.1666e-01],\n",
      "          [4.1380e-02, 5.3111e-01, 1.2001e-01, 3.1567e-02, 7.6769e-02,\n",
      "           8.5241e-02, 3.6255e-02, 3.3021e-02, 1.4564e-02, 7.1014e-05,\n",
      "           2.5778e-04, 1.0160e-03, 2.3742e-04, 1.2582e-03, 1.0805e-03,\n",
      "           1.0215e-03, 2.5147e-02]],\n",
      "\n",
      "         [[2.5901e-03, 4.0910e-03, 2.3251e-02, 2.0493e-03, 5.3184e-01,\n",
      "           3.5444e-01, 7.0159e-02, 2.1636e-03, 2.0102e-03, 8.7146e-05,\n",
      "           3.7551e-04, 1.1074e-03, 3.2351e-04, 1.2103e-03, 1.6823e-03,\n",
      "           8.8087e-04, 1.7392e-03],\n",
      "          [3.6140e-02, 2.0164e-01, 9.2041e-02, 1.5718e-02, 3.6398e-02,\n",
      "           5.1119e-01, 5.0137e-02, 1.7705e-02, 6.8773e-03, 1.3557e-03,\n",
      "           1.0246e-03, 7.5426e-04, 1.0560e-03, 1.5902e-03, 2.1791e-03,\n",
      "           7.3264e-04, 2.3453e-02],\n",
      "          [1.1522e-01, 2.9745e-01, 5.4066e-02, 5.6322e-02, 1.5310e-01,\n",
      "           1.3601e-01, 3.5955e-02, 5.2581e-03, 4.3369e-03, 3.0700e-02,\n",
      "           3.1786e-03, 9.7824e-03, 2.8809e-03, 2.9344e-03, 3.9768e-03,\n",
      "           3.9445e-03, 8.4887e-02],\n",
      "          [2.3569e-01, 3.4942e-02, 3.7613e-03, 4.8740e-01, 4.6477e-03,\n",
      "           6.6741e-03, 4.0859e-03, 1.8617e-04, 2.0253e-04, 1.3619e-03,\n",
      "           1.1879e-04, 6.4143e-04, 1.0480e-04, 1.3035e-04, 3.2315e-04,\n",
      "           4.1631e-04, 2.1931e-01],\n",
      "          [3.3563e-01, 1.0633e-02, 6.2996e-03, 2.6528e-01, 1.4737e-03,\n",
      "           3.1002e-03, 2.2025e-03, 4.2374e-03, 1.4868e-03, 2.4901e-04,\n",
      "           1.0706e-04, 1.3979e-04, 1.0223e-04, 1.8510e-04, 1.8866e-04,\n",
      "           6.6156e-04, 3.6802e-01],\n",
      "          [1.1812e-01, 1.8619e-01, 3.4161e-01, 3.7683e-02, 1.3223e-02,\n",
      "           1.5574e-01, 1.3342e-02, 5.6146e-02, 1.1732e-02, 9.4183e-05,\n",
      "           1.2757e-04, 2.8065e-04, 1.0790e-04, 1.3657e-03, 2.0283e-03,\n",
      "           2.7659e-04, 6.1943e-02]],\n",
      "\n",
      "         [[1.1537e-02, 4.0463e-02, 1.1963e-01, 8.5196e-03, 1.5613e-01,\n",
      "           4.7785e-01, 1.4848e-01, 4.7556e-03, 1.0242e-02, 1.3071e-03,\n",
      "           9.9085e-04, 2.5635e-03, 9.1511e-04, 3.5022e-03, 2.1266e-03,\n",
      "           2.3801e-03, 8.5981e-03],\n",
      "          [1.7585e-02, 3.8539e-01, 1.1688e-01, 6.1168e-03, 4.6612e-02,\n",
      "           3.4324e-01, 5.6861e-02, 9.9924e-04, 1.3109e-03, 8.6840e-04,\n",
      "           1.9761e-03, 5.7103e-04, 2.4861e-03, 3.0448e-03, 2.3841e-03,\n",
      "           2.1779e-03, 1.1504e-02],\n",
      "          [4.0584e-02, 1.0327e-01, 2.8698e-01, 5.4264e-03, 1.4224e-01,\n",
      "           2.9503e-01, 3.2236e-02, 3.1303e-02, 9.3257e-03, 3.7113e-03,\n",
      "           2.5519e-03, 1.9768e-03, 2.6039e-03, 7.2847e-03, 2.6060e-03,\n",
      "           2.8253e-03, 3.0044e-02],\n",
      "          [1.4611e-01, 3.8618e-02, 1.3763e-02, 5.7042e-01, 6.0486e-02,\n",
      "           2.8917e-02, 3.0115e-03, 6.6924e-05, 4.9160e-04, 1.8771e-03,\n",
      "           2.7887e-04, 7.1538e-04, 2.5841e-04, 1.1463e-03, 1.2130e-03,\n",
      "           2.9912e-04, 1.3233e-01],\n",
      "          [1.8096e-01, 1.3511e-01, 4.0123e-02, 3.8979e-01, 4.2671e-02,\n",
      "           5.3638e-02, 7.3994e-03, 3.6485e-04, 8.5969e-04, 5.3534e-04,\n",
      "           3.4825e-04, 1.0669e-03, 3.6083e-04, 2.0015e-03, 1.4886e-03,\n",
      "           6.3166e-04, 1.4266e-01],\n",
      "          [6.8168e-02, 4.8001e-01, 3.2749e-01, 6.8742e-03, 3.0715e-02,\n",
      "           4.5035e-02, 5.7728e-03, 5.2437e-03, 6.4480e-04, 2.2516e-05,\n",
      "           2.6115e-05, 1.7930e-05, 2.5040e-05, 3.8697e-04, 1.5286e-04,\n",
      "           7.6735e-05, 2.9329e-02]],\n",
      "\n",
      "         [[7.2577e-02, 1.5304e-01, 1.6273e-01, 3.2579e-02, 2.0103e-01,\n",
      "           1.4322e-01, 1.2201e-01, 4.2586e-03, 2.8589e-02, 3.4624e-03,\n",
      "           3.6977e-03, 2.8457e-03, 3.0219e-03, 1.1453e-03, 1.1842e-03,\n",
      "           8.1077e-03, 5.6500e-02],\n",
      "          [7.4569e-02, 1.5840e-01, 6.9947e-02, 3.2184e-02, 1.3375e-01,\n",
      "           2.8473e-01, 1.5478e-01, 4.3325e-04, 4.6106e-03, 1.8679e-03,\n",
      "           6.9463e-03, 1.9899e-03, 6.2037e-03, 1.1151e-02, 1.1965e-02,\n",
      "           6.5998e-03, 3.9872e-02],\n",
      "          [7.0524e-03, 4.8956e-02, 1.3307e-02, 6.4460e-03, 9.5386e-02,\n",
      "           7.1170e-01, 8.3515e-02, 2.6254e-03, 2.5613e-03, 4.5371e-03,\n",
      "           1.6703e-03, 4.5537e-03, 1.3544e-03, 4.7264e-03, 6.2111e-03,\n",
      "           9.0408e-04, 4.4957e-03],\n",
      "          [1.6082e-01, 1.0973e-02, 6.1483e-03, 5.5964e-01, 3.4907e-02,\n",
      "           1.5120e-02, 1.0630e-03, 1.2701e-04, 2.8810e-04, 1.8789e-02,\n",
      "           1.0288e-03, 4.6292e-03, 1.0572e-03, 4.0566e-03, 7.3833e-03,\n",
      "           1.1459e-03, 1.7283e-01],\n",
      "          [5.9382e-02, 1.3249e-02, 6.4481e-03, 8.3720e-01, 6.6907e-03,\n",
      "           8.3006e-03, 1.6924e-03, 2.5266e-05, 2.8911e-04, 2.2970e-05,\n",
      "           5.7880e-05, 6.0462e-05, 4.4967e-05, 6.8823e-05, 5.3506e-04,\n",
      "           5.9903e-05, 6.5873e-02],\n",
      "          [1.3447e-01, 1.5967e-01, 1.2163e-01, 2.9685e-01, 6.7304e-02,\n",
      "           1.1416e-01, 1.2691e-02, 8.8630e-04, 4.2954e-03, 2.7768e-04,\n",
      "           5.6347e-04, 1.1785e-03, 4.4517e-04, 2.8129e-03, 3.3138e-03,\n",
      "           4.2520e-04, 7.9037e-02]],\n",
      "\n",
      "         [[1.8500e-02, 4.6488e-03, 2.4297e-02, 1.5465e-02, 2.2031e-01,\n",
      "           4.1031e-01, 2.1691e-01, 3.1934e-02, 1.1519e-02, 4.8408e-03,\n",
      "           1.4349e-03, 6.2359e-03, 1.1308e-03, 3.9685e-03, 4.8328e-03,\n",
      "           6.7266e-03, 1.6938e-02],\n",
      "          [6.4975e-02, 6.0509e-02, 4.2867e-02, 2.6802e-02, 2.3328e-01,\n",
      "           3.2681e-01, 1.9087e-01, 5.4084e-04, 2.0421e-03, 6.6373e-04,\n",
      "           5.4243e-04, 8.7638e-04, 4.5589e-04, 2.4238e-03, 3.2180e-03,\n",
      "           2.0516e-03, 4.1066e-02],\n",
      "          [3.4049e-02, 1.9794e-02, 3.5795e-02, 1.5621e-02, 2.0767e-01,\n",
      "           3.3287e-01, 2.2698e-01, 1.9417e-02, 1.3882e-02, 4.0951e-02,\n",
      "           2.2765e-03, 3.3020e-03, 2.2202e-03, 8.6433e-03, 4.5617e-03,\n",
      "           7.8384e-03, 2.4137e-02],\n",
      "          [9.2918e-02, 1.3326e-02, 3.2757e-03, 7.5830e-01, 1.6788e-02,\n",
      "           2.4435e-02, 2.7181e-03, 1.9268e-05, 2.3064e-04, 1.1414e-03,\n",
      "           6.3232e-05, 4.0612e-04, 4.8193e-05, 2.5352e-04, 9.1938e-04,\n",
      "           7.9316e-05, 8.5081e-02],\n",
      "          [1.2464e-01, 1.2216e-02, 4.9200e-03, 7.1155e-01, 6.1603e-03,\n",
      "           1.1089e-02, 3.5330e-03, 1.4986e-05, 1.7792e-04, 2.4991e-05,\n",
      "           1.8962e-05, 7.6402e-05, 1.4610e-05, 1.1484e-05, 4.2298e-05,\n",
      "           3.5418e-05, 1.2547e-01],\n",
      "          [1.2566e-01, 8.5281e-02, 5.5495e-02, 2.1275e-01, 6.2162e-02,\n",
      "           2.4436e-01, 1.2821e-01, 1.4857e-04, 2.3544e-03, 9.8310e-05,\n",
      "           5.9096e-05, 5.3983e-04, 4.2402e-05, 3.5957e-04, 1.1392e-03,\n",
      "           3.0148e-04, 8.1036e-02]],\n",
      "\n",
      "         [[1.7600e-02, 8.5285e-03, 3.6417e-02, 1.0185e-02, 5.7025e-02,\n",
      "           4.7405e-01, 3.5295e-01, 1.3012e-03, 6.8646e-03, 2.4514e-03,\n",
      "           1.4334e-03, 7.7738e-03, 1.1087e-03, 8.8593e-04, 2.1551e-03,\n",
      "           3.8019e-03, 1.5472e-02],\n",
      "          [4.8449e-02, 2.3196e-01, 1.8550e-01, 7.9776e-03, 6.1444e-02,\n",
      "           2.4574e-01, 1.8434e-01, 1.5650e-03, 3.5518e-03, 4.0135e-04,\n",
      "           3.4161e-04, 3.2155e-04, 3.3397e-04, 1.3332e-03, 6.8339e-04,\n",
      "           1.1787e-03, 2.4887e-02],\n",
      "          [5.4983e-02, 1.4981e-01, 6.4043e-02, 8.1940e-03, 2.5492e-02,\n",
      "           3.2901e-01, 2.5257e-01, 1.6024e-02, 3.0384e-02, 1.3961e-02,\n",
      "           3.8257e-03, 3.2995e-03, 2.9166e-03, 6.7778e-03, 3.8303e-03,\n",
      "           1.0634e-03, 3.3814e-02],\n",
      "          [1.1571e-01, 1.1377e-02, 1.0125e-02, 6.3387e-01, 9.6633e-03,\n",
      "           2.5855e-02, 1.4830e-02, 9.8082e-03, 6.4630e-03, 1.7517e-02,\n",
      "           2.0453e-03, 3.8089e-03, 1.3604e-03, 3.8810e-03, 7.1405e-03,\n",
      "           3.7154e-04, 1.2617e-01],\n",
      "          [1.8162e-01, 1.5318e-02, 1.0776e-01, 3.0586e-01, 9.8343e-02,\n",
      "           4.6903e-02, 1.9474e-02, 1.1837e-02, 2.3956e-02, 5.9769e-04,\n",
      "           2.2599e-03, 7.4513e-03, 1.8609e-03, 3.5252e-03, 5.6119e-03,\n",
      "           2.3303e-03, 1.6529e-01],\n",
      "          [9.3567e-02, 3.8863e-01, 3.5891e-01, 9.1104e-03, 2.7232e-02,\n",
      "           1.5454e-02, 1.9104e-02, 1.1375e-02, 3.6492e-02, 9.3236e-05,\n",
      "           3.8893e-04, 3.0962e-04, 3.1945e-04, 6.8065e-04, 1.9959e-04,\n",
      "           4.2836e-04, 3.7709e-02]],\n",
      "\n",
      "         [[4.4535e-03, 1.5546e-02, 3.4853e-02, 2.8058e-03, 1.7927e-01,\n",
      "           4.7568e-01, 2.5066e-01, 6.8883e-03, 1.0078e-02, 5.0742e-05,\n",
      "           2.3165e-04, 8.1959e-04, 2.2286e-04, 8.3023e-03, 3.1336e-03,\n",
      "           4.2528e-03, 2.7499e-03],\n",
      "          [7.6824e-02, 5.6918e-02, 3.7978e-02, 1.5925e-02, 2.7099e-01,\n",
      "           4.0040e-01, 8.1054e-02, 1.5507e-03, 7.2735e-03, 4.8642e-05,\n",
      "           7.2153e-04, 2.2128e-03, 5.3790e-04, 4.2269e-04, 5.4290e-03,\n",
      "           5.3130e-04, 4.1188e-02],\n",
      "          [4.0531e-02, 2.4389e-02, 3.8391e-02, 1.9504e-02, 3.8249e-01,\n",
      "           1.9288e-01, 1.0416e-01, 1.2396e-02, 2.1664e-02, 9.9765e-03,\n",
      "           9.3922e-03, 1.8724e-02, 8.4772e-03, 4.1400e-02, 3.5819e-02,\n",
      "           1.3561e-02, 2.6241e-02],\n",
      "          [7.8301e-02, 7.9292e-03, 2.1941e-03, 7.9581e-01, 1.4639e-02,\n",
      "           1.1975e-02, 2.4525e-03, 6.0641e-04, 9.8893e-04, 4.1403e-03,\n",
      "           3.4231e-04, 1.3430e-03, 2.8789e-04, 1.1620e-03, 1.7369e-03,\n",
      "           3.4606e-04, 7.5749e-02],\n",
      "          [1.8876e-01, 6.2290e-02, 1.9610e-02, 4.1921e-01, 4.8494e-02,\n",
      "           6.5321e-02, 2.1007e-02, 2.1620e-03, 6.4221e-03, 4.8786e-04,\n",
      "           5.3908e-04, 8.6527e-04, 4.4358e-04, 3.9504e-04, 1.0972e-03,\n",
      "           1.1805e-03, 1.6172e-01],\n",
      "          [4.3581e-02, 7.5008e-02, 8.1672e-02, 1.4401e-02, 2.5501e-01,\n",
      "           3.7014e-01, 1.1722e-01, 2.6159e-03, 1.1939e-02, 4.4789e-05,\n",
      "           4.0599e-04, 8.0520e-04, 3.0899e-04, 1.2478e-03, 2.5612e-03,\n",
      "           1.4217e-03, 2.1610e-02]]]]), tensor([[[[1.7743e-01, 3.7521e-01, 1.6678e-01, 2.5366e-02, 3.4719e-02,\n",
      "           5.5695e-02, 1.9681e-02, 2.7427e-03, 5.3430e-03, 2.6665e-04,\n",
      "           2.7988e-04, 2.0024e-03, 1.9536e-04, 1.6475e-04, 3.5695e-04,\n",
      "           1.0933e-03, 1.3268e-01],\n",
      "          [4.3516e-02, 2.3388e-01, 9.6774e-02, 1.1312e-02, 7.5405e-02,\n",
      "           2.0868e-01, 2.4645e-01, 2.2417e-03, 8.4124e-03, 3.8403e-03,\n",
      "           6.8524e-03, 1.5869e-03, 7.1658e-03, 6.0570e-03, 1.9097e-03,\n",
      "           1.3840e-02, 3.2080e-02],\n",
      "          [8.1063e-02, 1.4702e-01, 1.3583e-01, 1.6272e-02, 1.6078e-01,\n",
      "           3.4457e-02, 1.6977e-02, 3.1023e-02, 2.4909e-02, 1.6201e-01,\n",
      "           3.5713e-02, 6.8470e-03, 3.2916e-02, 3.0521e-02, 1.0057e-02,\n",
      "           1.6966e-02, 5.6646e-02],\n",
      "          [1.5585e-01, 1.9927e-01, 1.7719e-02, 4.3789e-01, 7.2047e-03,\n",
      "           6.8037e-03, 1.2710e-03, 2.0167e-04, 4.0369e-04, 3.4111e-02,\n",
      "           1.2064e-03, 2.1071e-03, 9.2715e-04, 2.3399e-03, 1.7485e-03,\n",
      "           6.4412e-04, 1.3031e-01],\n",
      "          [1.3060e-01, 1.8805e-01, 1.7981e-02, 4.5097e-01, 2.0331e-02,\n",
      "           4.7270e-02, 1.8210e-02, 2.6018e-04, 3.2665e-04, 1.0140e-04,\n",
      "           8.1919e-05, 2.5576e-04, 7.1219e-05, 2.5921e-04, 3.5456e-04,\n",
      "           1.3356e-04, 1.2474e-01],\n",
      "          [1.6979e-01, 2.4596e-01, 3.0632e-01, 9.1252e-02, 3.6439e-02,\n",
      "           1.7458e-02, 1.3111e-02, 2.7164e-03, 1.2007e-02, 3.3953e-04,\n",
      "           4.5654e-04, 8.8566e-04, 3.5481e-04, 7.3110e-04, 6.1786e-04,\n",
      "           5.6720e-04, 1.0099e-01],\n",
      "          [1.5230e-01, 4.6520e-01, 2.1238e-01, 3.1184e-02, 3.0870e-02,\n",
      "           1.1960e-02, 5.8487e-03, 2.8154e-03, 6.6215e-04, 9.2013e-07,\n",
      "           9.5855e-06, 2.6814e-06, 8.6044e-06, 7.2006e-06, 9.7462e-06,\n",
      "           3.5613e-05, 8.6707e-02]],\n",
      "\n",
      "         [[5.9442e-02, 1.7457e-01, 6.8187e-02, 6.6231e-02, 1.2160e-01,\n",
      "           3.4383e-01, 9.6388e-02, 1.5546e-03, 7.2361e-03, 3.6152e-04,\n",
      "           5.8413e-04, 5.4978e-03, 4.6751e-04, 6.1408e-04, 5.3136e-04,\n",
      "           7.8217e-03, 4.5081e-02],\n",
      "          [1.1759e-01, 2.3108e-01, 4.9012e-02, 6.6589e-02, 5.7507e-02,\n",
      "           3.1980e-01, 5.6524e-02, 3.2067e-04, 1.6989e-03, 1.0950e-03,\n",
      "           1.4918e-03, 2.4627e-03, 1.3727e-03, 2.7629e-03, 4.0909e-03,\n",
      "           1.3290e-03, 8.5273e-02],\n",
      "          [9.1519e-02, 2.5034e-01, 8.7355e-02, 4.7904e-02, 1.9848e-01,\n",
      "           1.6532e-01, 4.2233e-02, 2.3966e-03, 6.1855e-03, 1.5384e-02,\n",
      "           2.1763e-03, 1.1061e-02, 1.8585e-03, 3.1324e-03, 2.1897e-03,\n",
      "           4.2162e-03, 6.8249e-02],\n",
      "          [6.9856e-02, 9.9510e-02, 9.7398e-03, 7.2912e-01, 1.2160e-02,\n",
      "           1.0836e-02, 2.9143e-03, 8.4413e-06, 1.1033e-04, 3.4721e-03,\n",
      "           2.0615e-04, 1.7303e-04, 1.8094e-04, 7.1524e-05, 3.1669e-04,\n",
      "           1.4845e-04, 6.1174e-02],\n",
      "          [1.4469e-01, 1.5470e-01, 3.8286e-02, 3.3086e-01, 5.4361e-02,\n",
      "           1.0198e-01, 4.0514e-02, 4.9126e-03, 4.6209e-03, 2.5702e-04,\n",
      "           7.4973e-04, 6.8863e-04, 7.5471e-04, 1.0092e-03, 2.5488e-03,\n",
      "           2.4052e-03, 1.1666e-01],\n",
      "          [4.1380e-02, 5.3111e-01, 1.2001e-01, 3.1567e-02, 7.6769e-02,\n",
      "           8.5241e-02, 3.6255e-02, 3.3021e-02, 1.4564e-02, 7.1014e-05,\n",
      "           2.5778e-04, 1.0160e-03, 2.3742e-04, 1.2582e-03, 1.0805e-03,\n",
      "           1.0215e-03, 2.5147e-02],\n",
      "          [3.1768e-02, 8.0229e-01, 5.8342e-02, 8.2664e-03, 3.6233e-02,\n",
      "           3.6127e-02, 8.6677e-03, 3.2226e-04, 4.9576e-04, 1.9509e-06,\n",
      "           1.6673e-05, 2.8514e-05, 1.5138e-05, 7.4601e-05, 6.0978e-05,\n",
      "           2.4132e-04, 1.7044e-02]],\n",
      "\n",
      "         [[2.5901e-03, 4.0910e-03, 2.3251e-02, 2.0493e-03, 5.3184e-01,\n",
      "           3.5444e-01, 7.0159e-02, 2.1636e-03, 2.0102e-03, 8.7146e-05,\n",
      "           3.7551e-04, 1.1074e-03, 3.2351e-04, 1.2103e-03, 1.6823e-03,\n",
      "           8.8087e-04, 1.7392e-03],\n",
      "          [3.6140e-02, 2.0164e-01, 9.2041e-02, 1.5718e-02, 3.6398e-02,\n",
      "           5.1119e-01, 5.0137e-02, 1.7705e-02, 6.8773e-03, 1.3557e-03,\n",
      "           1.0246e-03, 7.5426e-04, 1.0560e-03, 1.5902e-03, 2.1791e-03,\n",
      "           7.3264e-04, 2.3453e-02],\n",
      "          [1.1522e-01, 2.9745e-01, 5.4066e-02, 5.6322e-02, 1.5310e-01,\n",
      "           1.3601e-01, 3.5955e-02, 5.2581e-03, 4.3369e-03, 3.0700e-02,\n",
      "           3.1786e-03, 9.7824e-03, 2.8809e-03, 2.9344e-03, 3.9768e-03,\n",
      "           3.9445e-03, 8.4887e-02],\n",
      "          [2.3569e-01, 3.4942e-02, 3.7613e-03, 4.8740e-01, 4.6477e-03,\n",
      "           6.6741e-03, 4.0859e-03, 1.8617e-04, 2.0253e-04, 1.3619e-03,\n",
      "           1.1879e-04, 6.4143e-04, 1.0480e-04, 1.3035e-04, 3.2315e-04,\n",
      "           4.1631e-04, 2.1931e-01],\n",
      "          [3.3563e-01, 1.0633e-02, 6.2996e-03, 2.6528e-01, 1.4737e-03,\n",
      "           3.1002e-03, 2.2025e-03, 4.2374e-03, 1.4868e-03, 2.4901e-04,\n",
      "           1.0706e-04, 1.3979e-04, 1.0223e-04, 1.8510e-04, 1.8866e-04,\n",
      "           6.6156e-04, 3.6802e-01],\n",
      "          [1.1812e-01, 1.8619e-01, 3.4161e-01, 3.7683e-02, 1.3223e-02,\n",
      "           1.5574e-01, 1.3342e-02, 5.6146e-02, 1.1732e-02, 9.4183e-05,\n",
      "           1.2757e-04, 2.8065e-04, 1.0790e-04, 1.3657e-03, 2.0283e-03,\n",
      "           2.7659e-04, 6.1943e-02],\n",
      "          [1.4745e-01, 4.9637e-01, 1.5084e-01, 2.9436e-02, 3.0148e-02,\n",
      "           4.7577e-02, 3.5069e-03, 2.9932e-03, 1.7472e-03, 6.0078e-05,\n",
      "           7.3115e-05, 6.0077e-05, 6.4545e-05, 6.0196e-05, 8.6652e-05,\n",
      "           2.1859e-04, 8.9303e-02]],\n",
      "\n",
      "         [[1.1537e-02, 4.0463e-02, 1.1963e-01, 8.5196e-03, 1.5613e-01,\n",
      "           4.7785e-01, 1.4848e-01, 4.7556e-03, 1.0242e-02, 1.3071e-03,\n",
      "           9.9085e-04, 2.5635e-03, 9.1511e-04, 3.5022e-03, 2.1266e-03,\n",
      "           2.3801e-03, 8.5981e-03],\n",
      "          [1.7585e-02, 3.8539e-01, 1.1688e-01, 6.1168e-03, 4.6612e-02,\n",
      "           3.4324e-01, 5.6861e-02, 9.9924e-04, 1.3109e-03, 8.6840e-04,\n",
      "           1.9761e-03, 5.7103e-04, 2.4861e-03, 3.0448e-03, 2.3841e-03,\n",
      "           2.1779e-03, 1.1504e-02],\n",
      "          [4.0584e-02, 1.0327e-01, 2.8698e-01, 5.4264e-03, 1.4224e-01,\n",
      "           2.9503e-01, 3.2236e-02, 3.1303e-02, 9.3257e-03, 3.7113e-03,\n",
      "           2.5519e-03, 1.9768e-03, 2.6039e-03, 7.2847e-03, 2.6060e-03,\n",
      "           2.8253e-03, 3.0044e-02],\n",
      "          [1.4611e-01, 3.8618e-02, 1.3763e-02, 5.7042e-01, 6.0486e-02,\n",
      "           2.8917e-02, 3.0115e-03, 6.6924e-05, 4.9160e-04, 1.8771e-03,\n",
      "           2.7887e-04, 7.1538e-04, 2.5841e-04, 1.1463e-03, 1.2130e-03,\n",
      "           2.9912e-04, 1.3233e-01],\n",
      "          [1.8096e-01, 1.3511e-01, 4.0123e-02, 3.8979e-01, 4.2671e-02,\n",
      "           5.3638e-02, 7.3994e-03, 3.6485e-04, 8.5969e-04, 5.3534e-04,\n",
      "           3.4825e-04, 1.0669e-03, 3.6083e-04, 2.0015e-03, 1.4886e-03,\n",
      "           6.3166e-04, 1.4266e-01],\n",
      "          [6.8168e-02, 4.8001e-01, 3.2749e-01, 6.8742e-03, 3.0715e-02,\n",
      "           4.5035e-02, 5.7728e-03, 5.2437e-03, 6.4480e-04, 2.2516e-05,\n",
      "           2.6115e-05, 1.7930e-05, 2.5040e-05, 3.8697e-04, 1.5286e-04,\n",
      "           7.6735e-05, 2.9329e-02],\n",
      "          [2.7154e-02, 5.3631e-01, 2.6143e-01, 2.7959e-03, 3.1663e-02,\n",
      "           8.6201e-02, 3.7483e-02, 3.0748e-03, 7.9912e-04, 2.6038e-05,\n",
      "           2.7543e-05, 3.9400e-06, 2.8322e-05, 1.2737e-04, 7.0295e-05,\n",
      "           3.1541e-04, 1.2492e-02]],\n",
      "\n",
      "         [[7.2577e-02, 1.5304e-01, 1.6273e-01, 3.2579e-02, 2.0103e-01,\n",
      "           1.4322e-01, 1.2201e-01, 4.2586e-03, 2.8589e-02, 3.4624e-03,\n",
      "           3.6977e-03, 2.8457e-03, 3.0219e-03, 1.1453e-03, 1.1842e-03,\n",
      "           8.1077e-03, 5.6500e-02],\n",
      "          [7.4569e-02, 1.5840e-01, 6.9947e-02, 3.2184e-02, 1.3375e-01,\n",
      "           2.8473e-01, 1.5478e-01, 4.3325e-04, 4.6106e-03, 1.8679e-03,\n",
      "           6.9463e-03, 1.9899e-03, 6.2037e-03, 1.1151e-02, 1.1965e-02,\n",
      "           6.5998e-03, 3.9872e-02],\n",
      "          [7.0524e-03, 4.8956e-02, 1.3307e-02, 6.4460e-03, 9.5386e-02,\n",
      "           7.1170e-01, 8.3515e-02, 2.6254e-03, 2.5613e-03, 4.5371e-03,\n",
      "           1.6703e-03, 4.5537e-03, 1.3544e-03, 4.7264e-03, 6.2111e-03,\n",
      "           9.0408e-04, 4.4957e-03],\n",
      "          [1.6082e-01, 1.0973e-02, 6.1483e-03, 5.5964e-01, 3.4907e-02,\n",
      "           1.5120e-02, 1.0630e-03, 1.2701e-04, 2.8810e-04, 1.8789e-02,\n",
      "           1.0288e-03, 4.6292e-03, 1.0572e-03, 4.0566e-03, 7.3833e-03,\n",
      "           1.1459e-03, 1.7283e-01],\n",
      "          [5.9382e-02, 1.3249e-02, 6.4481e-03, 8.3720e-01, 6.6907e-03,\n",
      "           8.3006e-03, 1.6924e-03, 2.5266e-05, 2.8911e-04, 2.2970e-05,\n",
      "           5.7880e-05, 6.0462e-05, 4.4967e-05, 6.8823e-05, 5.3506e-04,\n",
      "           5.9903e-05, 6.5873e-02],\n",
      "          [1.3447e-01, 1.5967e-01, 1.2163e-01, 2.9685e-01, 6.7304e-02,\n",
      "           1.1416e-01, 1.2691e-02, 8.8630e-04, 4.2954e-03, 2.7768e-04,\n",
      "           5.6347e-04, 1.1785e-03, 4.4517e-04, 2.8129e-03, 3.3138e-03,\n",
      "           4.2520e-04, 7.9037e-02],\n",
      "          [9.0113e-02, 3.9059e-01, 1.4035e-01, 1.9438e-01, 4.1521e-02,\n",
      "           4.2372e-02, 2.0563e-02, 2.4760e-04, 7.3960e-03, 2.5084e-04,\n",
      "           1.1842e-03, 1.1142e-04, 1.1032e-03, 6.2835e-04, 2.1514e-03,\n",
      "           1.3535e-03, 6.5687e-02]],\n",
      "\n",
      "         [[1.8500e-02, 4.6488e-03, 2.4297e-02, 1.5465e-02, 2.2031e-01,\n",
      "           4.1031e-01, 2.1691e-01, 3.1934e-02, 1.1519e-02, 4.8408e-03,\n",
      "           1.4349e-03, 6.2359e-03, 1.1308e-03, 3.9685e-03, 4.8328e-03,\n",
      "           6.7266e-03, 1.6938e-02],\n",
      "          [6.4975e-02, 6.0509e-02, 4.2867e-02, 2.6802e-02, 2.3328e-01,\n",
      "           3.2681e-01, 1.9087e-01, 5.4084e-04, 2.0421e-03, 6.6373e-04,\n",
      "           5.4243e-04, 8.7638e-04, 4.5589e-04, 2.4238e-03, 3.2180e-03,\n",
      "           2.0516e-03, 4.1066e-02],\n",
      "          [3.4049e-02, 1.9794e-02, 3.5795e-02, 1.5621e-02, 2.0767e-01,\n",
      "           3.3287e-01, 2.2698e-01, 1.9417e-02, 1.3882e-02, 4.0951e-02,\n",
      "           2.2765e-03, 3.3020e-03, 2.2202e-03, 8.6433e-03, 4.5617e-03,\n",
      "           7.8384e-03, 2.4137e-02],\n",
      "          [9.2918e-02, 1.3326e-02, 3.2757e-03, 7.5830e-01, 1.6788e-02,\n",
      "           2.4435e-02, 2.7181e-03, 1.9268e-05, 2.3064e-04, 1.1414e-03,\n",
      "           6.3232e-05, 4.0612e-04, 4.8193e-05, 2.5352e-04, 9.1938e-04,\n",
      "           7.9316e-05, 8.5081e-02],\n",
      "          [1.2464e-01, 1.2216e-02, 4.9200e-03, 7.1155e-01, 6.1603e-03,\n",
      "           1.1089e-02, 3.5330e-03, 1.4986e-05, 1.7792e-04, 2.4991e-05,\n",
      "           1.8962e-05, 7.6402e-05, 1.4610e-05, 1.1484e-05, 4.2298e-05,\n",
      "           3.5418e-05, 1.2547e-01],\n",
      "          [1.2566e-01, 8.5281e-02, 5.5495e-02, 2.1275e-01, 6.2162e-02,\n",
      "           2.4436e-01, 1.2821e-01, 1.4857e-04, 2.3544e-03, 9.8310e-05,\n",
      "           5.9096e-05, 5.3983e-04, 4.2402e-05, 3.5957e-04, 1.1392e-03,\n",
      "           3.0148e-04, 8.1036e-02],\n",
      "          [1.1441e-01, 4.0361e-01, 1.7047e-01, 1.1417e-02, 7.1941e-02,\n",
      "           4.6938e-02, 5.9410e-02, 3.3428e-02, 1.5141e-02, 2.7260e-04,\n",
      "           5.8116e-04, 2.5767e-04, 4.9486e-04, 2.0488e-04, 6.9976e-04,\n",
      "           3.8906e-03, 6.6834e-02]],\n",
      "\n",
      "         [[1.7600e-02, 8.5285e-03, 3.6417e-02, 1.0185e-02, 5.7025e-02,\n",
      "           4.7405e-01, 3.5295e-01, 1.3012e-03, 6.8646e-03, 2.4514e-03,\n",
      "           1.4334e-03, 7.7738e-03, 1.1087e-03, 8.8593e-04, 2.1551e-03,\n",
      "           3.8019e-03, 1.5472e-02],\n",
      "          [4.8449e-02, 2.3196e-01, 1.8550e-01, 7.9776e-03, 6.1444e-02,\n",
      "           2.4574e-01, 1.8434e-01, 1.5650e-03, 3.5518e-03, 4.0135e-04,\n",
      "           3.4161e-04, 3.2155e-04, 3.3397e-04, 1.3332e-03, 6.8339e-04,\n",
      "           1.1787e-03, 2.4887e-02],\n",
      "          [5.4983e-02, 1.4981e-01, 6.4043e-02, 8.1940e-03, 2.5492e-02,\n",
      "           3.2901e-01, 2.5257e-01, 1.6024e-02, 3.0384e-02, 1.3961e-02,\n",
      "           3.8257e-03, 3.2995e-03, 2.9166e-03, 6.7778e-03, 3.8303e-03,\n",
      "           1.0634e-03, 3.3814e-02],\n",
      "          [1.1571e-01, 1.1377e-02, 1.0125e-02, 6.3387e-01, 9.6633e-03,\n",
      "           2.5855e-02, 1.4830e-02, 9.8082e-03, 6.4630e-03, 1.7517e-02,\n",
      "           2.0453e-03, 3.8089e-03, 1.3604e-03, 3.8810e-03, 7.1405e-03,\n",
      "           3.7154e-04, 1.2617e-01],\n",
      "          [1.8162e-01, 1.5318e-02, 1.0776e-01, 3.0586e-01, 9.8343e-02,\n",
      "           4.6903e-02, 1.9474e-02, 1.1837e-02, 2.3956e-02, 5.9769e-04,\n",
      "           2.2599e-03, 7.4513e-03, 1.8609e-03, 3.5252e-03, 5.6119e-03,\n",
      "           2.3303e-03, 1.6529e-01],\n",
      "          [9.3567e-02, 3.8863e-01, 3.5891e-01, 9.1104e-03, 2.7232e-02,\n",
      "           1.5454e-02, 1.9104e-02, 1.1375e-02, 3.6492e-02, 9.3236e-05,\n",
      "           3.8893e-04, 3.0962e-04, 3.1945e-04, 6.8065e-04, 1.9959e-04,\n",
      "           4.2836e-04, 3.7709e-02],\n",
      "          [1.0260e-01, 5.0002e-01, 1.6366e-01, 3.9514e-02, 4.5315e-02,\n",
      "           2.8849e-02, 4.6415e-02, 2.3107e-03, 7.1050e-03, 1.8108e-04,\n",
      "           8.5383e-04, 3.1116e-04, 9.4529e-04, 8.2605e-04, 1.9958e-04,\n",
      "           3.0077e-03, 5.7884e-02]],\n",
      "\n",
      "         [[4.4535e-03, 1.5546e-02, 3.4853e-02, 2.8058e-03, 1.7927e-01,\n",
      "           4.7568e-01, 2.5066e-01, 6.8883e-03, 1.0078e-02, 5.0742e-05,\n",
      "           2.3165e-04, 8.1959e-04, 2.2286e-04, 8.3023e-03, 3.1336e-03,\n",
      "           4.2528e-03, 2.7499e-03],\n",
      "          [7.6824e-02, 5.6918e-02, 3.7978e-02, 1.5925e-02, 2.7099e-01,\n",
      "           4.0040e-01, 8.1054e-02, 1.5507e-03, 7.2735e-03, 4.8642e-05,\n",
      "           7.2153e-04, 2.2128e-03, 5.3790e-04, 4.2269e-04, 5.4290e-03,\n",
      "           5.3130e-04, 4.1188e-02],\n",
      "          [4.0531e-02, 2.4389e-02, 3.8391e-02, 1.9504e-02, 3.8249e-01,\n",
      "           1.9288e-01, 1.0416e-01, 1.2396e-02, 2.1664e-02, 9.9765e-03,\n",
      "           9.3922e-03, 1.8724e-02, 8.4772e-03, 4.1400e-02, 3.5819e-02,\n",
      "           1.3561e-02, 2.6241e-02],\n",
      "          [7.8301e-02, 7.9292e-03, 2.1941e-03, 7.9581e-01, 1.4639e-02,\n",
      "           1.1975e-02, 2.4525e-03, 6.0641e-04, 9.8893e-04, 4.1403e-03,\n",
      "           3.4231e-04, 1.3430e-03, 2.8789e-04, 1.1620e-03, 1.7369e-03,\n",
      "           3.4606e-04, 7.5749e-02],\n",
      "          [1.8876e-01, 6.2290e-02, 1.9610e-02, 4.1921e-01, 4.8494e-02,\n",
      "           6.5321e-02, 2.1007e-02, 2.1620e-03, 6.4221e-03, 4.8786e-04,\n",
      "           5.3908e-04, 8.6527e-04, 4.4358e-04, 3.9504e-04, 1.0972e-03,\n",
      "           1.1805e-03, 1.6172e-01],\n",
      "          [4.3581e-02, 7.5008e-02, 8.1672e-02, 1.4401e-02, 2.5501e-01,\n",
      "           3.7014e-01, 1.1722e-01, 2.6159e-03, 1.1939e-02, 4.4789e-05,\n",
      "           4.0599e-04, 8.0520e-04, 3.0899e-04, 1.2478e-03, 2.5612e-03,\n",
      "           1.4217e-03, 2.1610e-02],\n",
      "          [7.1575e-02, 1.0106e-01, 2.2173e-01, 1.9055e-02, 1.0389e-01,\n",
      "           1.1729e-01, 7.3809e-02, 2.1795e-02, 1.3640e-01, 9.0137e-04,\n",
      "           1.2421e-02, 6.0616e-03, 1.2044e-02, 7.1623e-03, 7.2612e-03,\n",
      "           3.9119e-02, 4.8423e-02]]]]), tensor([[[[1.7743e-01, 3.7521e-01, 1.6678e-01,  ..., 3.5695e-04,\n",
      "           1.0933e-03, 1.3268e-01],\n",
      "          [4.3516e-02, 2.3388e-01, 9.6774e-02,  ..., 1.9097e-03,\n",
      "           1.3840e-02, 3.2080e-02],\n",
      "          [8.1063e-02, 1.4702e-01, 1.3583e-01,  ..., 1.0057e-02,\n",
      "           1.6966e-02, 5.6646e-02],\n",
      "          ...,\n",
      "          [1.6979e-01, 2.4596e-01, 3.0632e-01,  ..., 6.1786e-04,\n",
      "           5.6720e-04, 1.0099e-01],\n",
      "          [1.5230e-01, 4.6520e-01, 2.1238e-01,  ..., 9.7462e-06,\n",
      "           3.5613e-05, 8.6707e-02],\n",
      "          [1.4718e-02, 9.2080e-01, 2.4557e-02,  ..., 3.7802e-07,\n",
      "           6.1889e-07, 6.9881e-03]],\n",
      "\n",
      "         [[5.9442e-02, 1.7457e-01, 6.8187e-02,  ..., 5.3136e-04,\n",
      "           7.8217e-03, 4.5081e-02],\n",
      "          [1.1759e-01, 2.3108e-01, 4.9012e-02,  ..., 4.0909e-03,\n",
      "           1.3290e-03, 8.5273e-02],\n",
      "          [9.1519e-02, 2.5034e-01, 8.7355e-02,  ..., 2.1897e-03,\n",
      "           4.2162e-03, 6.8249e-02],\n",
      "          ...,\n",
      "          [4.1380e-02, 5.3111e-01, 1.2001e-01,  ..., 1.0805e-03,\n",
      "           1.0215e-03, 2.5147e-02],\n",
      "          [3.1768e-02, 8.0229e-01, 5.8342e-02,  ..., 6.0978e-05,\n",
      "           2.4132e-04, 1.7044e-02],\n",
      "          [9.9273e-02, 7.3246e-01, 4.4211e-02,  ..., 1.4259e-04,\n",
      "           2.1971e-04, 5.2814e-02]],\n",
      "\n",
      "         [[2.5901e-03, 4.0910e-03, 2.3251e-02,  ..., 1.6823e-03,\n",
      "           8.8087e-04, 1.7392e-03],\n",
      "          [3.6140e-02, 2.0164e-01, 9.2041e-02,  ..., 2.1791e-03,\n",
      "           7.3264e-04, 2.3453e-02],\n",
      "          [1.1522e-01, 2.9745e-01, 5.4066e-02,  ..., 3.9768e-03,\n",
      "           3.9445e-03, 8.4887e-02],\n",
      "          ...,\n",
      "          [1.1812e-01, 1.8619e-01, 3.4161e-01,  ..., 2.0283e-03,\n",
      "           2.7659e-04, 6.1943e-02],\n",
      "          [1.4745e-01, 4.9637e-01, 1.5084e-01,  ..., 8.6652e-05,\n",
      "           2.1859e-04, 8.9303e-02],\n",
      "          [8.0337e-02, 6.7662e-01, 1.2818e-01,  ..., 4.6698e-05,\n",
      "           2.1505e-04, 4.1401e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.8500e-02, 4.6488e-03, 2.4297e-02,  ..., 4.8328e-03,\n",
      "           6.7266e-03, 1.6938e-02],\n",
      "          [6.4975e-02, 6.0509e-02, 4.2867e-02,  ..., 3.2180e-03,\n",
      "           2.0516e-03, 4.1066e-02],\n",
      "          [3.4049e-02, 1.9794e-02, 3.5795e-02,  ..., 4.5617e-03,\n",
      "           7.8384e-03, 2.4137e-02],\n",
      "          ...,\n",
      "          [1.2566e-01, 8.5281e-02, 5.5495e-02,  ..., 1.1392e-03,\n",
      "           3.0148e-04, 8.1036e-02],\n",
      "          [1.1441e-01, 4.0361e-01, 1.7047e-01,  ..., 6.9976e-04,\n",
      "           3.8906e-03, 6.6834e-02],\n",
      "          [4.4579e-02, 8.2382e-01, 1.4685e-02,  ..., 1.1340e-04,\n",
      "           5.1802e-05, 2.2834e-02]],\n",
      "\n",
      "         [[1.7600e-02, 8.5285e-03, 3.6417e-02,  ..., 2.1551e-03,\n",
      "           3.8019e-03, 1.5472e-02],\n",
      "          [4.8449e-02, 2.3196e-01, 1.8550e-01,  ..., 6.8339e-04,\n",
      "           1.1787e-03, 2.4887e-02],\n",
      "          [5.4983e-02, 1.4981e-01, 6.4043e-02,  ..., 3.8303e-03,\n",
      "           1.0634e-03, 3.3814e-02],\n",
      "          ...,\n",
      "          [9.3567e-02, 3.8863e-01, 3.5891e-01,  ..., 1.9959e-04,\n",
      "           4.2836e-04, 3.7709e-02],\n",
      "          [1.0260e-01, 5.0002e-01, 1.6366e-01,  ..., 1.9958e-04,\n",
      "           3.0077e-03, 5.7884e-02],\n",
      "          [5.3178e-02, 8.2544e-01, 6.5429e-02,  ..., 1.4763e-05,\n",
      "           2.5327e-04, 2.3618e-02]],\n",
      "\n",
      "         [[4.4535e-03, 1.5546e-02, 3.4853e-02,  ..., 3.1336e-03,\n",
      "           4.2528e-03, 2.7499e-03],\n",
      "          [7.6824e-02, 5.6918e-02, 3.7978e-02,  ..., 5.4290e-03,\n",
      "           5.3130e-04, 4.1188e-02],\n",
      "          [4.0531e-02, 2.4389e-02, 3.8391e-02,  ..., 3.5819e-02,\n",
      "           1.3561e-02, 2.6241e-02],\n",
      "          ...,\n",
      "          [4.3581e-02, 7.5008e-02, 8.1672e-02,  ..., 2.5612e-03,\n",
      "           1.4217e-03, 2.1610e-02],\n",
      "          [7.1575e-02, 1.0106e-01, 2.2173e-01,  ..., 7.2612e-03,\n",
      "           3.9119e-02, 4.8423e-02],\n",
      "          [4.5017e-02, 7.1660e-01, 2.5459e-02,  ..., 2.4681e-04,\n",
      "           2.9587e-04, 2.7983e-02]]]]), tensor([[[[1.7743e-01, 3.7521e-01, 1.6678e-01,  ..., 3.5695e-04,\n",
      "           1.0933e-03, 1.3268e-01],\n",
      "          [4.3516e-02, 2.3388e-01, 9.6774e-02,  ..., 1.9097e-03,\n",
      "           1.3840e-02, 3.2080e-02],\n",
      "          [8.1063e-02, 1.4702e-01, 1.3583e-01,  ..., 1.0057e-02,\n",
      "           1.6966e-02, 5.6646e-02],\n",
      "          ...,\n",
      "          [1.5230e-01, 4.6520e-01, 2.1238e-01,  ..., 9.7462e-06,\n",
      "           3.5613e-05, 8.6707e-02],\n",
      "          [1.4718e-02, 9.2080e-01, 2.4557e-02,  ..., 3.7802e-07,\n",
      "           6.1888e-07, 6.9881e-03],\n",
      "          [9.1767e-02, 5.3351e-01, 1.6126e-01,  ..., 6.5448e-05,\n",
      "           1.3349e-04, 4.7224e-02]],\n",
      "\n",
      "         [[5.9442e-02, 1.7457e-01, 6.8187e-02,  ..., 5.3136e-04,\n",
      "           7.8217e-03, 4.5081e-02],\n",
      "          [1.1759e-01, 2.3108e-01, 4.9012e-02,  ..., 4.0909e-03,\n",
      "           1.3290e-03, 8.5273e-02],\n",
      "          [9.1519e-02, 2.5034e-01, 8.7355e-02,  ..., 2.1897e-03,\n",
      "           4.2162e-03, 6.8249e-02],\n",
      "          ...,\n",
      "          [3.1768e-02, 8.0229e-01, 5.8342e-02,  ..., 6.0978e-05,\n",
      "           2.4132e-04, 1.7044e-02],\n",
      "          [9.9273e-02, 7.3246e-01, 4.4211e-02,  ..., 1.4259e-04,\n",
      "           2.1971e-04, 5.2814e-02],\n",
      "          [1.1793e-01, 1.0234e-01, 6.4952e-02,  ..., 2.6288e-03,\n",
      "           1.1371e-02, 8.3182e-02]],\n",
      "\n",
      "         [[2.5901e-03, 4.0910e-03, 2.3251e-02,  ..., 1.6823e-03,\n",
      "           8.8087e-04, 1.7392e-03],\n",
      "          [3.6140e-02, 2.0164e-01, 9.2041e-02,  ..., 2.1791e-03,\n",
      "           7.3264e-04, 2.3453e-02],\n",
      "          [1.1522e-01, 2.9745e-01, 5.4066e-02,  ..., 3.9768e-03,\n",
      "           3.9445e-03, 8.4887e-02],\n",
      "          ...,\n",
      "          [1.4745e-01, 4.9637e-01, 1.5084e-01,  ..., 8.6652e-05,\n",
      "           2.1859e-04, 8.9303e-02],\n",
      "          [8.0337e-02, 6.7662e-01, 1.2818e-01,  ..., 4.6698e-05,\n",
      "           2.1505e-04, 4.1401e-02],\n",
      "          [1.9436e-01, 1.6086e-01, 2.4144e-01,  ..., 1.4360e-03,\n",
      "           1.5641e-03, 1.2590e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.8500e-02, 4.6488e-03, 2.4297e-02,  ..., 4.8328e-03,\n",
      "           6.7266e-03, 1.6938e-02],\n",
      "          [6.4975e-02, 6.0509e-02, 4.2867e-02,  ..., 3.2180e-03,\n",
      "           2.0516e-03, 4.1066e-02],\n",
      "          [3.4049e-02, 1.9794e-02, 3.5795e-02,  ..., 4.5617e-03,\n",
      "           7.8384e-03, 2.4137e-02],\n",
      "          ...,\n",
      "          [1.1441e-01, 4.0361e-01, 1.7047e-01,  ..., 6.9976e-04,\n",
      "           3.8906e-03, 6.6834e-02],\n",
      "          [4.4579e-02, 8.2382e-01, 1.4685e-02,  ..., 1.1340e-04,\n",
      "           5.1802e-05, 2.2834e-02],\n",
      "          [1.7554e-01, 1.1016e-01, 3.6968e-02,  ..., 4.6029e-04,\n",
      "           2.1249e-04, 1.3016e-01]],\n",
      "\n",
      "         [[1.7600e-02, 8.5285e-03, 3.6417e-02,  ..., 2.1551e-03,\n",
      "           3.8019e-03, 1.5472e-02],\n",
      "          [4.8449e-02, 2.3196e-01, 1.8550e-01,  ..., 6.8339e-04,\n",
      "           1.1787e-03, 2.4887e-02],\n",
      "          [5.4983e-02, 1.4981e-01, 6.4043e-02,  ..., 3.8303e-03,\n",
      "           1.0634e-03, 3.3814e-02],\n",
      "          ...,\n",
      "          [1.0260e-01, 5.0002e-01, 1.6366e-01,  ..., 1.9958e-04,\n",
      "           3.0077e-03, 5.7884e-02],\n",
      "          [5.3178e-02, 8.2544e-01, 6.5429e-02,  ..., 1.4763e-05,\n",
      "           2.5327e-04, 2.3618e-02],\n",
      "          [7.9269e-02, 9.9254e-02, 1.6045e-01,  ..., 1.7350e-03,\n",
      "           1.2317e-02, 4.0593e-02]],\n",
      "\n",
      "         [[4.4535e-03, 1.5546e-02, 3.4853e-02,  ..., 3.1336e-03,\n",
      "           4.2528e-03, 2.7499e-03],\n",
      "          [7.6824e-02, 5.6918e-02, 3.7978e-02,  ..., 5.4290e-03,\n",
      "           5.3130e-04, 4.1188e-02],\n",
      "          [4.0531e-02, 2.4389e-02, 3.8391e-02,  ..., 3.5819e-02,\n",
      "           1.3561e-02, 2.6241e-02],\n",
      "          ...,\n",
      "          [7.1575e-02, 1.0106e-01, 2.2173e-01,  ..., 7.2612e-03,\n",
      "           3.9119e-02, 4.8423e-02],\n",
      "          [4.5017e-02, 7.1660e-01, 2.5459e-02,  ..., 2.4681e-04,\n",
      "           2.9587e-04, 2.7983e-02],\n",
      "          [1.5115e-02, 7.6146e-02, 6.4195e-02,  ..., 2.1824e-02,\n",
      "           4.4464e-02, 7.9675e-03]]]]), tensor([[[[1.7743e-01, 3.7521e-01, 1.6678e-01,  ..., 3.5695e-04,\n",
      "           1.0933e-03, 1.3268e-01],\n",
      "          [4.3516e-02, 2.3388e-01, 9.6774e-02,  ..., 1.9097e-03,\n",
      "           1.3840e-02, 3.2080e-02],\n",
      "          [8.1063e-02, 1.4702e-01, 1.3583e-01,  ..., 1.0057e-02,\n",
      "           1.6966e-02, 5.6646e-02],\n",
      "          ...,\n",
      "          [1.4718e-02, 9.2080e-01, 2.4557e-02,  ..., 3.7802e-07,\n",
      "           6.1888e-07, 6.9881e-03],\n",
      "          [9.1767e-02, 5.3351e-01, 1.6126e-01,  ..., 6.5448e-05,\n",
      "           1.3349e-04, 4.7224e-02],\n",
      "          [5.6116e-02, 1.6442e-02, 3.5821e-02,  ..., 3.6146e-02,\n",
      "           6.3363e-02, 7.4302e-02]],\n",
      "\n",
      "         [[5.9442e-02, 1.7457e-01, 6.8187e-02,  ..., 5.3136e-04,\n",
      "           7.8217e-03, 4.5081e-02],\n",
      "          [1.1759e-01, 2.3108e-01, 4.9012e-02,  ..., 4.0909e-03,\n",
      "           1.3290e-03, 8.5273e-02],\n",
      "          [9.1519e-02, 2.5034e-01, 8.7355e-02,  ..., 2.1897e-03,\n",
      "           4.2162e-03, 6.8249e-02],\n",
      "          ...,\n",
      "          [9.9273e-02, 7.3246e-01, 4.4211e-02,  ..., 1.4259e-04,\n",
      "           2.1971e-04, 5.2814e-02],\n",
      "          [1.1793e-01, 1.0234e-01, 6.4952e-02,  ..., 2.6288e-03,\n",
      "           1.1371e-02, 8.3182e-02],\n",
      "          [8.1411e-03, 2.9663e-03, 7.2366e-03,  ..., 4.0859e-02,\n",
      "           3.5270e-01, 8.5280e-03]],\n",
      "\n",
      "         [[2.5901e-03, 4.0910e-03, 2.3251e-02,  ..., 1.6823e-03,\n",
      "           8.8087e-04, 1.7392e-03],\n",
      "          [3.6140e-02, 2.0164e-01, 9.2041e-02,  ..., 2.1791e-03,\n",
      "           7.3264e-04, 2.3453e-02],\n",
      "          [1.1522e-01, 2.9745e-01, 5.4066e-02,  ..., 3.9768e-03,\n",
      "           3.9445e-03, 8.4887e-02],\n",
      "          ...,\n",
      "          [8.0337e-02, 6.7662e-01, 1.2818e-01,  ..., 4.6698e-05,\n",
      "           2.1505e-04, 4.1401e-02],\n",
      "          [1.9436e-01, 1.6086e-01, 2.4144e-01,  ..., 1.4360e-03,\n",
      "           1.5641e-03, 1.2590e-01],\n",
      "          [2.0295e-04, 8.3125e-05, 4.7095e-04,  ..., 1.0522e-01,\n",
      "           1.9588e-01, 2.3776e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.8500e-02, 4.6488e-03, 2.4297e-02,  ..., 4.8328e-03,\n",
      "           6.7266e-03, 1.6938e-02],\n",
      "          [6.4975e-02, 6.0509e-02, 4.2867e-02,  ..., 3.2180e-03,\n",
      "           2.0516e-03, 4.1066e-02],\n",
      "          [3.4049e-02, 1.9794e-02, 3.5795e-02,  ..., 4.5617e-03,\n",
      "           7.8384e-03, 2.4137e-02],\n",
      "          ...,\n",
      "          [4.4579e-02, 8.2382e-01, 1.4685e-02,  ..., 1.1340e-04,\n",
      "           5.1802e-05, 2.2834e-02],\n",
      "          [1.7554e-01, 1.1016e-01, 3.6968e-02,  ..., 4.6029e-04,\n",
      "           2.1249e-04, 1.3016e-01],\n",
      "          [9.6224e-04, 2.0819e-05, 7.0085e-04,  ..., 8.3145e-02,\n",
      "           1.5910e-01, 1.5058e-03]],\n",
      "\n",
      "         [[1.7600e-02, 8.5285e-03, 3.6417e-02,  ..., 2.1551e-03,\n",
      "           3.8019e-03, 1.5472e-02],\n",
      "          [4.8449e-02, 2.3196e-01, 1.8550e-01,  ..., 6.8339e-04,\n",
      "           1.1787e-03, 2.4887e-02],\n",
      "          [5.4983e-02, 1.4981e-01, 6.4043e-02,  ..., 3.8303e-03,\n",
      "           1.0634e-03, 3.3814e-02],\n",
      "          ...,\n",
      "          [5.3178e-02, 8.2544e-01, 6.5429e-02,  ..., 1.4763e-05,\n",
      "           2.5327e-04, 2.3618e-02],\n",
      "          [7.9269e-02, 9.9254e-02, 1.6045e-01,  ..., 1.7350e-03,\n",
      "           1.2317e-02, 4.0593e-02],\n",
      "          [1.5976e-03, 2.5438e-04, 3.5471e-03,  ..., 7.2960e-02,\n",
      "           8.6685e-02, 1.9321e-03]],\n",
      "\n",
      "         [[4.4535e-03, 1.5546e-02, 3.4853e-02,  ..., 3.1336e-03,\n",
      "           4.2528e-03, 2.7499e-03],\n",
      "          [7.6824e-02, 5.6918e-02, 3.7978e-02,  ..., 5.4290e-03,\n",
      "           5.3130e-04, 4.1188e-02],\n",
      "          [4.0531e-02, 2.4389e-02, 3.8391e-02,  ..., 3.5819e-02,\n",
      "           1.3561e-02, 2.6241e-02],\n",
      "          ...,\n",
      "          [4.5017e-02, 7.1660e-01, 2.5459e-02,  ..., 2.4681e-04,\n",
      "           2.9587e-04, 2.7983e-02],\n",
      "          [1.5115e-02, 7.6146e-02, 6.4195e-02,  ..., 2.1824e-02,\n",
      "           4.4464e-02, 7.9675e-03],\n",
      "          [1.1855e-03, 4.5768e-04, 6.6438e-03,  ..., 1.0415e-01,\n",
      "           9.7604e-02, 1.0624e-03]]]]), tensor([[[[1.7743e-01, 3.7521e-01, 1.6678e-01,  ..., 3.5695e-04,\n",
      "           1.0933e-03, 1.3268e-01],\n",
      "          [4.3516e-02, 2.3388e-01, 9.6774e-02,  ..., 1.9097e-03,\n",
      "           1.3840e-02, 3.2080e-02],\n",
      "          [8.1063e-02, 1.4702e-01, 1.3583e-01,  ..., 1.0057e-02,\n",
      "           1.6966e-02, 5.6646e-02],\n",
      "          ...,\n",
      "          [9.1767e-02, 5.3351e-01, 1.6126e-01,  ..., 6.5448e-05,\n",
      "           1.3349e-04, 4.7224e-02],\n",
      "          [5.6116e-02, 1.6442e-02, 3.5821e-02,  ..., 3.6146e-02,\n",
      "           6.3363e-02, 7.4302e-02],\n",
      "          [1.3527e-04, 1.8381e-05, 3.7027e-05,  ..., 5.1562e-02,\n",
      "           2.8112e-02, 2.1499e-04]],\n",
      "\n",
      "         [[5.9442e-02, 1.7457e-01, 6.8187e-02,  ..., 5.3136e-04,\n",
      "           7.8217e-03, 4.5081e-02],\n",
      "          [1.1759e-01, 2.3108e-01, 4.9012e-02,  ..., 4.0909e-03,\n",
      "           1.3290e-03, 8.5273e-02],\n",
      "          [9.1519e-02, 2.5034e-01, 8.7355e-02,  ..., 2.1897e-03,\n",
      "           4.2162e-03, 6.8249e-02],\n",
      "          ...,\n",
      "          [1.1793e-01, 1.0234e-01, 6.4952e-02,  ..., 2.6288e-03,\n",
      "           1.1371e-02, 8.3182e-02],\n",
      "          [8.1411e-03, 2.9663e-03, 7.2366e-03,  ..., 4.0859e-02,\n",
      "           3.5270e-01, 8.5280e-03],\n",
      "          [1.0197e-03, 1.2534e-04, 6.3767e-04,  ..., 1.0253e-01,\n",
      "           1.1616e-02, 1.2605e-03]],\n",
      "\n",
      "         [[2.5901e-03, 4.0910e-03, 2.3251e-02,  ..., 1.6823e-03,\n",
      "           8.8087e-04, 1.7392e-03],\n",
      "          [3.6140e-02, 2.0164e-01, 9.2041e-02,  ..., 2.1791e-03,\n",
      "           7.3264e-04, 2.3453e-02],\n",
      "          [1.1522e-01, 2.9745e-01, 5.4066e-02,  ..., 3.9768e-03,\n",
      "           3.9445e-03, 8.4887e-02],\n",
      "          ...,\n",
      "          [1.9436e-01, 1.6086e-01, 2.4144e-01,  ..., 1.4360e-03,\n",
      "           1.5641e-03, 1.2590e-01],\n",
      "          [2.0295e-04, 8.3125e-05, 4.7095e-04,  ..., 1.0522e-01,\n",
      "           1.9588e-01, 2.3776e-04],\n",
      "          [9.1228e-05, 5.0055e-05, 1.4690e-04,  ..., 2.4541e-01,\n",
      "           5.8501e-02, 9.1818e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.8500e-02, 4.6488e-03, 2.4297e-02,  ..., 4.8328e-03,\n",
      "           6.7266e-03, 1.6938e-02],\n",
      "          [6.4975e-02, 6.0509e-02, 4.2867e-02,  ..., 3.2180e-03,\n",
      "           2.0516e-03, 4.1066e-02],\n",
      "          [3.4049e-02, 1.9794e-02, 3.5795e-02,  ..., 4.5617e-03,\n",
      "           7.8384e-03, 2.4137e-02],\n",
      "          ...,\n",
      "          [1.7554e-01, 1.1016e-01, 3.6968e-02,  ..., 4.6029e-04,\n",
      "           2.1249e-04, 1.3016e-01],\n",
      "          [9.6224e-04, 2.0819e-05, 7.0085e-04,  ..., 8.3145e-02,\n",
      "           1.5910e-01, 1.5058e-03],\n",
      "          [8.2599e-04, 1.4875e-04, 3.4344e-04,  ..., 4.1710e-02,\n",
      "           6.5811e-02, 1.1272e-03]],\n",
      "\n",
      "         [[1.7600e-02, 8.5285e-03, 3.6417e-02,  ..., 2.1551e-03,\n",
      "           3.8019e-03, 1.5472e-02],\n",
      "          [4.8449e-02, 2.3196e-01, 1.8550e-01,  ..., 6.8339e-04,\n",
      "           1.1787e-03, 2.4887e-02],\n",
      "          [5.4983e-02, 1.4981e-01, 6.4043e-02,  ..., 3.8303e-03,\n",
      "           1.0634e-03, 3.3814e-02],\n",
      "          ...,\n",
      "          [7.9269e-02, 9.9254e-02, 1.6045e-01,  ..., 1.7350e-03,\n",
      "           1.2317e-02, 4.0593e-02],\n",
      "          [1.5976e-03, 2.5438e-04, 3.5471e-03,  ..., 7.2960e-02,\n",
      "           8.6685e-02, 1.9321e-03],\n",
      "          [6.2839e-04, 1.3003e-03, 1.5374e-03,  ..., 1.2061e-01,\n",
      "           7.4237e-02, 6.3621e-04]],\n",
      "\n",
      "         [[4.4535e-03, 1.5546e-02, 3.4853e-02,  ..., 3.1336e-03,\n",
      "           4.2528e-03, 2.7499e-03],\n",
      "          [7.6824e-02, 5.6918e-02, 3.7978e-02,  ..., 5.4290e-03,\n",
      "           5.3130e-04, 4.1188e-02],\n",
      "          [4.0531e-02, 2.4389e-02, 3.8391e-02,  ..., 3.5819e-02,\n",
      "           1.3561e-02, 2.6241e-02],\n",
      "          ...,\n",
      "          [1.5115e-02, 7.6146e-02, 6.4195e-02,  ..., 2.1824e-02,\n",
      "           4.4464e-02, 7.9675e-03],\n",
      "          [1.1855e-03, 4.5768e-04, 6.6438e-03,  ..., 1.0415e-01,\n",
      "           9.7604e-02, 1.0624e-03],\n",
      "          [9.9145e-04, 2.7530e-04, 1.2775e-03,  ..., 1.2918e-01,\n",
      "           1.0644e-02, 1.1502e-03]]]]), tensor([[[[1.7743e-01, 3.7521e-01, 1.6678e-01,  ..., 3.5695e-04,\n",
      "           1.0933e-03, 1.3268e-01],\n",
      "          [4.3516e-02, 2.3388e-01, 9.6774e-02,  ..., 1.9097e-03,\n",
      "           1.3840e-02, 3.2080e-02],\n",
      "          [8.1063e-02, 1.4702e-01, 1.3583e-01,  ..., 1.0057e-02,\n",
      "           1.6966e-02, 5.6646e-02],\n",
      "          ...,\n",
      "          [5.6116e-02, 1.6442e-02, 3.5821e-02,  ..., 3.6146e-02,\n",
      "           6.3363e-02, 7.4302e-02],\n",
      "          [1.3527e-04, 1.8381e-05, 3.7027e-05,  ..., 5.1562e-02,\n",
      "           2.8112e-02, 2.1499e-04],\n",
      "          [4.5553e-04, 1.0902e-04, 1.7329e-04,  ..., 3.6247e-02,\n",
      "           2.2197e-02, 6.6165e-04]],\n",
      "\n",
      "         [[5.9442e-02, 1.7457e-01, 6.8187e-02,  ..., 5.3136e-04,\n",
      "           7.8217e-03, 4.5081e-02],\n",
      "          [1.1759e-01, 2.3108e-01, 4.9012e-02,  ..., 4.0909e-03,\n",
      "           1.3290e-03, 8.5273e-02],\n",
      "          [9.1519e-02, 2.5034e-01, 8.7355e-02,  ..., 2.1897e-03,\n",
      "           4.2162e-03, 6.8249e-02],\n",
      "          ...,\n",
      "          [8.1411e-03, 2.9663e-03, 7.2366e-03,  ..., 4.0859e-02,\n",
      "           3.5270e-01, 8.5280e-03],\n",
      "          [1.0197e-03, 1.2534e-04, 6.3767e-04,  ..., 1.0253e-01,\n",
      "           1.1616e-02, 1.2605e-03],\n",
      "          [9.2887e-04, 2.4432e-04, 1.8190e-03,  ..., 3.7186e-02,\n",
      "           1.5314e-02, 1.0980e-03]],\n",
      "\n",
      "         [[2.5901e-03, 4.0910e-03, 2.3251e-02,  ..., 1.6823e-03,\n",
      "           8.8087e-04, 1.7392e-03],\n",
      "          [3.6140e-02, 2.0164e-01, 9.2041e-02,  ..., 2.1791e-03,\n",
      "           7.3264e-04, 2.3453e-02],\n",
      "          [1.1522e-01, 2.9745e-01, 5.4066e-02,  ..., 3.9768e-03,\n",
      "           3.9445e-03, 8.4887e-02],\n",
      "          ...,\n",
      "          [2.0295e-04, 8.3125e-05, 4.7095e-04,  ..., 1.0522e-01,\n",
      "           1.9588e-01, 2.3776e-04],\n",
      "          [9.1228e-05, 5.0055e-05, 1.4690e-04,  ..., 2.4541e-01,\n",
      "           5.8501e-02, 9.1818e-05],\n",
      "          [1.8599e-04, 1.1446e-05, 7.9285e-05,  ..., 1.5163e-01,\n",
      "           4.2998e-02, 2.1631e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.8500e-02, 4.6488e-03, 2.4297e-02,  ..., 4.8328e-03,\n",
      "           6.7266e-03, 1.6938e-02],\n",
      "          [6.4975e-02, 6.0509e-02, 4.2867e-02,  ..., 3.2180e-03,\n",
      "           2.0516e-03, 4.1066e-02],\n",
      "          [3.4049e-02, 1.9794e-02, 3.5795e-02,  ..., 4.5617e-03,\n",
      "           7.8384e-03, 2.4137e-02],\n",
      "          ...,\n",
      "          [9.6224e-04, 2.0819e-05, 7.0085e-04,  ..., 8.3145e-02,\n",
      "           1.5910e-01, 1.5058e-03],\n",
      "          [8.2599e-04, 1.4875e-04, 3.4344e-04,  ..., 4.1710e-02,\n",
      "           6.5811e-02, 1.1272e-03],\n",
      "          [2.6940e-04, 1.2246e-05, 1.4015e-04,  ..., 6.7461e-02,\n",
      "           5.8942e-02, 3.7940e-04]],\n",
      "\n",
      "         [[1.7600e-02, 8.5285e-03, 3.6417e-02,  ..., 2.1551e-03,\n",
      "           3.8019e-03, 1.5472e-02],\n",
      "          [4.8449e-02, 2.3196e-01, 1.8550e-01,  ..., 6.8339e-04,\n",
      "           1.1787e-03, 2.4887e-02],\n",
      "          [5.4983e-02, 1.4981e-01, 6.4043e-02,  ..., 3.8303e-03,\n",
      "           1.0634e-03, 3.3814e-02],\n",
      "          ...,\n",
      "          [1.5976e-03, 2.5438e-04, 3.5471e-03,  ..., 7.2960e-02,\n",
      "           8.6685e-02, 1.9321e-03],\n",
      "          [6.2839e-04, 1.3003e-03, 1.5374e-03,  ..., 1.2061e-01,\n",
      "           7.4237e-02, 6.3621e-04],\n",
      "          [2.5232e-04, 1.4134e-04, 2.4048e-04,  ..., 5.7536e-02,\n",
      "           4.8296e-02, 2.3715e-04]],\n",
      "\n",
      "         [[4.4535e-03, 1.5546e-02, 3.4853e-02,  ..., 3.1336e-03,\n",
      "           4.2528e-03, 2.7499e-03],\n",
      "          [7.6824e-02, 5.6918e-02, 3.7978e-02,  ..., 5.4290e-03,\n",
      "           5.3130e-04, 4.1188e-02],\n",
      "          [4.0531e-02, 2.4389e-02, 3.8391e-02,  ..., 3.5819e-02,\n",
      "           1.3561e-02, 2.6241e-02],\n",
      "          ...,\n",
      "          [1.1855e-03, 4.5768e-04, 6.6438e-03,  ..., 1.0415e-01,\n",
      "           9.7604e-02, 1.0624e-03],\n",
      "          [9.9145e-04, 2.7530e-04, 1.2775e-03,  ..., 1.2918e-01,\n",
      "           1.0644e-02, 1.1502e-03],\n",
      "          [6.8652e-04, 7.3717e-05, 6.0797e-04,  ..., 1.7390e-01,\n",
      "           2.0928e-02, 7.9568e-04]]]]), tensor([[[[1.7743e-01, 3.7521e-01, 1.6678e-01,  ..., 3.5695e-04,\n",
      "           1.0933e-03, 1.3268e-01],\n",
      "          [4.3516e-02, 2.3388e-01, 9.6774e-02,  ..., 1.9097e-03,\n",
      "           1.3840e-02, 3.2080e-02],\n",
      "          [8.1063e-02, 1.4702e-01, 1.3583e-01,  ..., 1.0057e-02,\n",
      "           1.6966e-02, 5.6646e-02],\n",
      "          ...,\n",
      "          [1.3527e-04, 1.8381e-05, 3.7027e-05,  ..., 5.1562e-02,\n",
      "           2.8112e-02, 2.1499e-04],\n",
      "          [4.5553e-04, 1.0902e-04, 1.7329e-04,  ..., 3.6247e-02,\n",
      "           2.2197e-02, 6.6165e-04],\n",
      "          [5.4259e-02, 1.2076e-02, 1.6881e-02,  ..., 1.8245e-01,\n",
      "           8.1867e-02, 6.7370e-02]],\n",
      "\n",
      "         [[5.9442e-02, 1.7457e-01, 6.8187e-02,  ..., 5.3136e-04,\n",
      "           7.8217e-03, 4.5081e-02],\n",
      "          [1.1759e-01, 2.3108e-01, 4.9012e-02,  ..., 4.0909e-03,\n",
      "           1.3290e-03, 8.5273e-02],\n",
      "          [9.1519e-02, 2.5034e-01, 8.7355e-02,  ..., 2.1897e-03,\n",
      "           4.2162e-03, 6.8249e-02],\n",
      "          ...,\n",
      "          [1.0197e-03, 1.2534e-04, 6.3767e-04,  ..., 1.0253e-01,\n",
      "           1.1616e-02, 1.2605e-03],\n",
      "          [9.2887e-04, 2.4432e-04, 1.8190e-03,  ..., 3.7186e-02,\n",
      "           1.5314e-02, 1.0980e-03],\n",
      "          [1.3517e-02, 5.7531e-03, 1.0878e-02,  ..., 1.0728e-01,\n",
      "           3.8605e-01, 1.2825e-02]],\n",
      "\n",
      "         [[2.5901e-03, 4.0910e-03, 2.3251e-02,  ..., 1.6823e-03,\n",
      "           8.8087e-04, 1.7392e-03],\n",
      "          [3.6140e-02, 2.0164e-01, 9.2041e-02,  ..., 2.1791e-03,\n",
      "           7.3264e-04, 2.3453e-02],\n",
      "          [1.1522e-01, 2.9745e-01, 5.4066e-02,  ..., 3.9768e-03,\n",
      "           3.9445e-03, 8.4887e-02],\n",
      "          ...,\n",
      "          [9.1228e-05, 5.0055e-05, 1.4690e-04,  ..., 2.4541e-01,\n",
      "           5.8501e-02, 9.1818e-05],\n",
      "          [1.8599e-04, 1.1446e-05, 7.9285e-05,  ..., 1.5163e-01,\n",
      "           4.2998e-02, 2.1631e-04],\n",
      "          [6.2201e-04, 1.4844e-03, 2.7008e-03,  ..., 2.8201e-01,\n",
      "           1.2682e-01, 6.0292e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.8500e-02, 4.6488e-03, 2.4297e-02,  ..., 4.8328e-03,\n",
      "           6.7267e-03, 1.6938e-02],\n",
      "          [6.4975e-02, 6.0509e-02, 4.2867e-02,  ..., 3.2180e-03,\n",
      "           2.0516e-03, 4.1066e-02],\n",
      "          [3.4049e-02, 1.9794e-02, 3.5795e-02,  ..., 4.5617e-03,\n",
      "           7.8384e-03, 2.4137e-02],\n",
      "          ...,\n",
      "          [8.2599e-04, 1.4875e-04, 3.4344e-04,  ..., 4.1710e-02,\n",
      "           6.5811e-02, 1.1272e-03],\n",
      "          [2.6940e-04, 1.2246e-05, 1.4015e-04,  ..., 6.7461e-02,\n",
      "           5.8942e-02, 3.7940e-04],\n",
      "          [7.3629e-04, 1.1277e-04, 1.7478e-03,  ..., 6.9378e-02,\n",
      "           1.1674e-01, 9.3028e-04]],\n",
      "\n",
      "         [[1.7600e-02, 8.5285e-03, 3.6417e-02,  ..., 2.1551e-03,\n",
      "           3.8019e-03, 1.5472e-02],\n",
      "          [4.8449e-02, 2.3196e-01, 1.8550e-01,  ..., 6.8339e-04,\n",
      "           1.1787e-03, 2.4887e-02],\n",
      "          [5.4983e-02, 1.4981e-01, 6.4043e-02,  ..., 3.8303e-03,\n",
      "           1.0634e-03, 3.3814e-02],\n",
      "          ...,\n",
      "          [6.2839e-04, 1.3003e-03, 1.5374e-03,  ..., 1.2061e-01,\n",
      "           7.4237e-02, 6.3621e-04],\n",
      "          [2.5232e-04, 1.4134e-04, 2.4048e-04,  ..., 5.7536e-02,\n",
      "           4.8296e-02, 2.3715e-04],\n",
      "          [1.4915e-02, 9.1032e-04, 1.2856e-02,  ..., 2.3953e-01,\n",
      "           3.4171e-02, 1.7885e-02]],\n",
      "\n",
      "         [[4.4535e-03, 1.5546e-02, 3.4853e-02,  ..., 3.1336e-03,\n",
      "           4.2528e-03, 2.7499e-03],\n",
      "          [7.6824e-02, 5.6918e-02, 3.7978e-02,  ..., 5.4290e-03,\n",
      "           5.3130e-04, 4.1188e-02],\n",
      "          [4.0531e-02, 2.4389e-02, 3.8391e-02,  ..., 3.5819e-02,\n",
      "           1.3561e-02, 2.6241e-02],\n",
      "          ...,\n",
      "          [9.9145e-04, 2.7530e-04, 1.2775e-03,  ..., 1.2918e-01,\n",
      "           1.0644e-02, 1.1502e-03],\n",
      "          [6.8652e-04, 7.3717e-05, 6.0797e-04,  ..., 1.7390e-01,\n",
      "           2.0928e-02, 7.9568e-04],\n",
      "          [1.0863e-02, 2.5692e-03, 8.7320e-03,  ..., 7.8806e-02,\n",
      "           1.4702e-01, 1.1178e-02]]]]), tensor([[[[1.7743e-01, 3.7521e-01, 1.6678e-01,  ..., 3.5695e-04,\n",
      "           1.0933e-03, 1.3268e-01],\n",
      "          [4.3516e-02, 2.3388e-01, 9.6774e-02,  ..., 1.9097e-03,\n",
      "           1.3840e-02, 3.2080e-02],\n",
      "          [8.1063e-02, 1.4702e-01, 1.3583e-01,  ..., 1.0057e-02,\n",
      "           1.6966e-02, 5.6646e-02],\n",
      "          ...,\n",
      "          [4.5553e-04, 1.0902e-04, 1.7329e-04,  ..., 3.6247e-02,\n",
      "           2.2197e-02, 6.6165e-04],\n",
      "          [5.4259e-02, 1.2076e-02, 1.6881e-02,  ..., 1.8245e-01,\n",
      "           8.1867e-02, 6.7370e-02],\n",
      "          [2.8233e-04, 9.9061e-06, 5.0693e-05,  ..., 1.7955e-01,\n",
      "           2.2202e-02, 4.4994e-04]],\n",
      "\n",
      "         [[5.9442e-02, 1.7457e-01, 6.8187e-02,  ..., 5.3136e-04,\n",
      "           7.8217e-03, 4.5081e-02],\n",
      "          [1.1759e-01, 2.3108e-01, 4.9012e-02,  ..., 4.0909e-03,\n",
      "           1.3290e-03, 8.5273e-02],\n",
      "          [9.1519e-02, 2.5034e-01, 8.7355e-02,  ..., 2.1897e-03,\n",
      "           4.2162e-03, 6.8249e-02],\n",
      "          ...,\n",
      "          [9.2887e-04, 2.4432e-04, 1.8190e-03,  ..., 3.7186e-02,\n",
      "           1.5314e-02, 1.0980e-03],\n",
      "          [1.3517e-02, 5.7531e-03, 1.0878e-02,  ..., 1.0728e-01,\n",
      "           3.8605e-01, 1.2825e-02],\n",
      "          [2.9677e-04, 4.4046e-05, 8.1904e-04,  ..., 1.4555e-01,\n",
      "           5.9981e-03, 3.4819e-04]],\n",
      "\n",
      "         [[2.5901e-03, 4.0910e-03, 2.3251e-02,  ..., 1.6823e-03,\n",
      "           8.8087e-04, 1.7392e-03],\n",
      "          [3.6140e-02, 2.0164e-01, 9.2041e-02,  ..., 2.1791e-03,\n",
      "           7.3264e-04, 2.3453e-02],\n",
      "          [1.1522e-01, 2.9745e-01, 5.4066e-02,  ..., 3.9768e-03,\n",
      "           3.9445e-03, 8.4887e-02],\n",
      "          ...,\n",
      "          [1.8599e-04, 1.1446e-05, 7.9285e-05,  ..., 1.5163e-01,\n",
      "           4.2998e-02, 2.1631e-04],\n",
      "          [6.2201e-04, 1.4844e-03, 2.7008e-03,  ..., 2.8201e-01,\n",
      "           1.2682e-01, 6.0292e-04],\n",
      "          [2.2246e-05, 1.8991e-05, 6.7360e-05,  ..., 5.5136e-01,\n",
      "           1.8968e-02, 2.0666e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.8500e-02, 4.6488e-03, 2.4297e-02,  ..., 4.8328e-03,\n",
      "           6.7267e-03, 1.6938e-02],\n",
      "          [6.4975e-02, 6.0509e-02, 4.2867e-02,  ..., 3.2180e-03,\n",
      "           2.0516e-03, 4.1066e-02],\n",
      "          [3.4049e-02, 1.9794e-02, 3.5795e-02,  ..., 4.5617e-03,\n",
      "           7.8384e-03, 2.4137e-02],\n",
      "          ...,\n",
      "          [2.6940e-04, 1.2246e-05, 1.4015e-04,  ..., 6.7461e-02,\n",
      "           5.8942e-02, 3.7940e-04],\n",
      "          [7.3629e-04, 1.1277e-04, 1.7478e-03,  ..., 6.9378e-02,\n",
      "           1.1674e-01, 9.3028e-04],\n",
      "          [3.7613e-04, 1.1879e-04, 2.7632e-04,  ..., 1.1516e-01,\n",
      "           4.3101e-02, 4.6353e-04]],\n",
      "\n",
      "         [[1.7600e-02, 8.5285e-03, 3.6417e-02,  ..., 2.1551e-03,\n",
      "           3.8019e-03, 1.5472e-02],\n",
      "          [4.8449e-02, 2.3196e-01, 1.8550e-01,  ..., 6.8339e-04,\n",
      "           1.1787e-03, 2.4887e-02],\n",
      "          [5.4983e-02, 1.4981e-01, 6.4043e-02,  ..., 3.8303e-03,\n",
      "           1.0634e-03, 3.3814e-02],\n",
      "          ...,\n",
      "          [2.5232e-04, 1.4134e-04, 2.4048e-04,  ..., 5.7536e-02,\n",
      "           4.8296e-02, 2.3715e-04],\n",
      "          [1.4915e-02, 9.1032e-04, 1.2856e-02,  ..., 2.3953e-01,\n",
      "           3.4171e-02, 1.7885e-02],\n",
      "          [1.7252e-04, 1.6812e-04, 2.6707e-04,  ..., 2.0535e-01,\n",
      "           3.1039e-02, 1.9829e-04]],\n",
      "\n",
      "         [[4.4535e-03, 1.5546e-02, 3.4853e-02,  ..., 3.1336e-03,\n",
      "           4.2528e-03, 2.7499e-03],\n",
      "          [7.6824e-02, 5.6918e-02, 3.7978e-02,  ..., 5.4290e-03,\n",
      "           5.3130e-04, 4.1188e-02],\n",
      "          [4.0531e-02, 2.4389e-02, 3.8391e-02,  ..., 3.5819e-02,\n",
      "           1.3561e-02, 2.6241e-02],\n",
      "          ...,\n",
      "          [6.8652e-04, 7.3717e-05, 6.0797e-04,  ..., 1.7390e-01,\n",
      "           2.0928e-02, 7.9568e-04],\n",
      "          [1.0863e-02, 2.5692e-03, 8.7320e-03,  ..., 7.8806e-02,\n",
      "           1.4702e-01, 1.1178e-02],\n",
      "          [1.4483e-03, 3.0061e-04, 9.4022e-04,  ..., 2.3759e-01,\n",
      "           8.9389e-03, 1.6184e-03]]]]), tensor([[[[1.7743e-01, 3.7521e-01, 1.6678e-01,  ..., 3.5695e-04,\n",
      "           1.0933e-03, 1.3268e-01],\n",
      "          [4.3516e-02, 2.3388e-01, 9.6774e-02,  ..., 1.9097e-03,\n",
      "           1.3840e-02, 3.2080e-02],\n",
      "          [8.1063e-02, 1.4702e-01, 1.3583e-01,  ..., 1.0057e-02,\n",
      "           1.6966e-02, 5.6646e-02],\n",
      "          ...,\n",
      "          [5.4259e-02, 1.2076e-02, 1.6881e-02,  ..., 1.8245e-01,\n",
      "           8.1867e-02, 6.7370e-02],\n",
      "          [2.8233e-04, 9.9061e-06, 5.0693e-05,  ..., 1.7955e-01,\n",
      "           2.2202e-02, 4.4994e-04],\n",
      "          [1.0115e-03, 1.1204e-05, 2.7826e-04,  ..., 8.7870e-02,\n",
      "           1.6206e-02, 1.6069e-03]],\n",
      "\n",
      "         [[5.9442e-02, 1.7457e-01, 6.8187e-02,  ..., 5.3136e-04,\n",
      "           7.8217e-03, 4.5081e-02],\n",
      "          [1.1759e-01, 2.3108e-01, 4.9012e-02,  ..., 4.0909e-03,\n",
      "           1.3290e-03, 8.5273e-02],\n",
      "          [9.1519e-02, 2.5034e-01, 8.7355e-02,  ..., 2.1897e-03,\n",
      "           4.2162e-03, 6.8249e-02],\n",
      "          ...,\n",
      "          [1.3517e-02, 5.7531e-03, 1.0878e-02,  ..., 1.0728e-01,\n",
      "           3.8605e-01, 1.2825e-02],\n",
      "          [2.9677e-04, 4.4046e-05, 8.1904e-04,  ..., 1.4555e-01,\n",
      "           5.9981e-03, 3.4819e-04],\n",
      "          [4.0482e-04, 1.8568e-05, 1.1644e-03,  ..., 1.7088e-01,\n",
      "           4.4828e-03, 5.4615e-04]],\n",
      "\n",
      "         [[2.5901e-03, 4.0910e-03, 2.3251e-02,  ..., 1.6823e-03,\n",
      "           8.8087e-04, 1.7392e-03],\n",
      "          [3.6140e-02, 2.0164e-01, 9.2041e-02,  ..., 2.1791e-03,\n",
      "           7.3264e-04, 2.3453e-02],\n",
      "          [1.1522e-01, 2.9745e-01, 5.4066e-02,  ..., 3.9768e-03,\n",
      "           3.9445e-03, 8.4887e-02],\n",
      "          ...,\n",
      "          [6.2201e-04, 1.4844e-03, 2.7008e-03,  ..., 2.8201e-01,\n",
      "           1.2682e-01, 6.0292e-04],\n",
      "          [2.2246e-05, 1.8992e-05, 6.7360e-05,  ..., 5.5136e-01,\n",
      "           1.8968e-02, 2.0666e-05],\n",
      "          [3.7762e-04, 9.0280e-05, 4.8025e-04,  ..., 2.3457e-01,\n",
      "           1.8612e-02, 3.4958e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.8500e-02, 4.6488e-03, 2.4297e-02,  ..., 4.8328e-03,\n",
      "           6.7266e-03, 1.6938e-02],\n",
      "          [6.4975e-02, 6.0509e-02, 4.2867e-02,  ..., 3.2180e-03,\n",
      "           2.0516e-03, 4.1066e-02],\n",
      "          [3.4049e-02, 1.9794e-02, 3.5795e-02,  ..., 4.5617e-03,\n",
      "           7.8384e-03, 2.4137e-02],\n",
      "          ...,\n",
      "          [7.3629e-04, 1.1277e-04, 1.7478e-03,  ..., 6.9378e-02,\n",
      "           1.1674e-01, 9.3028e-04],\n",
      "          [3.7613e-04, 1.1879e-04, 2.7632e-04,  ..., 1.1516e-01,\n",
      "           4.3101e-02, 4.6353e-04],\n",
      "          [7.5199e-04, 9.7753e-05, 3.2368e-04,  ..., 8.9833e-02,\n",
      "           1.4723e-02, 9.3558e-04]],\n",
      "\n",
      "         [[1.7600e-02, 8.5285e-03, 3.6417e-02,  ..., 2.1551e-03,\n",
      "           3.8019e-03, 1.5472e-02],\n",
      "          [4.8449e-02, 2.3196e-01, 1.8550e-01,  ..., 6.8339e-04,\n",
      "           1.1787e-03, 2.4887e-02],\n",
      "          [5.4983e-02, 1.4981e-01, 6.4043e-02,  ..., 3.8303e-03,\n",
      "           1.0634e-03, 3.3814e-02],\n",
      "          ...,\n",
      "          [1.4915e-02, 9.1032e-04, 1.2856e-02,  ..., 2.3953e-01,\n",
      "           3.4171e-02, 1.7885e-02],\n",
      "          [1.7252e-04, 1.6812e-04, 2.6707e-04,  ..., 2.0535e-01,\n",
      "           3.1039e-02, 1.9829e-04],\n",
      "          [8.3051e-04, 2.4800e-04, 1.0705e-03,  ..., 3.3629e-01,\n",
      "           2.9422e-02, 8.9213e-04]],\n",
      "\n",
      "         [[4.4535e-03, 1.5546e-02, 3.4853e-02,  ..., 3.1336e-03,\n",
      "           4.2528e-03, 2.7499e-03],\n",
      "          [7.6824e-02, 5.6918e-02, 3.7978e-02,  ..., 5.4290e-03,\n",
      "           5.3130e-04, 4.1188e-02],\n",
      "          [4.0531e-02, 2.4389e-02, 3.8391e-02,  ..., 3.5819e-02,\n",
      "           1.3561e-02, 2.6241e-02],\n",
      "          ...,\n",
      "          [1.0863e-02, 2.5692e-03, 8.7320e-03,  ..., 7.8806e-02,\n",
      "           1.4702e-01, 1.1178e-02],\n",
      "          [1.4483e-03, 3.0061e-04, 9.4022e-04,  ..., 2.3759e-01,\n",
      "           8.9389e-03, 1.6184e-03],\n",
      "          [1.8501e-03, 2.8103e-04, 7.6538e-04,  ..., 8.4202e-02,\n",
      "           4.7958e-03, 2.2339e-03]]]]), tensor([[[[1.7743e-01, 3.7521e-01, 1.6678e-01,  ..., 3.5695e-04,\n",
      "           1.0933e-03, 1.3268e-01],\n",
      "          [4.3516e-02, 2.3388e-01, 9.6774e-02,  ..., 1.9097e-03,\n",
      "           1.3840e-02, 3.2080e-02],\n",
      "          [8.1063e-02, 1.4702e-01, 1.3583e-01,  ..., 1.0057e-02,\n",
      "           1.6966e-02, 5.6646e-02],\n",
      "          ...,\n",
      "          [2.8233e-04, 9.9061e-06, 5.0693e-05,  ..., 1.7955e-01,\n",
      "           2.2202e-02, 4.4994e-04],\n",
      "          [1.0115e-03, 1.1204e-05, 2.7826e-04,  ..., 8.7870e-02,\n",
      "           1.6206e-02, 1.6069e-03],\n",
      "          [1.5433e-01, 2.3420e-02, 1.2431e-02,  ..., 2.6346e-02,\n",
      "           2.5826e-02, 1.9878e-01]],\n",
      "\n",
      "         [[5.9442e-02, 1.7457e-01, 6.8187e-02,  ..., 5.3136e-04,\n",
      "           7.8217e-03, 4.5081e-02],\n",
      "          [1.1759e-01, 2.3108e-01, 4.9012e-02,  ..., 4.0909e-03,\n",
      "           1.3290e-03, 8.5273e-02],\n",
      "          [9.1519e-02, 2.5034e-01, 8.7355e-02,  ..., 2.1897e-03,\n",
      "           4.2162e-03, 6.8249e-02],\n",
      "          ...,\n",
      "          [2.9677e-04, 4.4046e-05, 8.1904e-04,  ..., 1.4555e-01,\n",
      "           5.9981e-03, 3.4819e-04],\n",
      "          [4.0482e-04, 1.8568e-05, 1.1644e-03,  ..., 1.7088e-01,\n",
      "           4.4828e-03, 5.4615e-04],\n",
      "          [2.2977e-02, 5.4783e-03, 3.4327e-02,  ..., 5.9168e-02,\n",
      "           1.4705e-01, 2.3459e-02]],\n",
      "\n",
      "         [[2.5901e-03, 4.0910e-03, 2.3251e-02,  ..., 1.6823e-03,\n",
      "           8.8087e-04, 1.7392e-03],\n",
      "          [3.6140e-02, 2.0164e-01, 9.2041e-02,  ..., 2.1791e-03,\n",
      "           7.3264e-04, 2.3453e-02],\n",
      "          [1.1522e-01, 2.9745e-01, 5.4066e-02,  ..., 3.9768e-03,\n",
      "           3.9445e-03, 8.4887e-02],\n",
      "          ...,\n",
      "          [2.2246e-05, 1.8992e-05, 6.7360e-05,  ..., 5.5136e-01,\n",
      "           1.8968e-02, 2.0666e-05],\n",
      "          [3.7762e-04, 9.0280e-05, 4.8025e-04,  ..., 2.3457e-01,\n",
      "           1.8612e-02, 3.4958e-04],\n",
      "          [7.9512e-02, 1.7778e-02, 1.7704e-02,  ..., 1.0674e-01,\n",
      "           5.5313e-02, 9.3379e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.8500e-02, 4.6488e-03, 2.4297e-02,  ..., 4.8328e-03,\n",
      "           6.7266e-03, 1.6938e-02],\n",
      "          [6.4975e-02, 6.0509e-02, 4.2867e-02,  ..., 3.2180e-03,\n",
      "           2.0516e-03, 4.1066e-02],\n",
      "          [3.4049e-02, 1.9794e-02, 3.5795e-02,  ..., 4.5617e-03,\n",
      "           7.8384e-03, 2.4137e-02],\n",
      "          ...,\n",
      "          [3.7613e-04, 1.1879e-04, 2.7632e-04,  ..., 1.1516e-01,\n",
      "           4.3101e-02, 4.6353e-04],\n",
      "          [7.5199e-04, 9.7753e-05, 3.2368e-04,  ..., 8.9833e-02,\n",
      "           1.4723e-02, 9.3558e-04],\n",
      "          [5.8742e-02, 1.3992e-02, 3.6791e-02,  ..., 8.9737e-02,\n",
      "           6.4449e-02, 5.7053e-02]],\n",
      "\n",
      "         [[1.7600e-02, 8.5285e-03, 3.6417e-02,  ..., 2.1551e-03,\n",
      "           3.8019e-03, 1.5472e-02],\n",
      "          [4.8449e-02, 2.3196e-01, 1.8550e-01,  ..., 6.8339e-04,\n",
      "           1.1787e-03, 2.4887e-02],\n",
      "          [5.4983e-02, 1.4981e-01, 6.4043e-02,  ..., 3.8303e-03,\n",
      "           1.0634e-03, 3.3814e-02],\n",
      "          ...,\n",
      "          [1.7252e-04, 1.6812e-04, 2.6707e-04,  ..., 2.0535e-01,\n",
      "           3.1039e-02, 1.9829e-04],\n",
      "          [8.3051e-04, 2.4800e-04, 1.0705e-03,  ..., 3.3629e-01,\n",
      "           2.9422e-02, 8.9213e-04],\n",
      "          [4.1726e-02, 2.6577e-03, 5.1034e-03,  ..., 2.0145e-01,\n",
      "           8.0668e-02, 4.0998e-02]],\n",
      "\n",
      "         [[4.4535e-03, 1.5546e-02, 3.4853e-02,  ..., 3.1336e-03,\n",
      "           4.2528e-03, 2.7499e-03],\n",
      "          [7.6824e-02, 5.6918e-02, 3.7978e-02,  ..., 5.4290e-03,\n",
      "           5.3130e-04, 4.1188e-02],\n",
      "          [4.0531e-02, 2.4389e-02, 3.8391e-02,  ..., 3.5819e-02,\n",
      "           1.3561e-02, 2.6241e-02],\n",
      "          ...,\n",
      "          [1.4483e-03, 3.0061e-04, 9.4022e-04,  ..., 2.3759e-01,\n",
      "           8.9389e-03, 1.6184e-03],\n",
      "          [1.8501e-03, 2.8103e-04, 7.6538e-04,  ..., 8.4202e-02,\n",
      "           4.7958e-03, 2.2339e-03],\n",
      "          [3.4065e-03, 4.0704e-04, 2.3070e-03,  ..., 1.5195e-02,\n",
      "           2.9854e-02, 4.0188e-03]]]]), tensor([[[[1.7743e-01, 3.7521e-01, 1.6678e-01,  ..., 3.5695e-04,\n",
      "           1.0933e-03, 1.3268e-01],\n",
      "          [4.3516e-02, 2.3388e-01, 9.6774e-02,  ..., 1.9097e-03,\n",
      "           1.3840e-02, 3.2080e-02],\n",
      "          [8.1063e-02, 1.4702e-01, 1.3583e-01,  ..., 1.0057e-02,\n",
      "           1.6966e-02, 5.6646e-02],\n",
      "          ...,\n",
      "          [1.0115e-03, 1.1204e-05, 2.7826e-04,  ..., 8.7870e-02,\n",
      "           1.6206e-02, 1.6069e-03],\n",
      "          [1.5433e-01, 2.3420e-02, 1.2431e-02,  ..., 2.6346e-02,\n",
      "           2.5826e-02, 1.9878e-01],\n",
      "          [7.2640e-02, 7.0794e-03, 3.2285e-02,  ..., 2.1007e-02,\n",
      "           1.3842e-02, 8.1350e-02]],\n",
      "\n",
      "         [[5.9442e-02, 1.7457e-01, 6.8187e-02,  ..., 5.3136e-04,\n",
      "           7.8217e-03, 4.5081e-02],\n",
      "          [1.1759e-01, 2.3108e-01, 4.9012e-02,  ..., 4.0909e-03,\n",
      "           1.3290e-03, 8.5273e-02],\n",
      "          [9.1519e-02, 2.5034e-01, 8.7355e-02,  ..., 2.1897e-03,\n",
      "           4.2162e-03, 6.8249e-02],\n",
      "          ...,\n",
      "          [4.0482e-04, 1.8568e-05, 1.1644e-03,  ..., 1.7088e-01,\n",
      "           4.4828e-03, 5.4615e-04],\n",
      "          [2.2977e-02, 5.4783e-03, 3.4327e-02,  ..., 5.9168e-02,\n",
      "           1.4705e-01, 2.3459e-02],\n",
      "          [3.3338e-03, 1.6034e-03, 1.4987e-02,  ..., 1.3627e-02,\n",
      "           9.5339e-03, 3.2630e-03]],\n",
      "\n",
      "         [[2.5901e-03, 4.0910e-03, 2.3251e-02,  ..., 1.6823e-03,\n",
      "           8.8087e-04, 1.7392e-03],\n",
      "          [3.6140e-02, 2.0164e-01, 9.2041e-02,  ..., 2.1791e-03,\n",
      "           7.3264e-04, 2.3453e-02],\n",
      "          [1.1522e-01, 2.9745e-01, 5.4066e-02,  ..., 3.9768e-03,\n",
      "           3.9445e-03, 8.4887e-02],\n",
      "          ...,\n",
      "          [3.7762e-04, 9.0280e-05, 4.8025e-04,  ..., 2.3457e-01,\n",
      "           1.8612e-02, 3.4958e-04],\n",
      "          [7.9512e-02, 1.7778e-02, 1.7704e-02,  ..., 1.0674e-01,\n",
      "           5.5313e-02, 9.3379e-02],\n",
      "          [8.0034e-02, 1.0719e-02, 2.2716e-02,  ..., 3.9518e-02,\n",
      "           3.0346e-02, 8.3647e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.8500e-02, 4.6488e-03, 2.4297e-02,  ..., 4.8328e-03,\n",
      "           6.7266e-03, 1.6938e-02],\n",
      "          [6.4975e-02, 6.0509e-02, 4.2867e-02,  ..., 3.2180e-03,\n",
      "           2.0516e-03, 4.1066e-02],\n",
      "          [3.4049e-02, 1.9795e-02, 3.5795e-02,  ..., 4.5617e-03,\n",
      "           7.8384e-03, 2.4137e-02],\n",
      "          ...,\n",
      "          [7.5199e-04, 9.7753e-05, 3.2368e-04,  ..., 8.9833e-02,\n",
      "           1.4723e-02, 9.3558e-04],\n",
      "          [5.8742e-02, 1.3992e-02, 3.6791e-02,  ..., 8.9737e-02,\n",
      "           6.4449e-02, 5.7053e-02],\n",
      "          [5.6626e-02, 2.4291e-02, 5.5221e-02,  ..., 2.1715e-02,\n",
      "           3.0906e-02, 6.0698e-02]],\n",
      "\n",
      "         [[1.7600e-02, 8.5285e-03, 3.6417e-02,  ..., 2.1551e-03,\n",
      "           3.8019e-03, 1.5472e-02],\n",
      "          [4.8449e-02, 2.3196e-01, 1.8550e-01,  ..., 6.8339e-04,\n",
      "           1.1787e-03, 2.4887e-02],\n",
      "          [5.4983e-02, 1.4981e-01, 6.4043e-02,  ..., 3.8303e-03,\n",
      "           1.0634e-03, 3.3814e-02],\n",
      "          ...,\n",
      "          [8.3051e-04, 2.4800e-04, 1.0705e-03,  ..., 3.3629e-01,\n",
      "           2.9422e-02, 8.9213e-04],\n",
      "          [4.1726e-02, 2.6577e-03, 5.1034e-03,  ..., 2.0145e-01,\n",
      "           8.0668e-02, 4.0998e-02],\n",
      "          [1.6732e-02, 2.4656e-03, 9.4828e-03,  ..., 6.7750e-02,\n",
      "           6.3112e-02, 1.6037e-02]],\n",
      "\n",
      "         [[4.4535e-03, 1.5546e-02, 3.4853e-02,  ..., 3.1336e-03,\n",
      "           4.2528e-03, 2.7499e-03],\n",
      "          [7.6824e-02, 5.6918e-02, 3.7978e-02,  ..., 5.4290e-03,\n",
      "           5.3130e-04, 4.1188e-02],\n",
      "          [4.0531e-02, 2.4389e-02, 3.8391e-02,  ..., 3.5819e-02,\n",
      "           1.3561e-02, 2.6241e-02],\n",
      "          ...,\n",
      "          [1.8500e-03, 2.8103e-04, 7.6537e-04,  ..., 8.4202e-02,\n",
      "           4.7958e-03, 2.2339e-03],\n",
      "          [3.4065e-03, 4.0705e-04, 2.3070e-03,  ..., 1.5195e-02,\n",
      "           2.9854e-02, 4.0188e-03],\n",
      "          [7.2228e-03, 1.4909e-03, 9.7961e-03,  ..., 1.0623e-01,\n",
      "           5.8050e-02, 8.0761e-03]]]]), tensor([[[[1.7743e-01, 3.7521e-01, 1.6678e-01,  ..., 3.5695e-04,\n",
      "           1.0933e-03, 1.3268e-01],\n",
      "          [4.3516e-02, 2.3388e-01, 9.6774e-02,  ..., 1.9097e-03,\n",
      "           1.3840e-02, 3.2080e-02],\n",
      "          [8.1063e-02, 1.4702e-01, 1.3583e-01,  ..., 1.0057e-02,\n",
      "           1.6966e-02, 5.6646e-02],\n",
      "          ...,\n",
      "          [1.5433e-01, 2.3420e-02, 1.2431e-02,  ..., 2.6346e-02,\n",
      "           2.5826e-02, 1.9878e-01],\n",
      "          [7.2640e-02, 7.0794e-03, 3.2285e-02,  ..., 2.1007e-02,\n",
      "           1.3842e-02, 8.1350e-02],\n",
      "          [6.7182e-03, 4.5956e-03, 4.4643e-03,  ..., 8.9160e-02,\n",
      "           1.6724e-01, 9.1482e-03]],\n",
      "\n",
      "         [[5.9442e-02, 1.7457e-01, 6.8187e-02,  ..., 5.3136e-04,\n",
      "           7.8217e-03, 4.5081e-02],\n",
      "          [1.1759e-01, 2.3108e-01, 4.9012e-02,  ..., 4.0909e-03,\n",
      "           1.3290e-03, 8.5273e-02],\n",
      "          [9.1519e-02, 2.5034e-01, 8.7355e-02,  ..., 2.1897e-03,\n",
      "           4.2162e-03, 6.8249e-02],\n",
      "          ...,\n",
      "          [2.2977e-02, 5.4783e-03, 3.4327e-02,  ..., 5.9168e-02,\n",
      "           1.4705e-01, 2.3459e-02],\n",
      "          [3.3338e-03, 1.6034e-03, 1.4987e-02,  ..., 1.3627e-02,\n",
      "           9.5339e-03, 3.2630e-03],\n",
      "          [1.7300e-03, 7.8616e-04, 1.0536e-03,  ..., 4.0230e-02,\n",
      "           2.8456e-01, 1.8048e-03]],\n",
      "\n",
      "         [[2.5901e-03, 4.0910e-03, 2.3251e-02,  ..., 1.6823e-03,\n",
      "           8.8087e-04, 1.7392e-03],\n",
      "          [3.6140e-02, 2.0164e-01, 9.2041e-02,  ..., 2.1791e-03,\n",
      "           7.3264e-04, 2.3453e-02],\n",
      "          [1.1522e-01, 2.9745e-01, 5.4066e-02,  ..., 3.9768e-03,\n",
      "           3.9445e-03, 8.4887e-02],\n",
      "          ...,\n",
      "          [7.9512e-02, 1.7778e-02, 1.7704e-02,  ..., 1.0674e-01,\n",
      "           5.5313e-02, 9.3379e-02],\n",
      "          [8.0034e-02, 1.0719e-02, 2.2716e-02,  ..., 3.9518e-02,\n",
      "           3.0346e-02, 8.3647e-02],\n",
      "          [1.0521e-03, 8.1056e-04, 4.0670e-04,  ..., 2.5617e-02,\n",
      "           1.5699e-01, 1.2399e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.8500e-02, 4.6488e-03, 2.4297e-02,  ..., 4.8328e-03,\n",
      "           6.7266e-03, 1.6938e-02],\n",
      "          [6.4975e-02, 6.0509e-02, 4.2867e-02,  ..., 3.2180e-03,\n",
      "           2.0516e-03, 4.1066e-02],\n",
      "          [3.4049e-02, 1.9795e-02, 3.5795e-02,  ..., 4.5617e-03,\n",
      "           7.8384e-03, 2.4137e-02],\n",
      "          ...,\n",
      "          [5.8742e-02, 1.3992e-02, 3.6791e-02,  ..., 8.9737e-02,\n",
      "           6.4449e-02, 5.7053e-02],\n",
      "          [5.6626e-02, 2.4291e-02, 5.5221e-02,  ..., 2.1715e-02,\n",
      "           3.0906e-02, 6.0698e-02],\n",
      "          [3.0689e-04, 6.6218e-05, 2.7607e-04,  ..., 4.9337e-02,\n",
      "           9.8316e-02, 4.9240e-04]],\n",
      "\n",
      "         [[1.7600e-02, 8.5285e-03, 3.6417e-02,  ..., 2.1551e-03,\n",
      "           3.8019e-03, 1.5472e-02],\n",
      "          [4.8449e-02, 2.3196e-01, 1.8550e-01,  ..., 6.8339e-04,\n",
      "           1.1787e-03, 2.4887e-02],\n",
      "          [5.4983e-02, 1.4981e-01, 6.4043e-02,  ..., 3.8303e-03,\n",
      "           1.0634e-03, 3.3814e-02],\n",
      "          ...,\n",
      "          [4.1726e-02, 2.6577e-03, 5.1034e-03,  ..., 2.0145e-01,\n",
      "           8.0668e-02, 4.0998e-02],\n",
      "          [1.6732e-02, 2.4656e-03, 9.4828e-03,  ..., 6.7750e-02,\n",
      "           6.3112e-02, 1.6037e-02],\n",
      "          [2.6678e-03, 7.9367e-04, 1.4494e-03,  ..., 1.0907e-01,\n",
      "           1.1556e-01, 3.1863e-03]],\n",
      "\n",
      "         [[4.4535e-03, 1.5546e-02, 3.4853e-02,  ..., 3.1336e-03,\n",
      "           4.2528e-03, 2.7499e-03],\n",
      "          [7.6824e-02, 5.6918e-02, 3.7978e-02,  ..., 5.4290e-03,\n",
      "           5.3130e-04, 4.1188e-02],\n",
      "          [4.0531e-02, 2.4389e-02, 3.8391e-02,  ..., 3.5819e-02,\n",
      "           1.3561e-02, 2.6241e-02],\n",
      "          ...,\n",
      "          [3.4065e-03, 4.0705e-04, 2.3070e-03,  ..., 1.5195e-02,\n",
      "           2.9854e-02, 4.0188e-03],\n",
      "          [7.2228e-03, 1.4909e-03, 9.7961e-03,  ..., 1.0623e-01,\n",
      "           5.8050e-02, 8.0761e-03],\n",
      "          [2.3513e-04, 1.5097e-04, 3.8232e-04,  ..., 4.5728e-02,\n",
      "           9.5790e-02, 2.7376e-04]]]])])]\n"
     ]
    }
   ],
   "source": [
    "print(translations[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XW17GD0zov22",
    "outputId": "b1d112a6-70ac-4a8b-a8b1-c29d548d2b17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I 'm looking for marine products . \", 'Can I get off at the Seouryeoksabangmulgwan ? ', 'I just got here this morning . ', 'Can I help you ? ', \"There 's a police station across the street . I 'm sure they can help you . \"]\n",
      "[\"i 'm looking for a spoon stand .\", 'can i get off at the seouryeoksabangmulgwan ?', 'i got here this morning .', 'may i help you ?', \"there 's a police station across the street . i 'm sure we 'll help you .\"]\n"
     ]
    }
   ],
   "source": [
    "reference = [example[\"en\"] for example in test_data]\n",
    "prediction = [\n",
    "    \" \".join([token for token in translation[0] if token not in [\"<sos>\", \"<eos>\"]])\n",
    "    for translation in translations\n",
    "]\n",
    "\n",
    "print(reference[:5])\n",
    "print(prediction[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4imOZ_7rov22",
    "outputId": "ad295807-ed7d-46d2-ee3f-fe9f6c15a4b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score = 39.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "bleu_score = calculate_bleu(reference, prediction)\n",
    "print(f'BLEU score = {bleu_score*100:.2f}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
